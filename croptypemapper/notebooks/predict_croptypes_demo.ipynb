{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69e57890-d43a-456d-a684-74075f8818ff",
   "metadata": {},
   "source": [
    "## Running inference with `croptypemapper`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "070a3717-30d2-4c8f-b870-91a5d4d231b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import os\n",
    "import inspect\n",
    "root_dir = os.environ['PWD']\n",
    "# sys.path.append('/home/mappers/projects/croptypemapper/croptypemapper')\n",
    "# works\n",
    "sys.path.insert(0, '/home/mappers/projects/croptypemapper/')\n",
    "sys.path.insert(0, '/home/mappers/projects/croptypemapper/croptypemapper/')\n",
    "\n",
    "\n",
    "# print(sys.path)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "# from torch import nn\n",
    "import yaml\n",
    "\n",
    "# os.listdir('/home/mappers/projects/croptypemapper/croptypemapper')\n",
    "# os.getcwd()\n",
    "import importlib\n",
    "import croptypemapper\n",
    "importlib.reload(croptypemapper)\n",
    "\n",
    "import models\n",
    "importlib.reload(models)\n",
    "from models import *\n",
    "# os.environ['PWD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56a4cf5e-4692-41f3-b882-be9f80985c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.path.pop()\n",
    "# sys.path.remove('/home/mappers/projects/croptypemapper/croptypemapper/')\n",
    "# print(sys.path)\n",
    "# Double_branch_stacked_biLSTM\n",
    "# os.environ\n",
    "# os.getlogin()\n",
    "# get_inp_branch()\n",
    "# print(inspect.getsource(Double_branch_stacked_biLSTM))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec69970b-fb45-4a2e-b889-4c03efab8386",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459b5b19-1b03-4756-981e-b5d253facdd3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def get_inp_branch(x):\n",
    "#     if isinstance(x, tuple) or isinstance(x, list):\n",
    "#         br1 = x[0]\n",
    "#         br2 = x[1]\n",
    "#     elif isinstance(x, int) or isinstance(x, float):\n",
    "#         br1 = x\n",
    "#         br2 = x\n",
    "           \n",
    "#     return br1, br2\n",
    "\n",
    "# class Double_branch_stacked_biLSTM(torch.nn.Module):\n",
    "#     def __init__(self, input_dims = (4, 11), hidden_dims = (64, 64), n_classes = 4, n_layers = (2, 2), \n",
    "#                  dropout_rate = (0.35, 0.45), s1_weight = 0.6, bidirectional = True, use_layernorm = True, \n",
    "#                  use_batchnorm = False, use_attention = False):\n",
    "#         super(Double_branch_stacked_biLSTM, self).__init__()\n",
    "        \n",
    "#         # Define object properties\n",
    "#         self.n_classes = n_classes\n",
    "#         self.s1_weight = s1_weight\n",
    "#         self.bidirectional = bidirectional\n",
    "#         self.use_layernorm = use_layernorm\n",
    "#         self.use_batchnorm = use_batchnorm\n",
    "#         self.use_attention = use_attention\n",
    "\n",
    "        \n",
    "#         s1_in_dim, s2_in_dim = get_inp_branch(input_dims)\n",
    "#         s1_hidden_dim, s2_hidden_dim = get_inp_branch(hidden_dims)\n",
    "#         s1_n_layers, s2_n_layers = get_inp_branch(n_layers)\n",
    "#         s1_dropout_rate, s2_dropout_rate = get_inp_branch(dropout_rate)\n",
    "        \n",
    "#         # Layer normalization for s1, s2 inputs and current_states of LSTM\n",
    "#         if self.use_layernorm:\n",
    "#             self.s1_inlayernorm = nn.LayerNorm(s1_in_dim)\n",
    "#             self.s1_clayernorm = nn.LayerNorm((s1_hidden_dim + s1_hidden_dim * self.bidirectional) * s1_n_layers)\n",
    "            \n",
    "#             self.s2_inlayernorm = nn.LayerNorm(s2_in_dim)\n",
    "#             self.s2_clayernorm = nn.LayerNorm((s2_hidden_dim + s2_hidden_dim * self.bidirectional) * s2_n_layers)\n",
    "        \n",
    "#         # LSTM layers for s1 and s2\n",
    "#         self.s1_lstm = nn.LSTM(input_size = s1_in_dim, hidden_size = s1_hidden_dim, \n",
    "#                                num_layers = s1_n_layers, bias = False, batch_first = True, dropout = s1_dropout_rate, \n",
    "#                                bidirectional = self.bidirectional)\n",
    "        \n",
    "#         self.s2_lstm = nn.LSTM(input_size = s2_in_dim, hidden_size = s2_hidden_dim, \n",
    "#                                num_layers = s2_n_layers, bias = False, batch_first = True, dropout = s2_dropout_rate, \n",
    "#                                bidirectional = self.bidirectional)\n",
    "        \n",
    "#         if self.bidirectional:\n",
    "#             s1_hidden_dim = s1_hidden_dim * 2\n",
    "#             s2_hidden_dim = s2_hidden_dim * 2\n",
    "        \n",
    "#         if self.use_attention:\n",
    "#             self.attention = attention()\n",
    "        \n",
    "#         # MLP layer on top of LSTM\n",
    "#         s1_linear_input_dim = s1_hidden_dim if self.use_attention else s1_hidden_dim * s1_n_layers\n",
    "#         self.s1_linear_class = nn.Linear(s1_linear_input_dim, self.n_classes, bias = True)\n",
    "        \n",
    "#         s2_linear_input_dim = s2_hidden_dim if self.use_attention else s2_hidden_dim * s2_n_layers\n",
    "#         self.s2_linear_class = nn.Linear(s2_linear_input_dim, self.n_classes, bias = True)\n",
    " \n",
    "\n",
    "#     def _logits(self, s1, s2):\n",
    "#         #set_trace()\n",
    "#         if self.use_layernorm:\n",
    "#             s1 = self.s1_inlayernorm(s1)\n",
    "#             s2 = self.s2_inlayernorm(s2)\n",
    "        \n",
    "#         # Get outputs and the last current state and hidden state for each branch.\n",
    "#         #s1_outputs & s2_outputs: [B, Seq_length, 2 x hidden_dim]\n",
    "#         s1_outputs, s1_last_state_list = self.s1_lstm.forward(s1)\n",
    "#         s2_outputs, s2_last_state_list = self.s2_lstm.forward(s2)\n",
    "        \n",
    "#         #s1_h & s1_c & s2_h & s2_c: [2 x num_layers, B, hidden_dim] \n",
    "#         s1_h, s1_c = s1_last_state_list\n",
    "#         s2_h, s2_c = s2_last_state_list\n",
    "        \n",
    "#         # Get the query layer to calculate self attention for each branch\n",
    "#         if self.use_attention:\n",
    "#             if self.bidirectional:\n",
    "#                 # Get the last state of each branch. size:[B, hidden_dim]\n",
    "#                 s1_query_forward = s1_c[-1]\n",
    "#                 s1_query_backward = s1_c[-2]\n",
    "#                 # size:[B, 2 x hidden_dim]\n",
    "#                 s1_query = torch.cat([s1_query_forward, s1_query_backward], 1)\n",
    "                \n",
    "#                 s2_query_forward = s2_c[-1]\n",
    "#                 s2_query_backward = s2_c[-2]\n",
    "#                 s2_query = torch.cat([s2_query_forward, s2_query_backward], 1)\n",
    "#             else:\n",
    "#                 s1_query = s1_c[-1]\n",
    "#                 s2_query = s2_c[-1]\n",
    "            \n",
    "#             # Get attention weights and hidden state\n",
    "#             s1_h, s1_weights = self.attention(s1_query, s1_outputs, s1_outputs)\n",
    "#             s2_h, s2_weights = self.attention(s2_query, s2_outputs, s2_outputs)\n",
    "#             s1_h = s1_h.squeeze(1)\n",
    "#             s2_h = s2_h.squeeze(1)\n",
    "#         else:\n",
    "#             s1_nlayers, s1_batchsize, s1_n_hidden = s1_c.shape\n",
    "#             s2_nlayers, s2_batchsize, s2_n_hidden = s2_c.shape\n",
    "#             s1_h = self.s1_clayernorm(s1_c.transpose(0,1).contiguous().view(s1_batchsize, s1_nlayers * s1_n_hidden))\n",
    "#             s2_h = self.s2_clayernorm(s2_c.transpose(0,1).contiguous().view(s2_batchsize, s2_nlayers * s2_n_hidden))\n",
    "        \n",
    "#         # Calculate logits for each branch. Shape:[B, num_classes]\n",
    "#         s1_logits = self.s1_linear_class.forward(s1_h)\n",
    "#         s2_logits = self.s2_linear_class.forward(s2_h)\n",
    "        \n",
    "#         if self.use_attention:\n",
    "#             s1_pts = s1_weights\n",
    "#             s2_pts = s2_weights\n",
    "#         else:\n",
    "#             s1_pts = None\n",
    "#             s2_pts = None\n",
    "        \n",
    "#         return s1_logits, s2_logits, s1_pts, s2_pts\n",
    "    \n",
    "#     def forward(self, s1, s2):\n",
    "        \n",
    "#         s1_logits, s2_logits, s1_pts, s2_pts = self._logits(s1, s2)\n",
    "#         fused_logits = (s1_logits * self.s1_weight) + (s2_logits * (1 - self.s1_weight))\n",
    "        \n",
    "#         return s1_logits, s2_logits, fused_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2295daa3-036e-4eec-a079-15b3420a763a",
   "metadata": {},
   "source": [
    "## Configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76854568-34df-40ca-ad4a-089e5842d66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yaml_path = '../../config-working.yaml'\n",
    "# with open(yaml_path, 'r') as yaml_file:\n",
    "#     config = yaml.safe_load(yaml_file)\n",
    "# # config\n",
    "# get_inp_branch(config[\"input_dims\"])\n",
    "# config[\"input_dims\"]\n",
    "# Double_branch_stacked_biLSTM\n",
    "\n",
    "config = {\n",
    "    \n",
    "    \"working_dir\" : \"C:/My_documents/CropTypeData_Rustowicz/working_folder\",\n",
    "    \"out_dir\": \"new_try_01\",\n",
    "    # Dataset & Loader\n",
    "    \"root_dir\" : \"C:/My_documents/CropTypeData_Rustowicz/CropType\",\n",
    "    \"sampling_strategy\" : \"ranked\",\n",
    "    \"lbl_fldrname\" : \"Labels\",\n",
    "    \"sources\" : [\"Sentinel-1\", \"Sentinel-2\"],\n",
    "    \"num_train_pixels\" : 15000,\n",
    "    \"num_validation_pixels\" : 10000,\n",
    "    \"test_label\" : False,\n",
    "    \"batch_train\" : 128,\n",
    "    \"batch_val\" : 1,\n",
    "    \n",
    "    # Model Compiler\n",
    "    \"init_params\" : \"/home/mappers/data/models/v1/model_path.rar\",\n",
    "    \"gpus\" : [0],\n",
    "    \"input_dims\" : (4, 11),\n",
    "    \"LSTM_hidden_dim\" : (48, 64),\n",
    "    \"CNN_hidden_dim\" : (48, 64),\n",
    "    \"CNN_kernel_size\" : (5, 5),\n",
    "    \"CNN_sequence_length\" : (57, 67),\n",
    "    \"n_classes\": 4,\n",
    "    \"n_LSTM_layers\" : (2, 4),\n",
    "    \"LSTM_lyr_dropout_rate\" : (0.4, 0.5),\n",
    "    \"CNN_lyr_dropout_rate\" : (0.25, 0.45),\n",
    "    \"s1_weight\" : 0.5,\n",
    "    \n",
    "    # Model fitting\n",
    "    \"epoch\" : 75,\n",
    "    \"optimizer\" : \"amsgrad\",\n",
    "    \"momentum\" : 0.95,\n",
    "    \"criterion\" : nn.CrossEntropyLoss,\n",
    "    \"branch_weights\" : (0.3, 0,3, 0.4),\n",
    "    \"lr_init\" : 0.01,\n",
    "    \"LR_policy\" : \"\",\n",
    "    \n",
    "    \"bucket\" : None,\n",
    "    \"save_fldr\": \"model_path\",\n",
    "    \"prefix_out\": \"/home/mappers/data/predictions/croptypes/v1/\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d1d5530-e011-4276-b261-fbb2ee571f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'working_dir': 'C:/My_documents/CropTypeData_Rustowicz/working_folder',\n",
       " 'out_dir': 'new_try_01',\n",
       " 'root_dir': 'C:/My_documents/CropTypeData_Rustowicz/CropType',\n",
       " 'sampling_strategy': 'ranked',\n",
       " 'lbl_fldrname': 'Labels',\n",
       " 'sources': ['Sentinel-1', 'Sentinel-2'],\n",
       " 'num_train_pixels': 15000,\n",
       " 'num_validation_pixels': 10000,\n",
       " 'test_label': False,\n",
       " 'batch_train': 128,\n",
       " 'batch_val': 1,\n",
       " 'init_params': '/home/mappers/data/models/v1/model_path.rar',\n",
       " 'gpus': [0],\n",
       " 'input_dims': (4, 11),\n",
       " 'LSTM_hidden_dim': (48, 64),\n",
       " 'CNN_hidden_dim': (48, 64),\n",
       " 'CNN_kernel_size': (5, 5),\n",
       " 'CNN_sequence_length': (57, 67),\n",
       " 'n_classes': 4,\n",
       " 'n_LSTM_layers': (2, 4),\n",
       " 'LSTM_lyr_dropout_rate': (0.4, 0.5),\n",
       " 'CNN_lyr_dropout_rate': (0.25, 0.45),\n",
       " 's1_weight': 0.5,\n",
       " 'epoch': 75,\n",
       " 'optimizer': 'amsgrad',\n",
       " 'momentum': 0.95,\n",
       " 'criterion': torch.nn.modules.loss.CrossEntropyLoss,\n",
       " 'branch_weights': (0.3, 0, 3, 0.4),\n",
       " 'lr_init': 0.01,\n",
       " 'LR_policy': '',\n",
       " 'bucket': None,\n",
       " 'save_fldr': 'model_path',\n",
       " 'prefix_out': '/home/mappers/data/predictions/croptypes/v1/'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e25939c-0e3a-476a-9f05-720cbf889a32",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d5b84d-f8e6-44ba-b5e5-947b378cac43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double_branch_stacked_biLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf73d72-3b3c-429c-8ab4-cf985c6248d9",
   "metadata": {},
   "source": [
    "### Set-up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b53f8b3-bdd4-4065-a746-78195284a34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "lstm_model = Double_branch_stacked_biLSTM(\n",
    "    input_dims = config[\"input_dims\"],\n",
    "    hidden_dims = config[\"LSTM_hidden_dim\"], \n",
    "    n_classes = config[\"n_classes\"], \n",
    "    n_layers = config[\"n_LSTM_layers\"], \n",
    "    dropout_rate = config[\"LSTM_lyr_dropout_rate\"], \n",
    "    s1_weight = config[\"s1_weight\"], \n",
    "    bidirectional = True, \n",
    "    use_layernorm = True, \n",
    "    use_batchnorm = False, \n",
    "    use_attention = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57927200-4412-453c-a242-eb49af5f50f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Double_branch_stacked_biLSTM(\n",
       "  (s1_inlayernorm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
       "  (s1_clayernorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "  (s2_inlayernorm): LayerNorm((11,), eps=1e-05, elementwise_affine=True)\n",
       "  (s2_clayernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (s1_lstm): LSTM(4, 48, num_layers=2, bias=False, batch_first=True, dropout=0.4, bidirectional=True)\n",
       "  (s2_lstm): LSTM(11, 64, num_layers=4, bias=False, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (s1_linear_class): Linear(in_features=192, out_features=4, bias=True)\n",
       "  (s2_linear_class): Linear(in_features=512, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8720f82a-5af5-416c-adae-3e6ca2591332",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ModelCompiler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5703/402557643.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Compile the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model = ModelCompiler(model=lstm_model,\n\u001b[0m\u001b[1;32m      3\u001b[0m                       \u001b[0mworking_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"working_dir\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                       \u001b[0mout_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"out_dir\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                       \u001b[0mgpuDevices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gpus\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ModelCompiler' is not defined"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model = ModelCompiler(model=lstm_model,\n",
    "                      working_dir=config[\"working_dir\"], \n",
    "                      out_dir=config[\"out_dir\"],\n",
    "                      gpuDevices=config[\"gpus\"],\n",
    "                      br_weights = config[\"branch_weights\"],\n",
    "                      params_init=config[\"init_params\"],\n",
    "                      freeze_params=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad0a308-7b36-4639-95cd-240b64f9dbb1",
   "metadata": {},
   "source": [
    "### Load prediction tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb98d432-2d2c-44d8-ac00-29a3112bddb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_pred(usage, item):\n",
    "    dataset = pixelDataset(root_dir = config[\"root_dir\"],\n",
    "                           usage = \"test\",\n",
    "                           sources = config[\"sources\"],\n",
    "                           inference_index = item)\n",
    "    tile = dataset.tile_id\n",
    "    meta = dataset.meta\n",
    "    data_loader = DataLoader(dataset, \n",
    "                          batch_size=config[\"batch_val\"], \n",
    "                          shuffle = False)\n",
    "    \n",
    "    return data_loader, meta, tile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8609447d-abf5-4d1d-8fbd-b2a59b925037",
   "metadata": {},
   "source": [
    "### Run predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62117e21-9044-4ae5-9be5-9d2601ac32f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "s1_pth = '/home/mappers/data/tiles/s1/source_s1_539059.npy'\n",
    "s1_array = np.load(s1_pth)\n",
    "\n",
    "s2_pth = '/home/mappers/data/tiles/s2/source_s2_539059.npy'\n",
    "s2_array = np.load(s2_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d25e53d1-2326-4606-a952-96fecddb430e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s1_array[0, 0:550, 0:550, 2]\n",
    "# s2_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca80b06a-7ab0-46ba-abc8-3ecee9008033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s2_array[10, 0:550, 0:550, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee448fcc-4983-4062-916e-a7633278cc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_dir = Path(config[root_dir]).joinpath(\n",
    "    \"prediction_tiles\", config[\"sources\"][0]\n",
    ")\n",
    "s1_fnames = [Path(dirpath) / f for (dirpath, dirnames, filenames) \\\n",
    "             in os.walk(prediction_dir) for f in filenames \\\n",
    "             if f.endswith(\".npy\")]\n",
    "tile_count = len(s1_fnames)\n",
    "\n",
    "for i in range(tile_count):\n",
    "    pred_data = load_data_pred(\"test\", i)\n",
    "    model.inference(pred_data, config[\"prefix_out\"])a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9372df1-bba4-437e-a187-474787ce8b42",
   "metadata": {},
   "source": [
    "## Filter predictions through field boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf71f9c-a1b7-4d0c-850c-c69fbb9e59aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
