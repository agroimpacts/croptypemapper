{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "from random import shuffle\n",
    "import gc\n",
    "import math\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from collections import Counter, defaultdict, OrderedDict\n",
    "import urllib.parse as urlparse\n",
    "import boto3\n",
    "import shutil\n",
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "from numpy import inf\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import rasterio\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "import torch.utils.data\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "import torch.nn.utils.rnn as rnn_util\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PyTorch version: {}\".format(torch.__version__))\n",
    "print(\"Cuda version : {}\".format(torch.version.cuda))\n",
    "print('CUDNN version:', torch.backends.cudnn.version())\n",
    "print('Number of available GPU Devices:', torch.cuda.device_count())\n",
    "print(\"current GPU Device: {}\".format(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_reproducable(seed = 42, cudnn = True):\n",
    "    \"\"\"Make all the randomization processes start from a shared seed\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    if cudnn:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "make_reproducable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Making the raw dataset, analysis-ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Rename the data such that the gridIDs in the filenames have leading zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def rename_w_leading_0s(root_dir, tif_content, num_digits, ftype, country, source, verbose = False):\n",
    "    \"\"\"\n",
    "    Renames grid IDs with leading 0's so that sorting of filenames is in ascending order\n",
    "    \n",
    "    root_dir (str) -- path to the main directory which data resides. Example: \"C:/My_documents/Data\".\n",
    "    tif_content (str) -- Seperate between Labels (mask) and img data (data).\n",
    "    num_digits (int) -- Decide on the number of digits to represent a Grid-ID. Default id 6.\n",
    "    ftype (str) -- identifies format of the file to be renamed.\n",
    "    country (str) -- This is based on the organization of dataset that images and \n",
    "                     labels reside inside a country folder.\n",
    "    source (str) -- folder name of the resource. It can be either the remote sensing sensor used to\n",
    "                    acquire the image dataset or the label dataset.\n",
    "    verbose (Binary) -- If set to True, prints a report of old and new names on screen. Default is False.\n",
    "    \"\"\"\n",
    "    assert tif_content in [\"mask\", \"data\"]\n",
    "    assert country in [\"SouthSudan\", \"Ghana\"]\n",
    "    assert source in [\"Sentinel-1\", \"Sentinel-2\", \"Labels\"]\n",
    "    \n",
    "    path_to_src = Path(root_dir) / country / source\n",
    "    old_fname = []\n",
    "    new_fname = []\n",
    "    \n",
    "    if tif_content == \"mask\":\n",
    "        for dirname in os.listdir(path_to_src):\n",
    "            gridID = str(dirname).split(\"_\")[-1]\n",
    "            \n",
    "            for filename in os.listdir(path_to_src / dirname):\n",
    "                \n",
    "                if ftype == \"tif\":\n",
    "                    \n",
    "                    if filename.endswith(\".tif\"):\n",
    "                        old_fname += [path_to_src / dirname / filename]\n",
    "                        new_name = filename.replace(\".tif\", \"_\" + gridID).zfill(num_digits) + \".tif\"\n",
    "                        new_fname += [path_to_src / dirname / new_name]\n",
    "                \n",
    "                elif ftype == \"npy\":\n",
    "                    \n",
    "                    if filename.endswith(\".npy\"):\n",
    "                        old_fname += [path_to_src / dirname / filename]\n",
    "                        new_name = filename.replace(\".npy\", \"_\" + gridID).zfill(num_digits) + \".npy\"\n",
    "                        new_fname += [path_to_src / dirname / new_name]\n",
    "                    \n",
    "                    elif filename.endswith(\".json\"):\n",
    "                        old_fname += [path_to_src / dirname / filename]\n",
    "                        new_name = filename.replace(\".json\", \"_\" + gridID).zfill(num_digits) + \".json\"\n",
    "                        new_fname += [path_to_src / dirname / new_name]\n",
    "    \n",
    "    elif tif_content == 'data':\n",
    "        \n",
    "        for dirname in os.listdir(path_to_src):\n",
    "            string_list = str(dirname).split(\"_\")[-5:]\n",
    "            string_list[1] = string_list[1].zfill(num_digits)\n",
    "            replace_string = '_'.join(string_list)\n",
    "            \n",
    "            for filename in os.listdir(path_to_src / dirname):\n",
    "                \n",
    "                if filename.endswith(\".tif\"):\n",
    "                    old_fname += [path_to_src / dirname / filename]\n",
    "                    new_name = filename.replace(\".tif\", \"_\" + replace_string) + \".tif\"\n",
    "                    new_fname += [path_to_src / dirname / new_name]\n",
    "                \n",
    "                elif filename.endswith(\".json\"):\n",
    "                    old_fname += [path_to_src / dirname / filename]\n",
    "                    new_name = filename.replace(\".json\", \"_\" + replace_string) + \".json\"\n",
    "                    new_fname += [path_to_src / dirname / new_name]\n",
    "    \n",
    "    for i,j in zip(old_fname, new_fname):\n",
    "        os.rename(i, j)\n",
    "        if verbose:\n",
    "            print('Renaming {} to {}'.format(i, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "root_dir = \"E:/CropType\"\n",
    "tif_content = \"data\"\n",
    "num_digits = 6\n",
    "ftype = \"tif\"\n",
    "country = \"Ghana\"\n",
    "source = \"Sentinel-2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rename_w_leading_0s(root_dir, tif_content, num_digits, ftype, country, source, verbose = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Remove those Grid-IDs where there is no actual label recorded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pickle\n",
    "import rasterio\n",
    "from collections import Counter\n",
    "import json\n",
    "\"\"\"\n",
    "\n",
    "def get_grid_nums(root_dir, country, source, ftype, verbose = False):\n",
    "    \n",
    "    src_path = Path(root_dir) / country / source\n",
    "    \n",
    "    if ftype == \"tif\":\n",
    "        files = [Path(dirpath) / f for (dirpath, dirnames, filenames) in os.walk(src_path) for \\\n",
    "                 f in filenames if f.endswith(\".tif\")]\n",
    "        files.sort()\n",
    "        \n",
    "        if country == \"Ghana\":\n",
    "            grid_numbers = [str(f).split(\"_\")[-4] for f in files]\n",
    "        \n",
    "        elif country == \"SouthSudan\":\n",
    "            grid_numbers = [str(f).split(\"_\")[-3] for f in files]\n",
    "    \n",
    "    elif ftype == \"npy\":\n",
    "        files = [Path(dirpath) / f for (dirpath, dirnames, filenames) in os.walk(src_path) for \\\n",
    "                 f in filenames if f.endswith(\".npy\") or f.endswith(\".json\")]\n",
    "        files.sort()\n",
    "        grid_numbers = [str(f).split(\"_\")[-4] for f in files]\n",
    "\n",
    "    grid_numbers.sort()\n",
    "    \n",
    "    if verbose:\n",
    "        for i,j in zip(grid_numbers, files):\n",
    "            print('Grid-ID: {}\\nAssociated file with same ID {}\\n'.format(i, j))\n",
    "    \n",
    "    return grid_numbers, files\n",
    "\n",
    "##################################################\n",
    "\n",
    "def get_empty_grids(root_dir, country, source, lbl_fldrname, verbose = True):\n",
    "    \"\"\"\n",
    "    Provides data from input .tif files depending on function input parameters. \n",
    "    \n",
    "    Args:\n",
    "      directory - (str) the base directory of data\n",
    "      countries - (list of str) list of strings that point to the directory names\n",
    "                  of the different countries (i.e. ['ghana', 'tanzania', 'southsudan'])\n",
    "      sources - (list of str) list of directory of satellite sources (i.e. 's1_64x64', 's2') \n",
    "      verbose - (boolean) prints outputs from function\n",
    "      ext - (str) file type that you are working with (i.e. 'tif', 'npy') \n",
    "   \n",
    "      lbl_dir - (str) the directory name that the raster labels are stored in \n",
    "                      (i.e. 'raster', 'raster_64x64')\n",
    "    \"\"\"\n",
    "\n",
    "    valid_pixels_list = []\n",
    "    empty_masks = []\n",
    "    \n",
    "    lbl_dir = Path(root_dir) / country / lbl_fldrname\n",
    "\n",
    "    mask_fnames = [Path(dirpath) / f for (dirpath, dirnames, filenames) in os.walk(lbl_dir) for \\\n",
    "                   f in filenames if f.endswith('.tif')]\n",
    "    mask_ids = [str(f).split('_')[-1].replace('.tif', '') for f in mask_fnames]\n",
    "\n",
    "    mask_fnames.sort()\n",
    "    mask_ids.sort()\n",
    "    \n",
    "    assert len(mask_fnames) == len(mask_ids)\n",
    "\n",
    "    for mask_fname, mask_id in zip(mask_fnames, mask_ids):\n",
    "        with rasterio.open(mask_fname) as src:\n",
    "            cur_mask = src.read()\n",
    "            valid_pixels = np.sum(cur_mask > 0) \n",
    "            valid_pixels_list.append((mask_id, valid_pixels))\n",
    "            if valid_pixels == 0:\n",
    "                empty_masks.append(mask_id)\n",
    "\n",
    "    delete_me = []\n",
    "    \n",
    "    grid_numbers, source_files = get_grid_nums(root_dir, country, source, ftype, verbose = False)\n",
    "\n",
    "    all_ids = set(empty_masks + grid_numbers)\n",
    "    for el in all_ids:\n",
    "        if el in empty_masks and el in grid_numbers:\n",
    "            delete_me.append(el)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"valid pixels list: \", len(valid_pixels_list))\n",
    "        print('empty masks: ', len(empty_masks))\n",
    "        print('delete me length: ', len(delete_me))\n",
    "        print('delete me: ', delete_me)\n",
    "        \n",
    "    return set(delete_me)\n",
    "\n",
    "##################################################\n",
    "\n",
    "def remove_irrelevant_files(root_dir, country, source, delete_list, ftype, verbose = True):\n",
    "    \n",
    "    if len(delete_list) == 0:\n",
    "        print(\"There is no empty grid to remove.\")\n",
    "    \n",
    "    else:\n",
    "        grid_nums, source_files = get_grid_nums(root_dir, country, source, ftype, verbose = False)\n",
    "    \n",
    "        for grid_to_rm in delete_list:\n",
    "            files_to_rm = [str(f) for f in source_files if ''.join(['_', grid_to_rm]) in str(f)]\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"grid to remove: {}\\n\".format(grid_to_rm))\n",
    "            print(\"files to remove: {}\\n\".format(files_to_rm))\n",
    "        \n",
    "        #Remove files        \n",
    "        [os.remove(f) for f in files_to_rm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "root_dir = \"E:/CropType\"\n",
    "lbl_fldrname = \"Labels\"\n",
    "ftype = \"tif\"\n",
    "country = \"Ghana\"\n",
    "source = \"Sentinel-2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grids_to_delete = get_empty_grids(root_dir, country, source, lbl_fldrname)\n",
    "\n",
    "remove_irrelevant_files(root_dir, country, source, grids_to_delete, ftype, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Normalize tiles, add doy band, add spectral indices to sentinel-2 and create temporal stacks for each grid and save them as .npy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "\n",
    "def normalize(grid, source, country, norm_type = \"z-value\"):\n",
    "    r\"\"\" Normalization based on the chosen normalization type.\n",
    "    Args: \n",
    "      grid (numpy array) -- grid to be normalized.\n",
    "      norm_type (str) -- decide on the type of normalization. either z-value (standardization) or min/max.\n",
    "                         default is z-value.\n",
    "      source (str) -- Satellite sensor.\n",
    "      country (str) -- Geographic region where the dataset is taken.\n",
    "    Returns:\n",
    "      grid (numpy array) -- a normalized version of the input grid.\n",
    "      \n",
    "    NOTE: z-value normalization is based on the statistics of the whole temporal extent for each band.\n",
    "          min/max normalization is based on the statistics of each indivisual grid.\n",
    "    \"\"\"\n",
    "    \n",
    "    MEANS = {\"Sentinel-1\": {\"Ghana\": np.array([-10.50, -17.24, 1.17])}, \n",
    "             \"Sentinel-2\": {\"Ghana\": np.array([2620.00, 2519.89, 2630.31, 2739.81, 3225.22, \n",
    "                                               3562.64, 3356.57, 3788.05, 2915.40, 2102.65])}\n",
    "            }\n",
    "\n",
    "\n",
    "    STDS = {\"Sentinel-1\": {\"Ghana\": np.array([3.57, 4.86, 5.60])}, \n",
    "            \"Sentinel-2\": {\"Ghana\": np.array([2171.62, 2085.69, 2174.37, 2084.56, 2058.97, \n",
    "                                              2117.31, 1988.70, 2099.78, 1209.48, 918.19])}\n",
    "           }\n",
    "    \n",
    "    num_bands = grid.shape[0]\n",
    "    \n",
    "    if norm_type == \"z-value\":\n",
    "        means = MEANS[source][country]\n",
    "        stds = STDS[source][country]\n",
    "        \n",
    "        for i in range(num_bands):\n",
    "            grid[i,:,:] = (grid[i,:,:] - means[i]) / stds[i]\n",
    "    \n",
    "    elif norm_type == \"min/max\":\n",
    "        nan_Corr_grid = np.where(grid == 0, np.nan, grid)\n",
    "        grid_min = np.nanmin(nan_Corr_grid)\n",
    "        grid_max = np.nanmax(nan_Corr_grid)\n",
    "        grid = (grid  - grid_min) / (grid_max - grid_min)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Normlaization type is not recognized.\")\n",
    "    \n",
    "    return grid\n",
    "\n",
    "##################################################\n",
    "\n",
    "def date2doy(date, in_shp):\n",
    "    r\"\"\"\n",
    "    Convert string dates to equivalent day of the year and convert it to a Z-norm.\n",
    "    \n",
    "    Parameters:\n",
    "        date_list (list of string) -- list of dates read from a .json file.\n",
    "        in_shape (tuple or None) -- If 'none' just make a vector of day of the year with the length equal to the sequence length.\n",
    "                                    Otherwise day of the year will be broadcasted to specified shape.\n",
    "    Output: Z-norm day of the year band in specified shape\n",
    "    \"\"\"\n",
    "    #set_trace()\n",
    "    date = datetime.strptime(date, '%Y_%m_%d').date()\n",
    "    doy = date.timetuple().tm_yday\n",
    "    doy = np.array([doy])\n",
    "    \n",
    "    # normalize\n",
    "    norm_doy = (doy - 177.5) / 177.5\n",
    "\n",
    "    C, W, H = in_shp\n",
    "        \n",
    "    stack = norm_doy[np.newaxis,:]\n",
    "    stack = np.broadcast_to(stack,(W,H))\n",
    "    stack = stack[np.newaxis,:]\n",
    "\n",
    "    return stack\n",
    "\n",
    "##################################################\n",
    "\n",
    "def get_spectral_indices(img, Channel_first = True):\n",
    "\n",
    "    #set_trace()\n",
    "    ch = img.shape[0] if Channel_first else img.shape[-1]\n",
    "    assert ch == 10, \"Either Number of bands are incorrect or its not located in first or last dimensions.\"\n",
    "\n",
    "    # B1, B2,\n",
    "    S2_BANDS = {\"BLUE\": 0, \"GREEN\": 1, \"RED\": 2, \"RDED1\": 3, \"RDED2\": 4, \"RDED3\": 5, \"NIR\": 6, \"RDED4\": 7, \"SWIR1\": 8, \"SWIR2\": 9}\n",
    "    \n",
    "    G = 2.5 \n",
    "    C1 = 6\n",
    "    C2 = 7.5\n",
    "    L= 0.5\n",
    "\n",
    "    if Channel_first:\n",
    "        blue = img[S2_BANDS[\"BLUE\"], :, :]\n",
    "        green = img[S2_BANDS[\"GREEN\"], :, :]\n",
    "        red = img[S2_BANDS[\"RED\"], :, :]\n",
    "        nir = img[S2_BANDS[\"NIR\"], :, :]\n",
    "        rded1 = img[S2_BANDS[\"RDED1\"], :, :]\n",
    "        rded2 = img[S2_BANDS[\"RDED2\"], :, :]\n",
    "        rded3 = img[S2_BANDS[\"RDED3\"], :, :]\n",
    "        swir1 = img[S2_BANDS[\"SWIR1\"], :, :]\n",
    "        rded4 = img[S2_BANDS[\"RDED4\"], :, :]\n",
    "        swir2 = img[S2_BANDS[\"SWIR2\"], :, :]\n",
    "        \n",
    "    else:\n",
    "        blue = img[:, :, S2_BANDS[\"BLUE\"]]\n",
    "        green = img[:, :, S2_BANDS[\"GREEN\"]]\n",
    "        red = img[:, :, S2_BANDS[\"RED\"]]\n",
    "        nir = img[:, :, S2_BANDS[\"NIR\"]]\n",
    "        rded1 = img[:, :, S2_BANDS[\"RDED1\"]]\n",
    "        rded2 = img[:, :, S2_BANDS[\"RDED2\"]]\n",
    "        rded3 = img[:, :, S2_BANDS[\"RDED3\"]]\n",
    "        swir1 = img[:, :, S2_BANDS[\"SWIR1\"]]\n",
    "        rded3 = img[:, :, S2_BANDS[\"RDED4\"]]\n",
    "        swir2 = img[:, :, S2_BANDS[\"SWIR2\"]]\n",
    "        \n",
    "    # Normalized Difference Vegetation Index\n",
    "    ndvi = (nir - red) / (nir + red)\n",
    "    \n",
    "    # Enhanced Vegetation Index\n",
    "    evi = G * (nir - red) / (nir + C1 * red - C2 * blue + 1)\n",
    "    \n",
    "    # Normalized Difference Water Index\n",
    "    ndwi = (nir - swir2) / (nir + swir2)\n",
    "    \n",
    "    #Absorption properties of the middle infrared band cause a low reflectance of rice plants in this channel (Lilliesand & Kiefer 1994). \n",
    "    #In irrigated rice fields, especially in early transplanting periods, water environment plays an important role in rice spectral.\n",
    "    # Nuarsa, I. W., Nishio, F., & Hongo, C. (2011). Spectral characteristics and mapping of rice plants using multi-temporal Landsat data. Journal of Agricultural Science.\n",
    "    # Rice Growth Vegetation Index\n",
    "    rgvi = 1 - (blue + red) / (nir + swir1 + swir2)\n",
    "    \n",
    "    bi = np.sqrt(((red * red) / (green * green)) / 2)\n",
    "\n",
    "    stack = np.dstack([ndvi, evi, ndwi, rgvi, bi]).transpose(2,0,1)\n",
    "\n",
    "    return stack\n",
    "\n",
    "##################################################\n",
    "\n",
    "\"\"\"\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pickle\n",
    "import rasterio\n",
    "from collections import Counter\n",
    "import json\n",
    "\"\"\"\n",
    "\n",
    "def get_img_cube(root_dir, country, source, out_format, lbl_fldrname, verbose):\n",
    "    \n",
    "    #set_trace()\n",
    "    # Path to \"Label\" folder which contains label tiles. \n",
    "    lbl_dir = Path(root_dir) / country / lbl_fldrname\n",
    "    lbl_fnames = [Path(dirpath) / f for (dirpath, dirnames, filenames) in os.walk(lbl_dir) for f in filenames if f.endswith(\".tif\")]\n",
    "    lbl_ids = [str(f).split(\"_\")[-1].replace(\".tif\", \"\") for f in lbl_fnames]\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Number of grids for country {}: {}\".format(country, len(lbl_ids)))\n",
    "    \n",
    "    # Path to \"source\" folder which contains img tiles.\n",
    "    src_path = Path(root_dir) / country / source\n",
    "    \n",
    "    out_path = src_path / out_format\n",
    "    Path(out_path).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # List of img tiles for the current source (RS sensor) and get the Grid-ID of each img tile..\n",
    "    files = [Path(dirpath) / f for (dirpath, dirnames, filenames) in os.walk(src_path) for f in filenames if f.endswith(\".tif\") if \"source\" in f]\n",
    "    grid_numbers = [str(f).split(\"_\")[-4] for f in files]\n",
    "    \n",
    "    if source == \"Sentinel-2\":\n",
    "        # cloud_mask categories --> {\"clear\":0, \"cloud\":1, \"haze\":2, \"shadow\":3}\n",
    "        cloud_masks = [Path(dirpath) / f for (dirpath, dirnames, filenames) in os.walk(src_path) for f in filenames if f.endswith(\".tif\") if \"cloudmask\" in f]\n",
    "        cloud_masks.sort()\n",
    "    \n",
    "    files.sort()\n",
    "    grid_numbers.sort()\n",
    "    \n",
    "    # read one image from list to get dimensions\n",
    "    with rasterio.open(files[0]) as src:\n",
    "        img = src.read()\n",
    "    \n",
    "    if out_format == \"pickle\":\n",
    "        # dimensions: grids x bands x rows x columns x timestamps\n",
    "        data_array = np.zeros((len(set(grid_numbers)), img.shape[0], img.shape[1], \n",
    "                               img.shape[2], Counter(grid_numbers).most_common(1)[0][1]))\n",
    "        g, b, r, c, t = data_array.shape\n",
    "        \n",
    "    if verbose:\n",
    "        print(\"-----------------------------\")\n",
    "        print(\"Image dimensions: {}\".format(img.shape))\n",
    "        print(\"Current data source: {}\".format(source))\n",
    "        print(\"Number of grids in set: {}\".format(len(set(grid_numbers))))\n",
    "        print(\"Set of grid numbers: {}\".format(sorted(set(grid_numbers))))\n",
    "        print(\"Maximum timestamps from this data source: {}\".format(Counter(grid_numbers).most_common(1)[0][1]))\n",
    "        if out_format == \"pickle\":\n",
    "            print(\"Final array shape: {}\".format(data_array.shape))\n",
    "            \n",
    "    for grid_idx, grid in enumerate(sorted(set(grid_numbers))):\n",
    "        if verbose:\n",
    "            print(\"Grid: {}\".format(grid))\n",
    "        cur_grid_files = [str(f) for f in files if \"_\" + grid + \"_\" in str(f)]\n",
    "        cur_grid_files.sort()\n",
    "        \n",
    "        if source == \"Sentinel-2\":\n",
    "            cur_mask_files = [str(f) for f in cloud_masks if \"_\" + grid + \"_\" in str(f)]\n",
    "            cur_mask_files.sort()\n",
    "    \n",
    "            if out_format == \"npy\":\n",
    "                # dimensions: bands x rows x columns x timestamps\n",
    "                data_array = np.zeros((img.shape[0]+6, img.shape[1], img.shape[2], len(cur_grid_files)))\n",
    "                mask_array = np.zeros((img.shape[0]+6, img.shape[1], img.shape[2], len(cur_mask_files)))\n",
    "        \n",
    "        if source == \"Sentinel-1\" and out_format == \"npy\":\n",
    "            data_array = np.zeros((img.shape[0]+1, img.shape[1], img.shape[2], len(cur_grid_files)))\n",
    "        \n",
    "        dates = []\n",
    "\n",
    "        if source == \"Sentinel-2\":\n",
    "            for idx, (fname, mname) in enumerate(zip(cur_grid_files, cur_mask_files)):\n",
    "                if verbose:\n",
    "                    print(\"idx: \", idx)\n",
    "                    print(\"fname: \", fname)\n",
    "                    print(\"mname: \", mname)\n",
    "        \n",
    "                with rasterio.open(fname) as src:\n",
    "                    tile = src.read()\n",
    "                    tile = tile.astype(float)\n",
    "                    if out_format == \"pickle\":\n",
    "                        data_array[grid_idx, :, :, :, idx] = normalize(tile, source, country, norm_type = \"z-value\")\n",
    "            \n",
    "                    elif out_format == \"npy\":\n",
    "                        tmp = Path(fname).name.replace(\".tif\", \"\").split(\"_\")\n",
    "                        date_parts = tmp[-3:]\n",
    "                        date = \"_\".join(date_parts)\n",
    "                        dates.append(date)\n",
    "                        \n",
    "                        si_bands = get_spectral_indices(tile, Channel_first = True)\n",
    "                        normal_tile = normalize(tile, source, country, norm_type = \"z-value\")\n",
    "                        doy_band = date2doy(date, tile.shape)\n",
    "                        aug_array = np.concatenate([normal_tile, si_bands, doy_band], axis = 0)\n",
    "                        \n",
    "                        data_array[:, :, :, idx] = aug_array\n",
    "                        #data_array[:, :, :, idx] = normalize(tile, source, country, norm_type = \"z-value\")\n",
    "                        \n",
    "                        \n",
    "                        with rasterio.open(mname) as msrc:\n",
    "                            mask_array[:, :, :, idx] = msrc.read()\n",
    "    \n",
    "            if out_format == \"npy\":\n",
    "                tmp_fn = Path(fname).name.replace(\".tif\", \"\").split(\"_\")\n",
    "                fn = \"_\".join(tmp_fn[0:3])\n",
    "                out_fname = out_path / fn\n",
    "                \n",
    "                tmp_mn = Path(mname).name.replace(\".tif\", \"\").split(\"_\")\n",
    "                mn = \"_\".join(tmp_mn[0:3])\n",
    "                out_mname = out_path / mn\n",
    "    \n",
    "                # store and save metadata\n",
    "                meta = {}\n",
    "                meta[\"dates\"] = dates\n",
    "    \n",
    "                with open(str(out_fname) + \".json\", \"w\") as fp:\n",
    "                    json.dump(meta, fp)\n",
    "    \n",
    "                # save image stack as .npy\n",
    "                np.save(out_fname, data_array)\n",
    "                np.save(out_mname, mask_array)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            for idx, fname in enumerate(cur_grid_files):\n",
    "                \n",
    "                if verbose:\n",
    "                    print(\"idx: \", idx)\n",
    "                    print(\"fname: \", fname)\n",
    "        \n",
    "                with rasterio.open(fname) as src:\n",
    "                    s1_tile = src.read()\n",
    "                    s1_tile = s1_tile.astype(float)\n",
    "                    \n",
    "                    if out_format == \"pickle\":\n",
    "                        data_array[grid_idx, :, :, :, idx] = normalize(s1_tile, source, country, norm_type = \"z-value\")\n",
    "            \n",
    "                    elif out_format == \"npy\":\n",
    "                        \n",
    "                        tmp = Path(fname).name.replace(\".tif\", \"\").split(\"_\")\n",
    "                        date_parts = tmp[-3:]\n",
    "                        date = \"_\".join(date_parts)\n",
    "                        dates.append(date)\n",
    "                        \n",
    "                        normal_tile = normalize(s1_tile, source, country, norm_type = \"z-value\")\n",
    "                        doy_band = date2doy(date, s1_tile.shape)\n",
    "                        \n",
    "                        aug_array = np.concatenate([normal_tile, doy_band], axis = 0)\n",
    "                        \n",
    "                        data_array[:, :, :, idx] = aug_array\n",
    "                        #data_array[:, :, :, idx] = normalize(tile, source, country, norm_type = \"z-value\")\n",
    "                        \n",
    "            \n",
    "            if out_format == \"npy\":\n",
    "                tmp_fn = Path(fname).name.replace(\".tif\", \"\").split(\"_\")\n",
    "                fn = \"_\".join(tmp_fn[0:3])\n",
    "                out_fname = out_path / fn\n",
    "    \n",
    "                # store and save metadata\n",
    "                meta = {}\n",
    "                meta[\"dates\"] = dates\n",
    "    \n",
    "                with open(str(out_fname) + \".json\", \"w\") as fp:\n",
    "                    json.dump(meta, fp)\n",
    "    \n",
    "                # save image stack as .npy\n",
    "                np.save(out_fname, data_array)\n",
    "\n",
    "        \n",
    "    if out_format == \"pickle\":\n",
    "        out_fname = \"_\".join([country, source, \"shape\", \"g\" + str(g), \"b\" + str(b), \"r\" + str(r), \"c\" + str(c), \"t\" + str(t) + \".pickle\"])\n",
    "        \n",
    "        with open(str(out_path / out_fname), \"wb\") as f:\n",
    "            pickle.dump((sorted(set(grid_numbers)), data_array), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "root_dir = \"E:/CropType\"\n",
    "#root_dir = \"C:/My_documents/Data\"\n",
    "lbl_fldrname = \"Labels\"\n",
    "out_format = \"npy\"\n",
    "country = \"Ghana\"\n",
    "source = \"Sentinel-2\"\n",
    "verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "get_img_cube(root_dir, country, source, out_format, lbl_fldrname, verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Find tiles with NaN value on SI and zero on image bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def findTilesWithNan(root_dir, country, source, lbl_fldrname):\n",
    "    #set_trace()\n",
    "    lbl_dir = Path(root_dir) / country / lbl_fldrname \n",
    "    lbl_fnames = [Path(dirpath) / f for (dirpath, dirnames, filenames) in os.walk(lbl_dir) for \\\n",
    "                  f in filenames if f.endswith(\".tif\")]\n",
    "\n",
    "    src_path = Path(root_dir) / country / source / \"npy\"\n",
    "    fnames = [Path(dirpath) / f for (dirpath, dirnames, filenames) in os.walk(src_path) for f in filenames if f.endswith(\".npy\") if \"source\" in f]\n",
    "    meta_fnames = [Path(dirpath) / f for (dirpath, dirnames, filenames) in os.walk(src_path) for f in filenames if f.endswith(\".json\")]\n",
    "    \n",
    "    lbl_fnames.sort()\n",
    "    fnames.sort()\n",
    "    meta_fnames.sort()\n",
    "\n",
    "    \n",
    "    if source == \"Sentinel-2\":\n",
    "        cloud_masks = [Path(dirpath) / f for (dirpath, dirnames, filenames) in os.walk(src_path) for f in filenames if f.endswith(\".npy\") if \"cloudmask\" in f]\n",
    "        cloud_masks.sort()\n",
    "    \n",
    "    src_out_path = src_path / \"chips_contain_nan\"\n",
    "    lbl_out_path = lbl_dir / \"chips_contain_nan\"\n",
    "    \n",
    "    dirs = [src_out_path, lbl_out_path]\n",
    "    \n",
    "    MEANS = {\"Sentinel-1\": {\"Ghana\": np.array([-10.50, -17.24, 1.17])}, \n",
    "             \"Sentinel-2\": {\"Ghana\": np.array([2620.00, 2519.89, 2630.31, 2739.81, 3225.22, \n",
    "                                               3562.64, 3356.57, 3788.05, 2915.40, 2102.65])}\n",
    "            }\n",
    "\n",
    "\n",
    "    STDS = {\"Sentinel-1\": {\"Ghana\": np.array([3.57, 4.86, 5.60])}, \n",
    "            \"Sentinel-2\": {\"Ghana\": np.array([2171.62, 2085.69, 2174.37, 2084.56, 2058.97, \n",
    "                                              2117.31, 1988.70, 2099.78, 1209.48, 918.19])}\n",
    "           }\n",
    "    \n",
    "    means = MEANS[source][country]\n",
    "    stds = STDS[source][country]\n",
    "    \n",
    "    \n",
    "    comparison_array = (-1 * means) / stds\n",
    "    \n",
    "    for p in dirs:\n",
    "        if not os.path.exists(p):\n",
    "            os.makedirs(p)\n",
    "    \n",
    "    nan_grids_list = []\n",
    "    if source == \"Sentinel-1\":\n",
    "        for fn, meta_fn, lbl_fn in zip(fnames, meta_fnames, lbl_fnames):\n",
    "            grid_id = str(fn).split(\"_\")[-1].replace(\".npy\", \"\")\n",
    "            src_array = np.load(fn)\n",
    "            num_nans = np.count_nonzero(np.isnan(src_array))\n",
    "            num_zeros = np.count_nonzero(np.isin(src_array, comparison_array))\n",
    "        \n",
    "            if num_nans > 0:\n",
    "                print(\"Grid ID: {} with {} number of NaN in indices and {} zero values in image band is moved.\".format(grid_id, num_nans, num_zeros))\n",
    "                nan_grids_list.append(grid_id)\n",
    "                #shutil.move(str(fn), str(src_out_path))\n",
    "                #shutil.move(str(meta_fn), str(src_out_path))\n",
    "                #shutil.move(str(lbl_fn), str(lbl_out_path))\n",
    "    else:\n",
    "        for fn, meta_fn, cmask_fn, lbl_fn in zip(fnames, meta_fnames, cloud_masks, lbl_fnames):\n",
    "            grid_id = str(fn).split(\"_\")[-1].replace(\".npy\", \"\")\n",
    "            src_array = np.load(fn)\n",
    "            num_nans = np.count_nonzero(np.isnan(src_array))\n",
    "            num_zeros = np.count_nonzero(np.isin(src_array, comparison_array))\n",
    "        \n",
    "            if num_nans > 0:\n",
    "                print(\"Grid ID: {} with {} number of NaN in indices and {} zero values in image band is moved.\".format(grid_id, num_nans, num_zeros))\n",
    "                nan_grids_list.append(grid_id)\n",
    "                #shutil.move(str(fn), str(src_out_path))\n",
    "                #shutil.move(str(cmask_fn), str(src_out_path))\n",
    "                #shutil.move(str(meta_fn), str(src_out_path))\n",
    "                #shutil.move(str(lbl_fn), str(lbl_out_path))\n",
    "    return nan_grids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def MoveTilesWithNan(root_dir, country, lbl_fldrname, verbose = True):\n",
    "    #set_trace()\n",
    "    lbl_dir = Path(root_dir) / country / lbl_fldrname / \"reclass\" \n",
    "    lbl_fnames = [Path(dirpath) / f for (dirpath, dirnames, filenames) in os.walk(lbl_dir) for f in filenames if f.endswith(\".tif\")]\n",
    "\n",
    "    s1_path = Path(root_dir) / country / \"Sentinel-1\" / \"npy\"\n",
    "    s1_fnames = [Path(dirpath) / f for (dirpath, dirnames, filenames) in os.walk(s1_path) for f in filenames if f.endswith(\".npy\") if \"source\" in f]\n",
    "    s1_meta_fnames = [Path(dirpath) / f for (dirpath, dirnames, filenames) in os.walk(s1_path) for f in filenames if f.endswith(\".json\")]\n",
    "    s2_path = Path(root_dir) / country / \"Sentinel-2\" / \"npy\"\n",
    "    s2_fnames = [Path(dirpath) / f for (dirpath, dirnames, filenames) in os.walk(s2_path) for f in filenames if f.endswith(\".npy\") if \"source\" in f]\n",
    "    s2_meta_fnames = [Path(dirpath) / f for (dirpath, dirnames, filenames) in os.walk(s2_path) for f in filenames if f.endswith(\".json\")]\n",
    "    cloud_masks = [Path(dirpath) / f for (dirpath, dirnames, filenames) in os.walk(s2_path) for f in filenames if f.endswith(\".npy\") if \"cloudmask\" in f]\n",
    "    \n",
    "    assert len(s1_fnames) == len(s2_fnames) == len(lbl_fnames) == len(s1_meta_fnames) == len(s1_meta_fnames) == len(cloud_masks)\n",
    "    lbl_fnames.sort()\n",
    "    s1_fnames.sort()\n",
    "    s1_meta_fnames.sort()\n",
    "    s2_fnames.sort()\n",
    "    s2_meta_fnames.sort()\n",
    "    cloud_masks.sort()\n",
    "\n",
    "    s1_out_path = s1_path / \"chips_contain_nan\"\n",
    "    s2_out_path = s2_path / \"chips_contain_nan\"\n",
    "    lbl_out_path = lbl_dir / \"chips_contain_nan\"\n",
    "    ext_file_path = Path(root_dir) / country / \"detailed_report\"\n",
    "    \n",
    "    dirs = [s1_out_path, s2_out_path, lbl_out_path, ext_file_path]\n",
    "    \n",
    "    for p in dirs:\n",
    "        if not os.path.exists(p):\n",
    "            os.makedirs(p)\n",
    "\n",
    "    nan_grids_list = []\n",
    "    for s1_fn, s1_meta_fn, s2_fn, s2_meta_fn, cmask_fn, lbl_fn in zip(s1_fnames, s1_meta_fnames, s2_fnames, s2_meta_fnames, cloud_masks, lbl_fnames):\n",
    "        \n",
    "        s1_grid_id = str(s1_fn).split(\"_\")[-1].replace(\".npy\", \"\")\n",
    "        s2_grid_id = str(s2_fn).split(\"_\")[-1].replace(\".npy\", \"\")\n",
    "        lbl_grid_id = str(lbl_fn).split(\"_\")[-1].replace(\".tif\", \"\")\n",
    "        assert s1_grid_id == s2_grid_id == lbl_grid_id, \"Grid Id mis-match between Sentinel-1 & 2 chips.\"\n",
    "        \n",
    "        s1_array = np.load(s1_fn)\n",
    "        s2_array = np.load(s2_fn)\n",
    "        \n",
    "        s1_num_nans = np.count_nonzero(np.isnan(s1_array))\n",
    "        s2_num_nans = np.count_nonzero(np.isnan(s2_array))\n",
    "        \n",
    "        if (s1_num_nans > 0) or (s2_num_nans > 0):\n",
    "            \n",
    "            \n",
    "            with open(os.path.join(str(ext_file_path), \"NaN_contaminated_tiles.txt\"), \"a\") as external_file:\n",
    "                print(\"Grid ID: {} with {} NaN indices in S1 and {} NaNs for S2 is moved.\".format(s1_grid_id, s1_num_nans, s2_num_nans), file=external_file)\n",
    "            if verbose:\n",
    "                print(\"Grid ID: {} with {} NaN indices in S1 and {} NaNs for S2 is moved.\".format(s1_grid_id, s1_num_nans, s2_num_nans))\n",
    "            \n",
    "            nan_grids_list.append(s1_grid_id)\n",
    "            shutil.move(str(s1_fn), str(s1_out_path))\n",
    "            shutil.move(str(s1_meta_fn), str(s1_out_path))\n",
    "            shutil.move(str(s2_fn), str(s2_out_path))\n",
    "            shutil.move(str(s2_meta_fn), str(s2_out_path))\n",
    "            shutil.move(str(cmask_fn), str(s2_out_path))\n",
    "            shutil.move(str(lbl_fn), str(lbl_out_path))\n",
    "    \n",
    "    external_file.close()\n",
    "    return nan_grids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def MoveLabels(root_dir, country, lbl_fldrname, verbose = True):\n",
    "    \n",
    "    #set_trace()\n",
    "    s1_path = Path(root_dir) / country / \"Sentinel-1\" / \"npy\" / \"chips_contain_nan\"\n",
    "    s1_fnames = [Path(dirpath) / f for (dirpath, dirnames, filenames) in os.walk(s1_path) for f in filenames if f.endswith(\".npy\") if \"source\" in f]\n",
    "    s1_fnames.sort()\n",
    "    s1_ids = [str(f).split(\"_\")[-1].replace(\".npy\", \"\") for f in s1_fnames]\n",
    "    \n",
    "    lbl_dir = Path(root_dir) / country / lbl_fldrname / \"reclass\" \n",
    "    lbl_fnames = [Path(dirpath) / f for (dirpath, dirnames, filenames) in os.walk(lbl_dir) for f in filenames if f.endswith(\".tif\")]\n",
    "    lbl_fnames.sort()\n",
    "    \n",
    "\n",
    "    lbl_out_path = lbl_dir / \"chips_contain_nan\"\n",
    "    if not os.path.exists(lbl_out_path):\n",
    "        os.makedirs(lbl_out_path)\n",
    "\n",
    "    for lbl_fn in lbl_fnames:\n",
    "        lbl_grid_id = str(lbl_fn).split(\"_\")[-1].replace(\".tif\", \"\")\n",
    "        if lbl_grid_id in s1_ids:\n",
    "            shutil.move(str(lbl_fn), str(lbl_out_path))\n",
    "\n",
    "            if verbose:\n",
    "                print(\"Label tilw with Grid ID: {} is moved.\".format(lbl_grid_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "root_dir = \"C:/My_documents/CropTypeData_Rustowicz\"\n",
    "country = \"Ghana\"\n",
    "source = \"Sentinel-1\"\n",
    "lbl_fldrname = \"Labels3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "S1_grids_with_nan = findTilesWithNan(root_dir, country, source, lbl_fldrname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "S2_grids_with_nan = findTilesWithNan(root_dir, country, source, lbl_fldrname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "MoveTilesWithNan(root_dir, country, lbl_fldrname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "MoveLabels(root_dir, country, lbl_fldrname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Reclassify Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import rasterio\n",
    "\"\"\"\n",
    "\n",
    "def reclassify_lbl(root_dir, country, lbl_fldrname, categories = None):\n",
    "    #set_trace()\n",
    "    lbl_dir = Path(root_dir) / country / lbl_fldrname\n",
    "    \n",
    "    lbl_fnames = [Path(dirpath) / f for (dirpath, dirnames, filenames) in os.walk(lbl_dir) for \\\n",
    "                  f in filenames if f.endswith(\".tif\")]\n",
    "    \n",
    "    lbl_ids = [str(f).split(\"_\")[-1].replace(\".tif\", \"\") for f in lbl_fnames]\n",
    "    \n",
    "    complete_categories = {\"unknown\": 0, \"ground nut\": 1, \"maize\": 2, \"rice\": 3, \"soya bean\": 4, \"yam\": 5, \n",
    "                           \"intercrop\": 6, \"sorghum\": 7, \"okra\": 8, \"cassava\": 9, \"millet\": 10, \"tomato\": 11, \n",
    "                           \"cowpea\": 12, \"sweet potato\": 13, \"babala beans\": 14, \"salad vegetables\": 15, \n",
    "                           \"bra and ayoyo\": 16, \"watermelon\": 17, \"zabla\": 18, \"nili\": 19, \"kpalika\": 20, \n",
    "                           \"cotton\": 21, \"akata\": 22, \"nyenabe\": 23, \"pepper\": 24}\n",
    "    \n",
    "    for fn in lbl_fnames:\n",
    "        with rasterio.open(fn) as src:\n",
    "            lbl_array = src.read()\n",
    "            \n",
    "            if categories is not None:\n",
    "                \n",
    "                # List of categories that need to be aggregated into the other class.\n",
    "                categories_to_other = list(np.setdiff1d(list(complete_categories.keys()),list(categories.keys())))\n",
    "                # name of the aggregation category usually 'other'.\n",
    "                aggregator_cat = list(np.setdiff1d(list(categories.keys()), list(complete_categories.keys())))\n",
    "                \n",
    "                for category in list(complete_categories.keys()):\n",
    "                    if category in list(categories.keys()):\n",
    "                        lbl_array[lbl_array == complete_categories[category]] = categories[category]\n",
    "                    else:\n",
    "                        if ((category in categories_to_other) and \n",
    "                            (complete_categories[category] != complete_categories[\"unknown\"])):\n",
    "                            lbl_array[lbl_array == complete_categories[category]] = categories[aggregator_cat[0]]\n",
    "                \n",
    "                reclass_lbl_out_path = lbl_dir / \"reclass\"\n",
    "                Path(reclass_lbl_out_path).mkdir(parents=True, exist_ok=True)\n",
    "                \n",
    "                profile = {\n",
    "                    \"driver\": \"GTiff\", \n",
    "                    \"count\": lbl_array.shape[0],\n",
    "                    \"height\": lbl_array.shape[1],\n",
    "                    \"width\": lbl_array.shape[2],\n",
    "                    \"dtype\": \"float64\",\n",
    "                    \"transform\": rasterio.Affine(1, 0, 0, 0, 1, 0),\n",
    "                }\n",
    "                \n",
    "                with rasterio.open(reclass_lbl_out_path / fn.name, \"w\", **profile) as dst:\n",
    "                    dst.write(lbl_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "root_dir = \"C:/My_documents/CropTypeData_Rustowicz\"\n",
    "lbl_fldrname = \"Labels3\"\n",
    "country = \"Ghana\"\n",
    "#categories = {\"unknown\": 0, \"ground nut\": 1, \"maize\": 2, \"rice\": 3, \"soya bean\": 4, \"other\": 5}\n",
    "categories = {\"unknown\": 0, \"maize\": 1, \"other\": 2, \"rice\": 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "reclassify_lbl(root_dir, country, lbl_fldrname, categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Summarize categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "\"\"\"\n",
    "\n",
    "def summarize_lbl(root_dir, country, lbl_fldrname, out_filename, category = None):\n",
    "    \n",
    "    lbl_dir = Path(root_dir) / country / lbl_fldrname / \"validation\"\n",
    "    \n",
    "    lbl_fnames = [Path(dirpath) / f for (dirpath, dirnames, filenames) in os.walk(lbl_dir) for \\\n",
    "                  f in filenames if f.endswith(\".tif\")]\n",
    "    \n",
    "    lbl_ids = [str(f).split(\"_\")[-1].replace(\".tif\", \"\") for f in lbl_fnames]\n",
    "    \n",
    "    if category:\n",
    "        category_dict = category\n",
    "    else:\n",
    "        category_dict = {\"unknown\": 0, \"ground nut\": 1, \"maize\": 2, \"rice\": 3, \"soya bean\": 4, \"yam\": 5, \n",
    "                         \"intercrop\": 6, \"sorghum\": 7, \"okra\": 8, \"cassava\": 9, \"millet\": 10, \"tomato\": 11, \n",
    "                         \"cowpea\": 12, \"sweet potato\": 13, \"babala beans\": 14, \"salad vegetables\": 15, \n",
    "                         \"bra and ayoyo\": 16, \"watermelon\": 17, \"zabla\": 18, \"nili\": 19, \"kpalika\": 20, \n",
    "                         \"cotton\": 21, \"akata\": 22, \"nyenabe\": 23, \"pepper\": 24}\n",
    "    \n",
    "    key_list = list(category_dict.keys())\n",
    "    val_list = list(category_dict.values())\n",
    "    \n",
    "    df = pd.DataFrame(columns = key_list, index = lbl_ids)\n",
    "    \n",
    "    for fn in lbl_fnames:\n",
    "        lbl_id = fn.name.split(\"_\")[-1].replace(\".tif\", \"\")\n",
    "        \n",
    "        with rasterio.open(fn) as src:\n",
    "            lbl_array = src.read()\n",
    "            categories, counts = np.unique(lbl_array, return_counts=True)\n",
    "            for a,b in zip(list(categories), list(counts)):\n",
    "                if lbl_id in list(df.index):\n",
    "                    if key_list[val_list.index(a)] in list(df.columns):\n",
    "                        df.loc[lbl_id, key_list[val_list.index(a)]] = b\n",
    "    df = df.fillna(0)\n",
    "    df.to_csv(lbl_dir / out_filename, index_label='Grid-ID')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "root_dir = \"C:/My_documents/CropTypeData_Rustowicz\"\n",
    "lbl_fldrname = \"Labels\"\n",
    "country = \"Ghana\"\n",
    "out_filename = \"report.csv\"\n",
    "category = {\"unknown\": 0, \"maize\": 1, \"other\": 2, \"rice\": 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "report = summarize_lbl(root_dir, country, lbl_fldrname, out_filename, category)\n",
    "report.sum(axis = 0, skipna = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Split the dataset into train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "import math\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\"\"\"\n",
    "\n",
    "def create_grid_splits(root_dir, country, sources, lbl_fldrname, csv_fn, split_threshold = 0.8):\n",
    "    \"\"\"\n",
    "    Splitting the dataset into train and test datasets.\n",
    "    \n",
    "    root_dir (str) -- path to the main directory which data resides. Example: \"C:/My_documents/Data\".\n",
    "    country (str) -- This is based on the organization of dataset that images and \n",
    "                     labels reside inside a country folder.\n",
    "    sources (list) -- folder name of the image resource. example: [\"Sentinel-1\", \"Sentinel-2\"]\n",
    "    lbl_fldrname (str) -- Name of the folder containing annotated grids.\n",
    "    csv_fn (str) -- Name of the csv file summerizing the content of each grid.\n",
    "    split_threshold (float) -- scalar value as a threshold to decide how many of the grids will be\n",
    "                               in the training folder. Default is 0.8.\n",
    "    \"\"\"\n",
    "    # Directory to labels\n",
    "    lbl_dir = Path(root_dir) / country / lbl_fldrname / \"reclass\"\n",
    "    \n",
    "    # filename of the label grids\n",
    "    lbl_fnames = [Path(dirpath) / f for (dirpath, dirnames, filenames) in os.walk(lbl_dir) for \\\n",
    "                  f in filenames if f.endswith(\".tif\")]\n",
    "    \n",
    "    # List of grid-ids\n",
    "    lbl_ids = [str(f).split(\"_\")[-1].replace(\".tif\", \"\") for f in lbl_fnames]\n",
    "    \n",
    "    # Read the csv file into a dataframe\n",
    "    report = pd.read_csv(lbl_dir / csv_fn, index_col=\"Grid-ID\")\n",
    "    \n",
    "    assert(report.shape[0] == len(lbl_ids))\n",
    "    \n",
    "    num_train_girds = math.ceil(split_threshold * len(lbl_ids))\n",
    "    categories = list(report.columns)\n",
    "    \n",
    "    # make a dictionary with the keys as category names and values as list of grid-ids containing\n",
    "    # those categories.\n",
    "    cat_grid = {}\n",
    "    for category in categories:\n",
    "        if category != \"unknown\":\n",
    "            cat_grid[category] = list(report[report[category] > 0].index)\n",
    "    \n",
    "    # Choose the category with the least amount of tiles as the initial category and add the sampled ids\n",
    "    # in the list of training grids.\n",
    "    initial_category = min(cat_grid, key=lambda cat: len(cat_grid[cat]))\n",
    "    num_initial_tiles = math.ceil(len(cat_grid[initial_category]) * split_threshold)\n",
    "    training_grids = random.sample(cat_grid[initial_category], num_initial_tiles)\n",
    "    \n",
    "    # for each category find the similar grid-ids that are already in the training list. Recalculate the number of\n",
    "    # samples that need to be taken. Sample unique grid-ids for the category and add it to the list of training grids.\n",
    "    for category in categories:\n",
    "        if category not in [\"unknown\", initial_category]:\n",
    "            similar_grids = set(cat_grid[category]).intersection(training_grids)\n",
    "            num_samples_to_take = math.ceil(len(cat_grid[category]) * split_threshold) - len(similar_grids)\n",
    "            allowable_grids = list(np.setdiff1d(cat_grid[category], training_grids))\n",
    "            grid_ids = random.sample(allowable_grids, num_samples_to_take)\n",
    "            training_grids.extend(grid_ids)\n",
    "    \n",
    "    # make sure that training folder contains correct number of grids as decided by the split threshold.\n",
    "    #To do that we add or drop grids from the category with the max number of grids.\n",
    "    if len(training_grids) < num_train_girds:\n",
    "        num_extra_samples = num_train_girds - len(training_grids)\n",
    "        biggest_category = max(cat_grid, key=lambda cat: len(cat_grid[cat]))\n",
    "        allowable_other_grids = list(np.setdiff1d(cat_grid[biggest_category], training_grids))\n",
    "        extra_other_grid_ids = random.sample(allowable_other_grids, num_extra_samples)\n",
    "        training_grids.extend(extra_other_grid_ids)\n",
    "    else:\n",
    "        num_samples_to_drop = len(training_grids) - num_train_girds\n",
    "        biggest_category = max(cat_grid, key=lambda cat: len(cat_grid[cat]))\n",
    "        allowable_other_grids = set(cat_grid[biggest_category]).intersection(training_grids)\n",
    "        droppable_other_grid_ids = random.sample(allowable_other_grids, num_samples_to_drop)\n",
    "        for item in training_grids:\n",
    "            if item in droppable_other_grid_ids:\n",
    "                training_grids.remove(item)\n",
    "    \n",
    "    # add preceding zeros to the list of training grids\n",
    "    training_grids = [str(item).zfill(6) for item in training_grids]\n",
    "    val_grids = list(np.setdiff1d(lbl_ids, training_grids))\n",
    "    training_grids.sort()\n",
    "    val_grids.sort()\n",
    "    \n",
    "    # Create proper folders for the splitted dataset\n",
    "    lbl_train_out_path = lbl_dir / \"train\"\n",
    "    lbl_val_out_path = lbl_dir / \"validation\"\n",
    "    Path(lbl_train_out_path).mkdir(parents=True, exist_ok=True)\n",
    "    Path(lbl_val_out_path).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Copy labels into train, validate subfolders.\n",
    "    for id, fn in zip(lbl_ids, lbl_fnames):\n",
    "        \n",
    "        if (id in training_grids) and (id in fn.name):\n",
    "            #shutil.copy(fn, lbl_train_out_path)\n",
    "            shutil.move(str(fn), str(lbl_train_out_path))\n",
    "        \n",
    "        if (id in val_grids) and (id in fn.name):\n",
    "            #shutil.copy(fn, lbl_val_out_path)\n",
    "            shutil.move(str(fn), str(lbl_val_out_path))\n",
    "    \n",
    "    # Copy the img dataset based on the grid-ID to equivalent subfolders.\n",
    "    for source in sources:        \n",
    "        \n",
    "        src_dir = Path(root_dir) / country / source / \"npy\"\n",
    "        src_train_out_path = src_dir / \"train\"\n",
    "        src_val_out_path = src_dir / \"validation\"\n",
    "        \n",
    "        Path(src_train_out_path).mkdir(parents=True, exist_ok=True)\n",
    "        Path(src_val_out_path).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        src_files = [Path(dirpath) / f for (dirpath, dirnames, filenames) in os.walk(src_dir) for \\\n",
    "                     f in filenames]\n",
    "        \n",
    "        for id in lbl_ids:\n",
    "            for fn in src_files:\n",
    "                if (id in training_grids) and (id in fn.name):\n",
    "                    #shutil.copy(fn, src_train_out_path)\n",
    "                    shutil.move(str(fn), str(src_train_out_path))\n",
    "            \n",
    "                if (id in val_grids) and (id in fn.name):\n",
    "                    #shutil.copy(fn, src_val_out_path)\n",
    "                    shutil.move(str(fn), str(src_val_out_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "root_dir = \"C:/My_documents/CropTypeData_Rustowicz\"\n",
    "country = \"Ghana\"\n",
    "sources = [\"Sentinel-1\", \"Sentinel-2\"]\n",
    "lbl_fldrname = \"Labels\"\n",
    "csv_fn = \"report.csv\"\n",
    "split_threshold = 0.80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "create_grid_splits(root_dir, country, sources, lbl_fldrname, csv_fn, split_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Make pixel dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def Make_pixel_dataset(root_dir, country, sources, lbl_fldrname, usage):\n",
    "    \n",
    "    lbl_dir = Path(root_dir) / country / lbl_fldrname / usage\n",
    "    lbl_fnames = [Path(dirpath) / f for (dirpath, dirnames, filenames) in os.walk(lbl_dir) for f in filenames if f.endswith(\".tif\")]\n",
    "    lbl_fnames.sort()\n",
    "    \n",
    "    s1_src_path = Path(root_dir) / country / \"Sentinel-1\" / usage\n",
    "    s1_fnames = [Path(dirpath) / f for (dirpath, dirnames, filenames) in os.walk(s1_src_path) for f in filenames if f.endswith(\".npy\")]\n",
    "    s1_fnames.sort()\n",
    "            \n",
    "    s2_src_path = Path(root_dir) / country / \"Sentinel-2\" / usage\n",
    "    s2_fnames = [Path(dirpath) / f for (dirpath, dirnames, filenames) in os.walk(s2_src_path) for f in filenames if f.endswith(\".npy\") if \"source\" in f]\n",
    "    cmasks = [Path(dirpath) / f for (dirpath, dirnames, filenames) in os.walk(s2_src_path) for f in filenames if f.endswith(\".npy\") if \"cloudmask\" in f]\n",
    "    s2_fnames.sort()\n",
    "    cmasks.sort()\n",
    "    \n",
    "    for lbl_fn, s1_fn, s2_fn, cmask_fn in zip(lbl_fnames, s1_fnames, s2_fnames, cmasks):\n",
    "        \n",
    "        lbl_grid_id = str(lbl_fn).split(\"_\")[-1].replace(\".tif\", \"\")\n",
    "        s1_grid_id = str(s1_fn).split(\"_\")[-1].replace(\".npy\", \"\")\n",
    "        s2_grid_id = str(s2_fn).split(\"_\")[-1].replace(\".npy\", \"\")\n",
    "        cmask_grid_id = str(s2_fn).split(\"_\")[-1].replace(\".npy\", \"\")\n",
    "        assert lbl_grid_id == s1_grid_id == s2_grid_id == cmask_grid_id\n",
    "        \n",
    "        lbl_array = load_data(lbl_fn, isLabel = True)\n",
    "        s1_array = load_data(s1_fn, isLabel = False)\n",
    "        s2_array = load_data(s2_fn, isLabel = False)\n",
    "        cmask_array = load_data(cmask_fn, isLabel = False)\n",
    "        \n",
    "        unique_vals, unique_counts = np.unique(lbl_tile, return_counts=True)\n",
    "        for val, count in zip(unique_vals, unique_counts):\n",
    "            crop_indices = np.where(lbl_tile == [val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "source_s1_grid_id,crop_type,coord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def shiftBrightness(img, gammaRange=(0.2, 2.0), shiftSubset=(4, 4), patchShift=True):\n",
    "    '''\n",
    "    Shift image brightness through gamma correction\n",
    "    Params:\n",
    "        img (narray): Concatenated variables or brightness value with a dimension of (H, W, C)\n",
    "        gammaRange (tuple): Range of gamma values\n",
    "        shiftSubset (tuple): Number of bands or channels for each shift\n",
    "        patchShift (bool): Whether apply the shift on small patches\n",
    "     Returns:\n",
    "        narray, brightness shifted image\n",
    "    '''\n",
    "\n",
    "\n",
    "    c_start = 0\n",
    "\n",
    "    if patchShift:\n",
    "        for i in shiftSubset:\n",
    "            gamma = random.triangular(gammaRange[0], gammaRange[1], 1)\n",
    "\n",
    "            h, w, _ = img.shape\n",
    "            rotMtrx = cv2.getRotationMatrix2D(center=(random.randint(0, h), random.randint(0, w)),\n",
    "                                              angle=random.randint(0, 90),\n",
    "                                              scale=random.uniform(1, 2))\n",
    "            mask = cv2.warpAffine(img[:, :, c_start:c_start + i], rotMtrx, (w, h))\n",
    "            mask = np.where(mask, 0, 1)\n",
    "            # apply mask\n",
    "            img_ma = ma.masked_array(img[:, :, c_start:c_start + i], mask=mask)\n",
    "            img[:, :, c_start:c_start + i] = ma.power(img_ma, gamma)\n",
    "            # default extra step -- shift on image\n",
    "            gamma_full = random.triangular(0.5, 1.5, 1)\n",
    "            img[:, :, c_start:c_start + i] = np.power(img[:, :, c_start:c_start + i], gamma_full)\n",
    "\n",
    "            c_start += i\n",
    "    else:\n",
    "        # convert image dimension to (C, H, W) if len(img.shape)==3\n",
    "        img = np.transpose(img, list(range(img.ndim)[-1:]) + list(range(img.ndim)[:-1]))\n",
    "        for i in shiftSubset:\n",
    "            gamma = random.triangular(gammaRange[0], gammaRange[1], 1)\n",
    "            img[c_start:c_start + i, ] = np.power(img[c_start:c_start + i, ], gamma)\n",
    "\n",
    "            c_start += i\n",
    "        img = np.transpose(img, list(range(img.ndim)[-img.ndim + 1:]) + [0])\n",
    "\n",
    "    return img\n",
    "\n",
    "#########################################################################################\n",
    "\n",
    "def jitter(x, sigma=0.03):\n",
    "    # https://arxiv.org/pdf/1706.00527.pdf\n",
    "    jittered = x + np.random.normal(loc=0., scale=sigma, size=x.shape)\n",
    "    return jittered\n",
    "\n",
    "#########################################################################################\n",
    "\n",
    "def shift_tstack_brightness(img, gamma_range=(0.2, 2.0), sample_number=5, patch_shift=False, mode = 'random'):\n",
    "    '''\n",
    "    Shift image brightness on sampled timestamps\n",
    "    Params:\n",
    "        img (narray): Concatenated time series cube in a dimension of (N, T), where N could be either nothing or  C, H, W\n",
    "        gamma_range (tuple): Range of gamma values\n",
    "        sample_number (int): Nubmer of timestamps to sample\n",
    "        patch_shift (bool): Whether apply the shift on small patches; will be ignored if input is point stack\n",
    "        mode {int): 'random' or 'uni'\n",
    "     Returns:\n",
    "        narray, brightness shifted time series cube\n",
    "    '''\n",
    "\n",
    "    # parameters\n",
    "    assert img.ndim == 4 or img.ndim == 1\n",
    "    if img.ndim == 4:\n",
    "        c, h, w, t = img.shape\n",
    "        if h < 2 or w < 2:\n",
    "            patch_shift = False\n",
    "    else:\n",
    "        t = img.shape[-1]\n",
    "    # reset sample number \n",
    "    sample_number = min(sample_number, t)\n",
    "\n",
    "    # sample timestamos\n",
    "    if mode == 'random':\n",
    "        # convert t dimension to the first dimension\n",
    "        img = np.transpose(img, list(range(img.ndim)[-1:]) + list(range(img.ndim)[:-1])) # T, C, H, W\n",
    "        tsamples = random.sample(range(t), sample_number)\n",
    "        for tsample in tsamples:\n",
    "            img_t = img[tsample, ]\n",
    "            img_t = img_t.transpose(list(range(img_t.ndim)[1:]) + [0]) # H, W, C\n",
    "            shifted = shiftBrightness(img_t, gamma_range, [c],  patch_shift) # H, W C\n",
    "            img[tsample,] = shifted.transpose(list(range(img_t.ndim)[-1:]) + list(range(img_t.ndim)[:-1])) # C, H, W\n",
    "        # transpose back to C, H, W, T\n",
    "        img = np.transpose(img, list(range(img.ndim)[-img.ndim + 1:]) + [0]) # C, H, W, T\n",
    "    else:\n",
    "        # convert c dimension to the last\n",
    "        img = np.transpose(img, list(range(img.ndim)[1:]) + [0]) # H, W, T, C\n",
    "        shifted = shiftBrightness(img, gamma_range, [c], patchShift = False)\n",
    "        # transpose back to  C, H, W, T\n",
    "        img = np.transpose(shifted, list(range(shifted.ndim)[-1:]) + list(range(shifted.ndim)[:-1]))\n",
    "\n",
    "    return img\n",
    "\n",
    "###############################################################################################\n",
    "\n",
    "def jitter_tstack(img, sample_number=5):\n",
    "    '''\n",
    "    Apply jitter augmentation on sampled timestamps\n",
    "    Params:\n",
    "        img(narray): Concatenated time series cube in a dimension of (N, T), where N could be either nothing or  C, H, W\n",
    "        sample_number (int): Nubmer of timestamps to sample\n",
    "    Returns:\n",
    "        narray, jittered time series cube\n",
    "    '''\n",
    "    assert img.ndim == 4 or img.ndim == 1\n",
    "   \n",
    "    # convert t dimension to the first dimension\n",
    "    t = img.shape[-1]\n",
    "    # reset sample number \n",
    "    sample_number = min(sample_number, t)\n",
    "    img = np.transpose(img, list(range(img.ndim)[-1:]) + list(range(img.ndim)[:-1]))\n",
    "\n",
    "    # jitter\n",
    "    tsamples = random.sample(range(t), sample_number)\n",
    "    for tsample in tsamples:\n",
    "        img[tsample, ] = jitter(img[tsample, ])\n",
    "\n",
    "    img = np.transpose(img, list(range(img.ndim)[-img.ndim + 1:]) + [0])\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Evaluation and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\"\"\"\n",
    "\n",
    "class BinaryMetrics:\n",
    "    \n",
    "    '''Metrics measuring model performance.'''\n",
    "\n",
    "    def __init__(self, refArray, scoreArray, predArray = None):\n",
    "        '''\n",
    "        Params:\n",
    "            refArray (narray): Array of ground truth\n",
    "            scoreArray (narray): Array of pixels scores of positive class\n",
    "        '''\n",
    "\n",
    "        self.observation = refArray.flatten()\n",
    "        self.score = scoreArray.flatten()\n",
    "        \n",
    "        if self.observation.shape != self.score.shape:\n",
    "            raise Exception(\"Inconsistent size between label and prediction arrays.\")\n",
    "        \n",
    "        if predArray is not None:\n",
    "            self.prediction = predArray.flatten()\n",
    "        else:\n",
    "            self.prediction = np.where(self.score > 0.5, 1, 0)\n",
    "\n",
    "        self.confusion_matrix = self.confusion_matrix()\n",
    "\n",
    "        \n",
    "    def __add__(self, other):\n",
    "        \"\"\"\n",
    "        Add two BinaryMetrics instances\n",
    "        Params:\n",
    "            other (''BinaryMetrics''): A BinaryMetrics instance\n",
    "        Return:\n",
    "            ''BinaryMetrics''\n",
    "        \"\"\"\n",
    "\n",
    "        return BinaryMetrics(np.append(self.observation, other.observation),\n",
    "                             np.append(self.score, other.score),\n",
    "                            np.append(self.prediction, other.prediction))\n",
    "\n",
    "\n",
    "    def __radd__(self, other):\n",
    "        \"\"\"\n",
    "        Add a BinaryMetrics instance with reversed operands.\n",
    "        Params:\n",
    "            other\n",
    "        Returns:\n",
    "            ''BinaryMetrics\n",
    "        \"\"\"\n",
    "\n",
    "        if other == 0:\n",
    "            return self\n",
    "        else:\n",
    "            return self.__add__(other)\n",
    "\n",
    "\n",
    "    def confusion_matrix(self):\n",
    "        \"\"\"\n",
    "        Calculate confusion matrix of given ground truth and predicted label\n",
    "        Returns:\n",
    "            ''pandas.dataframe'' of observation on the column and prediction on the row\n",
    "        \"\"\"\n",
    "\n",
    "        #set_trace()\n",
    "        refArray = self.observation\n",
    "        predArray = self.prediction\n",
    "\n",
    "        if refArray.max() > 1 or predArray.max() > 1:\n",
    "            raise Exception(\"Invalid array\")\n",
    "        \n",
    "        predArray = predArray * 2\n",
    "        sub = refArray - predArray\n",
    "\n",
    "        self.tp = np.sum(sub == -1)\n",
    "        self.fp = np.sum(sub == -2)\n",
    "        self.fn = np.sum(sub == 1)\n",
    "        self.tn = np.sum(sub == 0)\n",
    "        \n",
    "        confusionMatrix = pd.DataFrame(data = np.array([[self.tn, self.fp],[self.fn, self.tp]]),\n",
    "                                       index = ['observation = 0', 'observation = 1'],\n",
    "                                       columns = ['prediction = 0', 'prediction = 1'])\n",
    "\n",
    "        return confusionMatrix\n",
    "\n",
    "\n",
    "    def ir(self):\n",
    "        \"\"\"\n",
    "        Imbalance Ratio (IR) is defined as the proportion between positive and negative instances of the label. \n",
    "        This value lies within the [0, ] range, having a value IR = 1 in the balanced case.\n",
    "        Returns:\n",
    "             float\n",
    "        \"\"\"\n",
    "        try:\n",
    "            ir = (self.tp + self.fn) / (self.fp + self.tn)\n",
    "        \n",
    "        except ZeroDivisionError:\n",
    "            ir = np.nan_to_num(float(\"NaN\"))\n",
    "\n",
    "        return ir\n",
    "    \n",
    "    \n",
    "    def oa(self):\n",
    "        \"\"\"\n",
    "        Calculate Overal Accuracy.\n",
    "        Returns:\n",
    "            float\n",
    "        \"\"\"\n",
    "\n",
    "        oa = metrics.accuracy_score(self.observation, self.prediction)\n",
    "        \n",
    "        return oa\n",
    "    \n",
    "    \n",
    "    def producers_accuracy(self):\n",
    "        \"\"\"\n",
    "        Calculate Producer's Accuracy (True Positive Rate |Sensitivity |hit rate | recall).\n",
    "        Returns:\n",
    "            float\n",
    "        \"\"\"\n",
    "\n",
    "        return metrics.recall_score(self.observation, self.prediction, average='binary')\n",
    "\n",
    "    \n",
    "    def users_accuracy(self):\n",
    "        \"\"\"\n",
    "        Calculate Users Accuracy (Positive Prediction Value (PPV) | Precision).\n",
    "        Returns:\n",
    "            float\n",
    "        \"\"\"\n",
    "\n",
    "        ua = metrics.precision_score(self.observation, self.prediction, average='binary')\n",
    "        \n",
    "        return ua\n",
    "    \n",
    "    \n",
    "    def npv(self):\n",
    "        \"\"\"\n",
    "        Calculate Negative Predictive Value or true negative accuracy.\n",
    "        Returns:\n",
    "             float\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            npv = self.tn / (self.tn + self.fn)\n",
    "        \n",
    "        except ZeroDivisionError:\n",
    "            npv = np.nan_to_num(float(\"NaN\"))\n",
    "        \n",
    "        return npv\n",
    "\n",
    "\n",
    "    def specificity(self):\n",
    "        \"\"\"\n",
    "        Calculate Specificity aka. True negative rate (TNR), or inverse recall.\n",
    "        Returns:\n",
    "             float\n",
    "        \"\"\"\n",
    "        try:\n",
    "            spc = self.tn / (self.tn + self.fp)\n",
    "        \n",
    "        except ZeroDivisionError:\n",
    "            spc = np.nan_to_num(float(\"NaN\"))\n",
    "\n",
    "        return spc\n",
    "\n",
    "      \n",
    "    def F1_measure(self):\n",
    "        \"\"\"\n",
    "        Calculate F1 score.\n",
    "        Returns:\n",
    "            float\n",
    "        \"\"\"\n",
    "\n",
    "        f1 = metrics.f1_score(self.observation, self.prediction)\n",
    "\n",
    "        return f1\n",
    "    \n",
    "    \n",
    "    def iou(self):\n",
    "        \"\"\"\n",
    "        Calculate interception over union for the positive class.\n",
    "        Returns:\n",
    "            float\n",
    "        \"\"\"\n",
    "\n",
    "        return metrics.jaccard_score(self.observation, self.prediction)\n",
    "    \n",
    "    \n",
    "    def miou(self):\n",
    "        \"\"\"\n",
    "        Calculate mean interception over union considering both positive and negative classes.\n",
    "        Returns:\n",
    "            float\n",
    "        \"\"\"\n",
    "        try:\n",
    "            miou = np.nanmean([self.tn / (self.tn + self.fn + self.fp), self.tp / (self.tp + self.fn + self.fp)])\n",
    "        \n",
    "        except ZeroDivisionError:\n",
    "            miou = np.nan_to_num(float(\"NaN\"))\n",
    "\n",
    "        return miou\n",
    "    \n",
    "    \n",
    "    def MCCn(self):\n",
    "        \"\"\"\n",
    "        Calculate Matthews correlation coefficient (MCC). Rescale the range from [-1,1] to [o,1].\n",
    ".\n",
    "        Returns:\n",
    "            float\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            mmcn = 0.5 * ((self.lambda_pp + self.lambda_nn - 1) / math.sqrt((self.lambda_pp + (1 - self.lambda_nn)) * \n",
    "                                                                               (self.lambda_nn + (1 - self.lambda_pp))) + 1)\n",
    "        except ZeroDivisionError:\n",
    "            mmcn = np.nan_to_num(float(\"NaN\"))\n",
    "\n",
    "        return mmcn\n",
    "\n",
    "\n",
    "    def tss(self):\n",
    "        \"\"\"\n",
    "        Calculates true scale statistic (TSS). Also called Bookmaker Informedness (BM). \n",
    "        Scale of the metric:[-1,1].\n",
    "        Returns:\n",
    "            float\n",
    "        \"\"\"  \n",
    "        tss = self.tp / (self.tp + self.fn) + self.tn / (self.tn + self.fp) - 1\n",
    "        \n",
    "        return tss\n",
    "\n",
    "##################################################    \n",
    "    \n",
    "def accuracy_evaluation(evalData, model, gpu, outPrefix, bucket = None):\n",
    "    \"\"\"\n",
    "    Evaluate model\n",
    "    Params:\n",
    "        evalData (''DataLoader''): Batch grouped data\n",
    "        model: Trained model for validation\n",
    "        buffer: Buffer added to the targeted grid when creating dataset. This allows metrics to calculate only\n",
    "            at non-buffered region\n",
    "        gpu (binary,optional): Decide whether to use GPU, default is True\n",
    "        bucket (str): name of s3 bucket to save metrics\n",
    "        outPrefix (str): s3 prefix to save metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    metrics = []\n",
    "    \n",
    "    for s1_img, s2_img, label in evalData:\n",
    "        s1_img = Variable(s1_img, requires_grad=False)    #shape=(B,T,C)\n",
    "        s1_img[s1_img != s1_img] = 0\n",
    "        s2_img = Variable(s2_img, requires_grad=False)\n",
    "        s2_img[s2_img != s2_img] = 0\n",
    "        label = Variable(label, requires_grad=False)      #shape=1\n",
    "    \n",
    "        if gpu:\n",
    "            s1_img = s1_img.cuda()\n",
    "            s2_img = s2_img.cuda()\n",
    "            label = label.cuda()\n",
    "        \n",
    "        model_out = model(s1_img, s2_img) #shape=(B, Class_num)\n",
    "        model_out_prob = F.softmax(model_out, 1)\n",
    "        \n",
    "        batch, nclass = model_out_prob.size()\n",
    "        \n",
    "        for i in range(batch):\n",
    "            label_batch = label[i].cpu().numpy()\n",
    "            batch_pred = model_out_prob.max(dim=1)[1].data[i].cpu().numpy()\n",
    "            \n",
    "            for n in range(1, nclass):\n",
    "                class_out = model_out_prob[:, n].data[i].cpu().numpy()\n",
    "                class_pred = np.where(batch_pred == n, 1, 0)\n",
    "                class_label = np.where(label_batch == n, 1, 0)\n",
    "                pixel_metrics = BinaryMetrics(class_label, class_out, class_pred)\n",
    "                \n",
    "                try:\n",
    "                    metrics[n - 1].append(pixel_metrics)\n",
    "                except:\n",
    "                    metrics.append([pixel_metrics])\n",
    "    #set_trace()\n",
    "    metrics = [sum(m) for m in metrics]\n",
    "    \n",
    "    report = pd.DataFrame({\n",
    "        \"Overal Accuracy\" : [m.oa() for m in metrics],\n",
    "        \"Producer's Accuracy (recall)\" : [m.producers_accuracy() for m in metrics],\n",
    "        \"User's Accuracy (precision)\" : [m.users_accuracy() for m in metrics],\n",
    "        \"Negative Predictive Value\" : [m.npv() for m in metrics],\n",
    "        \"Specificity (TNR)\" : [m.specificity() for m in metrics],\n",
    "        \"F1 score\" : [m.F1_measure() for m in metrics],\n",
    "        \"IoU\" : [m.iou() for m in metrics],\n",
    "        \"mIoU\" : [m.miou() for m in metrics],\n",
    "        \"TSS\" : [m.tss() for m in metrics]\n",
    "    }, index=[\"class_{}\".format(m) for m in range(1, len(metrics) + 1)])\n",
    "    \n",
    "    if bucket:\n",
    "        dir_metrics = \"s3://{}/{}/Metrics.csv\".format(bucket, outPrefix)\n",
    "    else:\n",
    "        dir_metrics = Path(outPrefix)/ \"Metrics.csv\"\n",
    "        \n",
    "        if not os.path.exists(Path(outPrefix)):\n",
    "            os.makedirs(Path(outPrefix))\n",
    "        \n",
    "    report.to_csv(dir_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rustowicz African crop custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################### Helper functions for custom Dataset ######################################\n",
    "\n",
    "def load_data(dataPath, isLabel = False):\n",
    "    \"\"\"Load the dataset.\n",
    "    Args:\n",
    "        dataPath (str) -- Path to either the image or label raster.\n",
    "        isLabel (binary) -- decide wether the input dataset is label. Default is False.\n",
    "    \n",
    "    Returns:\n",
    "        loaded data as numpy ndarray. \n",
    "    \"\"\"\n",
    "    \n",
    "    if isLabel:\n",
    "        \n",
    "        with rasterio.open(dataPath, \"r\") as src:\n",
    "            \n",
    "            if src.count != 1:\n",
    "                raise ValueError(\"Label must have only 1 band but {} bands were detected.\".format(src.count))\n",
    "            img = src.read(1)\n",
    "    \n",
    "    else:\n",
    "        img = np.load(dataPath)\n",
    "    \n",
    "    return img\n",
    "\n",
    "############################################################\n",
    "\n",
    "def get_pixel_coord(lbl_tile, lbl_grid_id, percnt_pixels = 1, sampling_strategy = \"natural frequency\", \n",
    "                    get_neg_samp = False, verbose = False):\n",
    "    \"\"\"\n",
    "    get coordinates of pixels to be sampled in image coordinated (row|col).\n",
    "    Args:\n",
    "        lbl_tile (ndarray) -- 64x64 array of label values.\n",
    "        lbl_grid_id (int) -- 6 digit index to identify the chips.\n",
    "        percnt_pixels (float) -- value between (0, 1] indicating the percentage of crop pixels to be sampled\n",
    "                               from each grid. By default all the crop pixels and only 10% of negative pixels\n",
    "                               are sampled.\n",
    "        get_neg_samp (Binary) -- Decision whether to use Negative samples from the Unknown class.\n",
    "        sampling_strategy (str) -- choice of sampling strategy. It can be either 'natural frequency' or \n",
    "                                   'fixed size' with the former as default choice.\n",
    "    Returns:\n",
    "        A list of coordinate tuples in the form of [(sample1_row, sample1_col),...,(sampleN_row, sampleN_col)]\n",
    "        \n",
    "        \n",
    "    Note 1: If percnt_pixels is other than 1, then:\n",
    "            'natural frequency': Actually is a stratified sampling that follows the natural frequency of \n",
    "                                 categories during sampling to ensure the samples represent the underlying \n",
    "                                 distribution of crop categories.\n",
    "            'fixed size': it's a fixed size uniform stratified sampling that choose the minimum of the smallest \n",
    "                          category size and a fixed value as the number of samples from each crop category.\n",
    "    Note 2: number of negative samples is fixed to maximum 30 pixels based on availability in each chip.\n",
    "    \"\"\"\n",
    "    \n",
    "    # fixed sampling strategy for negative samples from each image chip.\n",
    "    if get_neg_samp:\n",
    "        negative_indices = np.where(lbl_tile == [0])\n",
    "        negative_coordinates = list(zip(negative_indices[0], negative_indices[1]))\n",
    "        total_neg_pixels = len(negative_coordinates)\n",
    "        total_pos_pixels = 4096 - total_neg_pixels\n",
    "    \n",
    "        if sampling_strategy == \"natural frequency\":\n",
    "            #(min(total_pos_pixels, total_neg_pixels) / max(total_pos_pixels, total_neg_pixels))\n",
    "            num_negative_samples = math.ceil((total_neg_pixels * percnt_pixels) * 0.1) \n",
    "        elif sampling_strategy == \"fixed size\":    \n",
    "            num_negative_samples = min(total_neg_pixels, 3)\n",
    "    \n",
    "        neg_samples = random.sample(negative_coordinates, num_negative_samples)\n",
    "    \n",
    "    sampled_coordinates = []\n",
    "    unique_vals, unique_counts = np.unique(lbl_tile, return_counts=True)\n",
    "    smallest_category_count = min(unique_counts)\n",
    "    \n",
    "    if sampling_strategy == \"natural frequency\":\n",
    "        if verbose:\n",
    "            print(\"Chip ID: {}\".format(lbl_grid_id)) \n",
    "        for val, count in zip(unique_vals, unique_counts):\n",
    "            if val != 0:\n",
    "                num_samples_per_cat = math.ceil(np.count_nonzero(lbl_tile == val) * percnt_pixels)\n",
    "                crop_indices = np.where(lbl_tile == [val])\n",
    "                crop_coordinates = list(zip(crop_indices[0], crop_indices[1]))\n",
    "                crop_samples = random.sample(crop_coordinates, num_samples_per_cat)\n",
    "                if verbose:\n",
    "                    print(\"Number of sampled pixels of crop type {}: {}\".format(val, len(crop_samples)))\n",
    "                sampled_coordinates.extend(crop_samples)\n",
    "        if get_neg_samp:\n",
    "            sampled_coordinates.extend(neg_samples)\n",
    "        return sampled_coordinates\n",
    "    \n",
    "    elif sampling_strategy == \"fixed size\":\n",
    "        for val, count in zip(unique_vals, unique_counts):\n",
    "            if val != 0:\n",
    "                num_samples_per_cat = min(count, 8)\n",
    "                crop_indices = np.where(lbl_tile == [val])\n",
    "                crop_coordinates = list(zip(crop_indices[0], crop_indices[1]))\n",
    "                crop_samples = random.sample(crop_coordinates, num_samples_per_cat)\n",
    "                if verbose:\n",
    "                    print(\"Chip ID: {}\".format(lbl_grid_id))\n",
    "                    print(\"Number of sampled pixels of crop type {}: {}\".format(val, len(crop_samples)))\n",
    "                sampled_coordinates.extend(crop_samples)\n",
    "        if get_neg_samp:\n",
    "            sampled_coordinates.extend(neg_samples)\n",
    "        return sampled_coordinates\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Sampling strategy is not recognized.\")\n",
    "\n",
    "############################################################\n",
    "\n",
    "class CropTypeBatchSampler(Sampler):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "            dataset (Pytorch dataset): list of tuples in the form of [(s1_img, s2_img, label),...,(s1_img, s2_img, label)]\n",
    "            batch_size (int): Number of samples in a mini-batch training strategy.\n",
    "    Returns:\n",
    "            list of batches of list of sample indices.\n",
    "    \n",
    "    Note 1: Batches are designed so that samples in a batch are exactly the same in sequence length.\n",
    "    Note 2: Batches might be of varied length. The number of batches that vary from batch size are maximum\n",
    "            equal to the number of unique sequence lengths in the image source (s1).\n",
    "    Note 3: No seperate padding is required for S1 using 'collate_fn'.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataset, batch_size):\n",
    "        super(CropTypeBatchSampler, self).__init__(dataset)\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.indices_n_lengths = []\n",
    "        \n",
    "        for i in range(len(dataset)):\n",
    "            self.indices_n_lengths.append((i, dataset[i][0].shape[0]))\n",
    "        \n",
    "        shuffle(self.indices_n_lengths)\n",
    "        \n",
    "        # dictionary with unique temporal length as keys and sample index as values.\n",
    "        batch_map = OrderedDict()\n",
    "        \n",
    "        for idx, length in self.indices_n_lengths:\n",
    "            if length not in batch_map:\n",
    "                batch_map[length] = [idx]\n",
    "            else:\n",
    "                batch_map[length].append(idx)\n",
    "        \n",
    "        self.batch_list = []\n",
    "        for length, indices in batch_map.items():\n",
    "            for bucket in [indices[i:(i + self.batch_size)] for i in range(0, len(indices), self.batch_size)]:\n",
    "                self.batch_list.append(bucket)\n",
    "   \n",
    "    def __len__(self):\n",
    "        return len(self.batch_list)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        shuffle(self.batch_list)\n",
    "        for i in self.batch_list:\n",
    "            yield i\n",
    "\n",
    "############################################################\n",
    "\n",
    "class CropTypeBatchSampler2(Sampler):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "            dataset (Pytorch dataset): list of tuples in the form of [(s1_img, s2_img, label),...,(s1_img, s2_img, label)]\n",
    "            batch_size (int): Number of samples in a mini-batch training strategy.\n",
    "    Returns:\n",
    "            list of batches of list of sample indices\n",
    "            \n",
    "    Note 1: Batches are designed so that samples in a batch are closest in sequence length for S1.\n",
    "    Note 2: The last batch might be shorter that the batch size.\n",
    "    Note 3: Seperate padding might be required for S1 using 'collate_fn'.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataset, batch_size):\n",
    "        super(CropTypeBatchSampler2, self).__init__(dataset)\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.batches = []\n",
    "        batch = []\n",
    "        indices_n_lengths = []\n",
    "        \n",
    "        for i in range(len(dataset)):\n",
    "            indices_n_lengths.append((i, train_dataset[i][0].shape[0]))\n",
    "        \n",
    "        shuffle(indices_n_lengths)\n",
    "        indices_n_lengths.sort(key = lambda x:x[1])\n",
    "        \n",
    "        for i in range(len(indices_n_lengths)):\n",
    "            sample_idx = indices_n_lengths[i][0]\n",
    "            batch.append(sample_idx)\n",
    "            \n",
    "            if len(batch) == self.batch_size:\n",
    "                self.batches.append(batch)\n",
    "                batch = []\n",
    "                \n",
    "        if len(batch) > 0:\n",
    "            self.batches.append(batch)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.batches)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for b in self.batches:\n",
    "            yield(b)\n",
    "\n",
    "############################################################\n",
    "\n",
    "def collate_var_length(batch):\n",
    "    \n",
    "    batch_size = len(batch)\n",
    "    \n",
    "    labels = [batch[i][2] for i in range(batch_size)]\n",
    "    label = torch.stack(labels)\n",
    "    \n",
    "    s1_grids = [batch[i][0] for i in range(batch_size)]\n",
    "    s2_grids = [batch[i][1] for i in range(batch_size)]\n",
    "    \n",
    "    #s1_lengths = [batch[i][0].shape[0] for i in range(batch_size)]\n",
    "    #s2_lengths = [batch[i][1].shape[0] for i in range(batch_size)]\n",
    "    \n",
    "    s1_img = rnn_util.pad_sequence(s1_grids, batch_first=True)\n",
    "    s2_img = rnn_util.pad_sequence(s2_grids, batch_first=True)\n",
    "    \n",
    "    return s1_img, s2_img, label\n",
    "    #return s1_img, s2_img, label, s1_lengths, s2_lengths \n",
    "\n",
    "######################################## Custom Dataset ######################################\n",
    "\"\"\"\n",
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import rasterio\n",
    "\"\"\"\n",
    "\n",
    "class pixelDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "            root_dir (str): path to the main folder of the dataset, formatted as indicated in the readme\n",
    "            country (str): name of the country. Necessary based on the organization of dataset into folders.\n",
    "            lbl_fldrname (str): Name of the folder containing the labels.\n",
    "            usage (str): decide whether we are making a \"train\", \"validation\" or \"test\" dataset.\n",
    "            sources (list of str): Sensors of image acquisition. At the moment two sensors \n",
    "                                   are used [\"Sentinel-1\", \"Sentinel-2\"]\n",
    "            percnt_pixels (float): Defines the number of pixels to be randomly sampled from each Grid-ID as\n",
    "                                   a percentage of the total number of field pixels in that Grid-ID. If set\n",
    "                                   to \"None\" then all the crop pixels are sampled. Default value is \"None\".\n",
    "            useCloudMask (Binary) : Decides whether to apply cloud mask on Sentinel-2 images. Default is False.\n",
    "            transform (str): apply the temporal jittering augmentation on temporal pixel samples. Default is None.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, root_dir, country, lbl_fldrname, usage, sources = [\"Sentinel-1\", \"Sentinel-2\"], \n",
    "                 percnt_pixels = None, sampling_strategy = \"natural frequency\", transform = None):\n",
    "        \n",
    "        self.usage = usage\n",
    "        self.sources = sources\n",
    "        self.percnt_pixels = percnt_pixels\n",
    "        self.sampling_strategy = sampling_strategy\n",
    "        self.transform = transform\n",
    "        \n",
    "        if self.usage in [\"train\", \"validation\"]:\n",
    "     \n",
    "            self.lbl_dir = Path(root_dir) / country / lbl_fldrname / self.usage\n",
    "        \n",
    "            lbl_fnames = [Path(dirpath) / f for (dirpath, dirnames, filenames) in os.walk(self.lbl_dir) for \\\n",
    "                          f in filenames if f.endswith(\".tif\")]\n",
    "            lbl_fnames.sort()\n",
    "            \n",
    "            s1_src_path = Path(root_dir) / country / \"Sentinel-1\" / self.usage\n",
    "            s1_fnames = [Path(dirpath) / f for (dirpath, dirnames, filenames) in os.walk(s1_src_path) for \\\n",
    "                                         f in filenames if f.endswith(\".npy\")]\n",
    "            s1_fnames.sort()\n",
    "            \n",
    "            s2_src_path = Path(root_dir) / country / \"Sentinel-2\" / self.usage\n",
    "            s2_fnames = [Path(dirpath) / f for (dirpath, dirnames, filenames) in os.walk(s2_src_path) for \\\n",
    "                                         f in filenames if f.endswith(\".npy\") if \"source\" in f]\n",
    "            s2_fnames.sort()\n",
    "\n",
    "            assert len(lbl_fnames) == len(s1_fnames) == len(s2_fnames)\n",
    "            \n",
    "            self.lbl = []\n",
    "            self.lbl_grid_ids = []\n",
    "            self.s1 = []\n",
    "            self.s2 = []\n",
    "            \n",
    "            for lbl_fn, s1_fn, s2_fn in tqdm.tqdm(zip(lbl_fnames, s1_fnames, s2_fnames), total = len(lbl_fnames)):\n",
    "\n",
    "                lbl_grid_id = str(lbl_fn).split(\"_\")[-1].replace(\".tif\", \"\")\n",
    "                s1_grid_id = str(s1_fn).split(\"_\")[-1].replace(\".npy\", \"\")\n",
    "                s2_grid_id = str(s2_fn).split(\"_\")[-1].replace(\".npy\", \"\")\n",
    "                \n",
    "                lbl_array = load_data(lbl_fn, isLabel = True)\n",
    "                s1_array = load_data(s1_fn, isLabel = False)\n",
    "                s2_array = load_data(s2_fn, isLabel = False)\n",
    "                s2_array[s2_array == +inf] = 0\n",
    "                s2_array[s2_array == -inf] = 0\n",
    "                #print(lbl_grid_id)\n",
    "                sample_coordinates = get_pixel_coord(lbl_array, lbl_grid_id, self.percnt_pixels, self.sampling_strategy)\n",
    "                \n",
    "                assert lbl_grid_id == s1_grid_id == s2_grid_id\n",
    "                assert lbl_array.shape[0] == s1_array.shape[1] == s2_array.shape[1]\n",
    "                assert lbl_array.shape[1] == s1_array.shape[2] == s2_array.shape[2]\n",
    "                \n",
    "                \n",
    "                \n",
    "                for coord in sample_coordinates:\n",
    "                    lbl_val = lbl_array[coord[0], coord[1]]\n",
    "                    self.lbl.append(lbl_val.copy())\n",
    "                    \n",
    "                    s1_val = s1_array[:,coord[0], coord[1],:]\n",
    "                    self.s1.append(s1_val.copy())\n",
    "                    \n",
    "                    s2_val = s2_array[:,coord[0], coord[1],:]\n",
    "                    self.s2.append(s2_val.copy())\n",
    "                    \n",
    "                    self.lbl_grid_ids.append(lbl_grid_id)\n",
    "                \n",
    "                del lbl_array, s1_array, s2_array\n",
    "                gc.collect()\n",
    "\n",
    "        #print(\"Size of lbl: \" + str(sys.getsizeof(self.lbl)) + \"bytes\")\n",
    "        #print(\"Size of s1: \" + str(sys.getsizeof(self.s1)) + \"bytes\")\n",
    "        #print(\"Size of s2: \" + str(sys.getsizeof(self.s2)) + \"bytes\")\n",
    "        \n",
    "        assert len(self.s1) == len(self.s2)\n",
    "        print(\"------{} samples from each of the Sentinel sources are loaded in the {} dataset------\".format(len(self.s1),\n",
    "                                                                                                             self.usage))\n",
    "        \n",
    "        if self.usage == \"test\":\n",
    "            pass\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        if self.usage in [\"train\", \"validation\"]:\n",
    "            s1_img = self.s1[index]\n",
    "            s2_img = self.s2[index]\n",
    "            label = self.lbl[index]\n",
    "            grid_id = self.lbl_grid_ids[index]\n",
    "            \n",
    "            if (self.usage == \"train\") and self.transform:\n",
    "                pass\n",
    "                \"\"\"\n",
    "                # apply the transformation.\n",
    "                if random.randint(0, 1) and \"shift brightness\" in self.transform:\n",
    "                    s1_img = shift_tstack_brightness(s1_img, gamma_range=(0.2, 2.0), sample_number=5, \n",
    "                                                     patch_shift=False, mode = \"random\")\n",
    "                    \n",
    "                if random.randint(0, 1) and \"jitter\" in self.transform:\n",
    "                    s1_img = jitter_tstack(s1_img, sample_number=5)\n",
    "                \"\"\"    \n",
    "                \n",
    "            # numpy to torch\n",
    "            # tensor shape: (N x C x T)\n",
    "            s1_img = torch.from_numpy(s1_img.transpose((1, 0))).float()\n",
    "            s2_img = torch.from_numpy(s2_img.transpose((1, 0))).float()\n",
    "            label = torch.from_numpy(np.asarray(label)).long()\n",
    "            grid_id = torch.from_numpy(np.asarray(int(grid_id))).long()\n",
    "                \n",
    "            return s1_img, s2_img, label\n",
    "        \n",
    "        else:\n",
    "            s1_img = self.s1[index]\n",
    "            s2_img = self.s2[index]\n",
    "            label = self.lbl[index]\n",
    "            \n",
    "            s1_img = torch.from_numpy(s1_img.transpose((1, 0))).float()\n",
    "            s2_img = torch.from_numpy(s2_img.transpose((1, 0))).float()\n",
    "            label = torch.from_numpy(np.asarray(label)).long()\n",
    "            grid_id = torch.from_numpy(np.asarray(int(grid_id))).long()\n",
    "            \n",
    "            return s1_img, s2_img, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Ruwurm Bavarian Crop custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import tqdm\n",
    "\"\"\"\n",
    "\n",
    "BANDS = ['B1', 'B10', 'B11', 'B12', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9']\n",
    "NORMALIZING_FACTOR = 1e-4\n",
    "PADDING_VALUE = -1\n",
    "\n",
    "class BavarianCropsDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, root, partition, classmapping, mode=None, scheme=\"random\", region=None, samplet=70, \n",
    "                 cache=True, seed=0, validfraction=0.1):\n",
    "        \n",
    "        assert (mode in [\"trainvalid\", \"traintest\"] and scheme==\"random\") or (mode is None and scheme==\"blocks\")\n",
    "        assert scheme in [\"random\",\"blocks\"]\n",
    "        assert partition in [\"train\",\"test\",\"trainvalid\",\"valid\"]\n",
    "        \n",
    "        self.seed = seed\n",
    "        self.validfraction = validfraction\n",
    "        self.scheme = scheme\n",
    "        \n",
    "        seed += sum([ord(ch) for ch in partition])\n",
    "        np.random.seed(seed)\n",
    "        torch.random.manual_seed(seed)\n",
    "        \n",
    "        self.mode = mode\n",
    "        self.root = root\n",
    "        \n",
    "        if scheme==\"random\":\n",
    "            if mode == \"traintest\":\n",
    "                self.trainids = os.path.join(self.root, \"ids\", \"random\", region+\"_train.txt\")\n",
    "                self.testids = os.path.join(self.root, \"ids\", \"random\", region+\"_test.txt\")\n",
    "            elif mode == \"trainvalid\":\n",
    "                self.trainids = os.path.join(self.root, \"ids\", \"random\", region+\"_train.txt\")\n",
    "                self.testids = None\n",
    "            \n",
    "            self.read_ids = self.read_ids_random\n",
    "        \n",
    "        elif scheme==\"blocks\":\n",
    "            self.trainids = os.path.join(self.root, \"ids\", \"blocks\", region+\"_train.txt\")\n",
    "            self.testids = os.path.join(self.root, \"ids\", \"blocks\", region+\"_test.txt\")\n",
    "            self.validids = os.path.join(self.root, \"ids\", \"blocks\", region + \"_valid.txt\")\n",
    "            \n",
    "            self.read_ids = self.read_ids_blocks\n",
    "            \n",
    "        self.mapping = pd.read_csv(classmapping, index_col=0).sort_values(by=\"id\")\n",
    "        self.mapping = self.mapping.set_index(\"nutzcode\")\n",
    "        self.classes = self.mapping[\"id\"].unique()\n",
    "        self.classname = self.mapping.groupby(\"id\").first().classname.values\n",
    "        self.klassenname = self.mapping.groupby(\"id\").first().klassenname.values\n",
    "        self.nclasses = len(self.classes)\n",
    "        \n",
    "        self.region = region\n",
    "        self.partition = partition\n",
    "        self.data_folder = \"{root}/csv/{region}\".format(root=self.root, region=self.region)\n",
    "        self.samplet = samplet\n",
    "        \n",
    "        print(\"Initializing BavarianCropsDataset {} partition in {}\".format(self.partition, self.region))\n",
    "        \n",
    "        self.cache = os.path.join(self.root,\"npy\",os.path.basename(classmapping), scheme,region, partition)\n",
    "        print(\"read {} classes\".format(self.nclasses))\n",
    "        \n",
    "        if cache and self.cache_exists() and not self.mapping_consistent_with_cache():\n",
    "            self.clean_cache()\n",
    "        \n",
    "        if cache and self.cache_exists() and self.mapping_consistent_with_cache():\n",
    "            print(\"precached dataset files found at \" + self.cache)\n",
    "            self.load_cached_dataset()\n",
    "        else:\n",
    "            print(\"no cached dataset found. iterating through csv folders in \" + str(self.data_folder))\n",
    "            self.cache_dataset()\n",
    "        \n",
    "        self.hist, _ = np.histogram(self.y, bins=self.nclasses)\n",
    "        print(\"loaded {} samples\".format(len(self.ids)))\n",
    "        print(self)\n",
    "    \n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"Dataset {}. region {}. partition {}. X:{}, y:{} with {} classes\".format(self.root, self.region, \n",
    "                                                                                        self.partition,str(len(self.X)) +\"x\"+ \n",
    "                                                                                        str(self.X[0].shape), self.y.shape, \n",
    "                                                                                        self.nclasses)\n",
    "    \n",
    "    def read_ids_random(self):\n",
    "        assert isinstance(self.seed, int)\n",
    "        assert isinstance(self.validfraction, float)\n",
    "        assert self.partition in [\"train\", \"valid\", \"test\"]\n",
    "        assert self.trainids is not None\n",
    "        assert os.path.exists(self.trainids)\n",
    "\n",
    "        np.random.seed(self.seed)\n",
    "\n",
    "        \"\"\"if trainids file provided and no testids file <- sample holdback set from trainids\"\"\"\n",
    "        if self.testids is None:\n",
    "            assert self.partition in [\"train\", \"valid\"]\n",
    "\n",
    "            print(\"partition {} and no test ids file provided.\\ \n",
    "                  Splitting trainids file in train and valid partitions\".format(self.partition))\n",
    "\n",
    "            with open(self.trainids,\"r\") as f:\n",
    "                ids = [int(id) for id in f.readlines()]\n",
    "            print(\"Found {} ids in {}\".format(len(ids), self.trainids))\n",
    "\n",
    "            np.random.shuffle(ids)\n",
    "\n",
    "            validsize = int(len(ids) * self.validfraction)\n",
    "            validids = ids[:validsize]\n",
    "            trainids = ids[validsize:]\n",
    "\n",
    "            print(\"splitting {} ids in {} for training and {} for validation\".format(len(ids), \n",
    "                                                                                     len(trainids), len(validids)))\n",
    "\n",
    "            assert len(validids) + len(trainids) == len(ids)\n",
    "\n",
    "            if self.partition == \"train\":\n",
    "                return trainids\n",
    "            if self.partition == \"valid\":\n",
    "                return validids\n",
    "\n",
    "        elif self.testids is not None:\n",
    "            assert self.partition in [\"train\", \"test\"]\n",
    "\n",
    "            if self.partition==\"test\":\n",
    "                with open(self.testids,\"r\") as f:\n",
    "                    test_ids = [int(id) for id in f.readlines()]\n",
    "                print(\"Found {} ids in {}\".format(len(test_ids), self.testids))\n",
    "                return test_ids\n",
    "\n",
    "            if self.partition == \"train\":\n",
    "                with open(self.trainids, \"r\") as f:\n",
    "                    train_ids = [int(id) for id in f.readlines()]\n",
    "                return train_ids\n",
    "    \n",
    "    \n",
    "    def read_ids_blocks(self):\n",
    "        assert self.partition in [\"train\", \"valid\", \"test\", \"trainvalid\"]\n",
    "        assert os.path.exists(self.validids)\n",
    "        assert os.path.exists(self.testids)\n",
    "        assert os.path.exists(self.trainids)\n",
    "        assert self.scheme == \"blocks\"\n",
    "        assert self.mode is None\n",
    "\n",
    "        def read(filename):\n",
    "            with open(filename, \"r\") as f:\n",
    "                ids = [int(id) for id in f.readlines()]\n",
    "            return ids\n",
    "\n",
    "        if self.partition == \"train\":\n",
    "            ids = read(self.trainids)\n",
    "        elif self.partition == \"valid\":\n",
    "            ids = read(self.validids)\n",
    "        elif self.partition == \"test\":\n",
    "            ids = read(self.testids)\n",
    "        elif self.partition == \"trainvalid\":\n",
    "            ids = read(self.trainids) + read(self.validids)\n",
    "        return ids\n",
    "    \n",
    "    \n",
    "    def cache_dataset(self):\n",
    "        \"\"\"\n",
    "        Iterates though the data folders and stores y, ids, classweights, and sequencelengths\n",
    "        X is loaded at with getitem\n",
    "        \"\"\"\n",
    "        #ids = self.split(self.partition)\n",
    "\n",
    "        ids = self.read_ids()\n",
    "        assert len(ids) > 0\n",
    "\n",
    "        self.X = list()\n",
    "        self.nutzcodes = list()\n",
    "        self.stats = dict(not_found=list())\n",
    "        self.ids = list()\n",
    "        self.samples = list()\n",
    "\n",
    "        for id in tqdm.tqdm(ids):\n",
    "\n",
    "            id_file = self.data_folder + \"/{id}.csv\".format(id=id)\n",
    "            if os.path.exists(id_file):\n",
    "                self.samples.append(id_file)\n",
    "\n",
    "                X,nutzcode = self.load(id_file)\n",
    "\n",
    "                if len(nutzcode) > 0:\n",
    "                    nutzcode = nutzcode[0]\n",
    "                    if nutzcode in self.mapping.index:\n",
    "                        self.X.append(X)\n",
    "                        self.nutzcodes.append(nutzcode)\n",
    "                        self.ids.append(id)\n",
    "            else:\n",
    "                self.stats[\"not_found\"].append(id_file)\n",
    "\n",
    "        self.y = self.applyclassmapping(self.nutzcodes)\n",
    "\n",
    "        self.sequencelengths = np.array([np.array(X).shape[0] for X in self.X])\n",
    "        assert len(self.sequencelengths) > 0\n",
    "        self.sequencelength = self.sequencelengths.max()\n",
    "        self.ndims = np.array(X).shape[1]\n",
    "\n",
    "        self.hist,_ = np.histogram(self.y, bins=self.nclasses)\n",
    "        self.classweights = 1 / self.hist\n",
    "        self.cache_variables(self.y, self.sequencelengths, self.ids, self.ndims, self.X, self.classweights)\n",
    "    \n",
    "    \n",
    "    def mapping_consistent_with_cache(self):\n",
    "        # cached y must have the same number of classes than the mapping\n",
    "        return True\n",
    "        #return len(np.unique(np.load(os.path.join(self.cache, \"y.npy\")))) == self.nclasses\n",
    "    \n",
    "    \n",
    "    def cache_variables(self, y, sequencelengths, ids, ndims, X, classweights):\n",
    "        os.makedirs(self.cache, exist_ok=True)\n",
    "        # cache\n",
    "        np.save(os.path.join(self.cache, \"classweights.npy\"), classweights)\n",
    "        np.save(os.path.join(self.cache, \"y.npy\"), y)\n",
    "        np.save(os.path.join(self.cache, \"ndims.npy\"), ndims)\n",
    "        np.save(os.path.join(self.cache, \"sequencelengths.npy\"), sequencelengths)\n",
    "        np.save(os.path.join(self.cache, \"ids.npy\"), ids)\n",
    "        #np.save(os.path.join(self.cache, \"dataweights.npy\"), dataweights)\n",
    "        np.save(os.path.join(self.cache, \"X.npy\"), X)\n",
    "    \n",
    "    def load_cached_dataset(self):\n",
    "        # load\n",
    "        self.classweights = np.load(os.path.join(self.cache, \"classweights.npy\"))\n",
    "        self.y = np.load(os.path.join(self.cache, \"y.npy\"))\n",
    "        self.ndims = int(np.load(os.path.join(self.cache, \"ndims.npy\")))\n",
    "        self.sequencelengths = np.load(os.path.join(self.cache, \"sequencelengths.npy\"))\n",
    "        self.sequencelength = self.sequencelengths.max()\n",
    "        self.ids = np.load(os.path.join(self.cache, \"ids.npy\"))\n",
    "        self.X = np.load(os.path.join(self.cache, \"X.npy\"), allow_pickle=True)\n",
    "    \n",
    "    \n",
    "    def cache_exists(self):\n",
    "        weightsexist = os.path.exists(os.path.join(self.cache, \"classweights.npy\"))\n",
    "        yexist = os.path.exists(os.path.join(self.cache, \"y.npy\"))\n",
    "        ndimsexist = os.path.exists(os.path.join(self.cache, \"ndims.npy\"))\n",
    "        sequencelengthsexist = os.path.exists(os.path.join(self.cache, \"sequencelengths.npy\"))\n",
    "        idsexist = os.path.exists(os.path.join(self.cache, \"ids.npy\"))\n",
    "        Xexists = os.path.exists(os.path.join(self.cache, \"X.npy\"))\n",
    "        return yexist and sequencelengthsexist and idsexist and ndimsexist and Xexists and weightsexist\n",
    "    \n",
    "    \n",
    "    def clean_cache(self):\n",
    "        os.remove(os.path.join(self.cache, \"classweights.npy\"))\n",
    "        os.remove(os.path.join(self.cache, \"y.npy\"))\n",
    "        os.remove(os.path.join(self.cache, \"ndims.npy\"))\n",
    "        os.remove(os.path.join(self.cache, \"sequencelengths.npy\"))\n",
    "        os.remove(os.path.join(self.cache, \"ids.npy\"))\n",
    "        #os.remove(os.path.join(self.cache, \"dataweights.npy\"))\n",
    "        os.remove(os.path.join(self.cache, \"X.npy\"))\n",
    "        os.removedirs(self.cache)\n",
    "    \n",
    "    \n",
    "    def load(self, csv_file, load_pandas = False):\n",
    "        \"\"\"['B1', 'B10', 'B11', 'B12', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8',\n",
    "       'B8A', 'B9', 'QA10', 'QA20', 'QA60', 'doa', 'label', 'id']\"\"\"\n",
    "\n",
    "        if load_pandas:\n",
    "            sample = pd.read_csv(csv_file, index_col=0)\n",
    "            X = np.array((sample[BANDS] * NORMALIZING_FACTOR).values)\n",
    "            nutzcodes = sample[\"label\"].values\n",
    "            # nutzcode to classids (451,411) -> (0,1)\n",
    "\n",
    "        else: # load with numpy\n",
    "            data = genfromtxt(csv_file, delimiter=',', skip_header=1)\n",
    "            X = data[:, 1:14] * NORMALIZING_FACTOR\n",
    "            nutzcodes = data[:, 18]\n",
    "\n",
    "        # drop times that contain nans\n",
    "        if np.isnan(X).any():\n",
    "            t_without_nans = np.isnan(X).sum(1) > 0\n",
    "\n",
    "            X = X[~t_without_nans]\n",
    "            nutzcodes = nutzcodes[~t_without_nans]\n",
    "\n",
    "        return X, nutzcodes\n",
    "    \n",
    "    \n",
    "    def applyclassmapping(self, nutzcodes):\n",
    "        \"\"\"uses a mapping table to replace nutzcodes (e.g. 451, 411) with class ids\"\"\"\n",
    "        return np.array([self.mapping.loc[nutzcode][\"id\"] for nutzcode in nutzcodes])\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        load_file = False\n",
    "        if load_file:\n",
    "            id = self.ids[idx]\n",
    "            csvfile = os.path.join(self.data_folder, \"{}.csv\".format(id))\n",
    "            X,nutzcodes = self.load(csvfile)\n",
    "            y = self.applyclassmapping(nutzcodes=nutzcodes)\n",
    "        else:\n",
    "\n",
    "            X = self.X[idx]\n",
    "            y = np.array([self.y[idx]] * X.shape[0]) # repeat y for each entry in x\n",
    "\n",
    "        # pad up to maximum sequence length\n",
    "        t = X.shape[0]\n",
    "\n",
    "        if self.samplet is None:\n",
    "            npad = self.sequencelengths.max() - t\n",
    "            X = np.pad(X,[(0,npad), (0,0)],'constant', constant_values=PADDING_VALUE)\n",
    "            y = np.pad(y, (0, npad), 'constant', constant_values=PADDING_VALUE)\n",
    "        else:\n",
    "            idxs = np.random.choice(t, self.samplet, replace=False)\n",
    "            idxs.sort()\n",
    "            X = X[idxs]\n",
    "            y = y[idxs]\n",
    "\n",
    "\n",
    "        X = torch.from_numpy(X).type(torch.FloatTensor)\n",
    "        y = torch.from_numpy(y).type(torch.LongTensor)\n",
    "\n",
    "        return X, y, self.ids[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import bisect\n",
    "import warnings\n",
    "\n",
    "class ConcatDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Dataset to concatenate multiple datasets.\n",
    "    Purpose: useful to assemble different existing datasets, possibly\n",
    "    large-scale datasets as the concatenation operation is done in an\n",
    "    on-the-fly manner.\n",
    "    Arguments:\n",
    "        datasets (sequence): List of datasets to be concatenated\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def cumsum(sequence):\n",
    "        r, s = [], 0\n",
    "        for e in sequence:\n",
    "            l = len(e)\n",
    "            r.append(l + s)\n",
    "            s += l\n",
    "        return r\n",
    "\n",
    "    def __init__(self, datasets):\n",
    "        super(ConcatDataset, self).__init__()\n",
    "        assert len(datasets) > 0, 'datasets should not be an empty iterable'\n",
    "        self.datasets = list(datasets)\n",
    "        self.nclasses = datasets[0].nclasses\n",
    "        self.mapping = datasets[0].mapping\n",
    "        self.classes = datasets[0].classes\n",
    "        self.sequencelength = datasets[0].sequencelength\n",
    "        self.sequencelengths = datasets[0].sequencelengths\n",
    "        self.ndims = datasets[0].ndims\n",
    "        self.classweights = datasets[0].classweights\n",
    "        self.classname = datasets[0].classname\n",
    "        self.klassenname = datasets[0].klassenname\n",
    "        self.hist = np.array([d.hist for d in self.datasets]).sum(0)\n",
    "        self.partition = self.datasets[0].partition\n",
    "\n",
    "        self.y = np.concatenate([d.y for d in self.datasets], axis=0)\n",
    "        self.cumulative_sizes = self.cumsum(self.datasets)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.cumulative_sizes[-1]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx < 0:\n",
    "            if -idx > len(self):\n",
    "                raise ValueError(\"absolute value of index should not exceed dataset length\")\n",
    "            idx = len(self) + idx\n",
    "        dataset_idx = bisect.bisect_right(self.cumulative_sizes, idx)\n",
    "        if dataset_idx == 0:\n",
    "            sample_idx = idx\n",
    "        else:\n",
    "            sample_idx = idx - self.cumulative_sizes[dataset_idx - 1]\n",
    "        return self.datasets[dataset_idx][sample_idx]\n",
    "\n",
    "    @property\n",
    "    def cummulative_sizes(self):\n",
    "        warnings.warn(\"cummulative_sizes attribute is renamed to \"\n",
    "                      \"cumulative_sizes\", DeprecationWarning, stacklevel=2)\n",
    "        return self.cumulative_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(args):\n",
    "\n",
    "    if args.dataset == \"BavarianCrops\":\n",
    "        root = os.path.join(args.dataroot,\"BavarianCrops\")\n",
    "\n",
    "        #ImbalancedDatasetSampler\n",
    "        test_dataset_list = list()\n",
    "        for region in args.testregions:\n",
    "            test_dataset_list.append(\n",
    "                BavarianCropsDataset(root=root, region=region, partition=args.test_on,\n",
    "                                            classmapping=args.classmapping, samplet=args.samplet,\n",
    "                                     scheme=args.scheme,mode=args.mode, seed=args.seed)\n",
    "            )\n",
    "\n",
    "        train_dataset_list = list()\n",
    "        for region in args.trainregions:\n",
    "            train_dataset_list.append(\n",
    "                BavarianCropsDataset(root=root, region=region, partition=args.train_on,\n",
    "                                            classmapping=args.classmapping, samplet=args.samplet,\n",
    "                                     scheme=args.scheme,mode=args.mode, seed=args.seed)\n",
    "            )\n",
    "\n",
    "    if args.dataset == \"VNRice\":\n",
    "        train_dataset_list=[VNRiceDataset(root=args.root, partition=args.train_on, samplet=args.samplet,\n",
    "                                          mode=args.mode, seed=args.seed)]\n",
    "\n",
    "        test_dataset_list=[VNRiceDataset(root=args.root, partition=args.test_on, samplet=args.samplet,\n",
    "                                         mode=args.mode, seed=args.seed)]\n",
    "\n",
    "    if args.dataset == \"BreizhCrops\":\n",
    "        root = \"/home/marc/projects/BreizhCrops/data\"\n",
    "\n",
    "        train_dataset_list = list()\n",
    "        for region in args.trainregions:\n",
    "            train_dataset_list.append(\n",
    "                CropsDataset(root=root, region=region, samplet=args.samplet)\n",
    "            )\n",
    "\n",
    "        #ImbalancedDatasetSampler\n",
    "        test_dataset_list = list()\n",
    "        for region in args.testregions:\n",
    "            test_dataset_list.append(\n",
    "                CropsDataset(root=root, region=region, samplet=args.samplet)\n",
    "            )\n",
    "\n",
    "    elif args.dataset == \"GAFv2\":\n",
    "        root = os.path.join(args.dataroot,\"GAFdataset\")\n",
    "\n",
    "        #ImbalancedDatasetSampler\n",
    "        test_dataset_list = list()\n",
    "        for region in args.testregions:\n",
    "            test_dataset_list.append(\n",
    "                GAFDataset(root, region=region, partition=\"test\", scheme=args.scheme, classmapping=args.classmapping, features=args.features)\n",
    "            )\n",
    "\n",
    "        train_dataset_list = list()\n",
    "        for region in args.trainregions:\n",
    "            train_dataset_list.append(\n",
    "                GAFDataset(root, region=region, partition=\"train\", scheme=args.scheme, classmapping=args.classmapping, features=args.features)\n",
    "            )\n",
    "\n",
    "    print(\"setting random seed to \"+str(args.seed))\n",
    "    np.random.seed(args.seed)\n",
    "    if args.seed is not None:\n",
    "        torch.random.manual_seed(args.seed)\n",
    "\n",
    "    traindataset = ConcatDataset(train_dataset_list)\n",
    "    traindataloader = torch.utils.data.DataLoader(dataset=traindataset, sampler=RandomSampler(traindataset),\n",
    "                                                  batch_size=args.batchsize, num_workers=args.workers)\n",
    "\n",
    "    testdataset = ConcatDataset(test_dataset_list)\n",
    "\n",
    "    testdataloader = torch.utils.data.DataLoader(dataset=testdataset, sampler=SequentialSampler(testdataset),\n",
    "                                                 batch_size=args.batchsize, num_workers=args.workers)\n",
    "\n",
    "    return traindataloader, testdataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Loss functions, Accuracy Metric and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import torch\n",
    "from torch import nn\n",
    "\"\"\"\n",
    "\n",
    "class BalancedCrossEntropyLoss(nn.Module):\n",
    "    '''\n",
    "    Balanced cross entropy loss by weighting of inverse class ratio\n",
    "    Params:\n",
    "        ignore_index (int): Class index to ignore\n",
    "        reduction (str): Reduction method to apply, return mean over batch if 'mean',\n",
    "            return sum if 'sum', return a tensor of shape [N,] if 'none'\n",
    "    Returns:\n",
    "        Loss tensor according to arg reduction\n",
    "    '''\n",
    "\n",
    "    def __init__(self, ignore_index=-100, reduction='mean'):\n",
    "        super(BalancedCrossEntropyLoss, self).__init__()\n",
    "        self.ignore_index = ignore_index\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, predict, target):\n",
    "        #set_trace()\n",
    "        # get class weights\n",
    "        unique, unique_counts = torch.unique(target, return_counts=True)\n",
    "        # calculate weight for only valid indices\n",
    "        unique_counts = unique_counts[unique != self.ignore_index]\n",
    "        unique = unique[unique != self.ignore_index]\n",
    "        ratio = unique_counts.float() / torch.numel(target)\n",
    "        weight = (1. / ratio) / torch.sum(1. / ratio)\n",
    "\n",
    "        lossWeight = torch.ones(predict.shape[1]).cuda() * 0.00001\n",
    "        for i in range(len(unique)):\n",
    "            lossWeight[unique[i]] = weight[i]\n",
    "        loss = nn.CrossEntropyLoss(weight=lossWeight, ignore_index=self.ignore_index, reduction=self.reduction)\n",
    "\n",
    "        return loss(predict, target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "import os\n",
    "\"\"\"\n",
    "# Conv_based Expansive Prametric Spectral Index\n",
    "class CEPSI(torch.nn.Module):\n",
    "    def __init__(self, input_dim, expanded_dim):\n",
    "        super(CEPSI, self).__init__()\n",
    "\n",
    "        layers = [nn.Conv1d(input_dim, input_dim, kernel_size = 1, stride = 1, padding = 0, bias=False),\n",
    "                  nn.BatchNorm1d(input_dim),\n",
    "                  nn.ReLU(inplace = True),]\n",
    "        \n",
    "        layers += [nn.Conv1d(input_dim, expanded_dim, kernel_size = 1, stride = 1, padding = 0, bias=False),\n",
    "                  nn.BatchNorm1d(expanded_dim),\n",
    "                  nn.ReLU(inplace = True),]\n",
    "        \n",
    "        layers += [nn.Conv1d(expanded_dim, expanded_dim, kernel_size = 1, stride = 1, padding = 0, bias=False),\n",
    "                  nn.BatchNorm1d(expanded_dim),\n",
    "                  nn.ReLU(inplace = True),]\n",
    "        \n",
    "        self.block = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.block(inputs)\n",
    "\n",
    "###################################################################################################\n",
    "\n",
    "# Dot-product attention between Bi-LSTM last states and its output.\n",
    "class attention(nn.Module):\n",
    "    def __init__(self, attn_dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dropout = nn.Dropout(attn_dropout)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, q, k, v):\n",
    "        #set_trace()\n",
    "        query = q.unsqueeze(1)\n",
    "        \n",
    "        key = k.transpose(2,1).contiguous()\n",
    "        weight_score = torch.bmm(query, key)\n",
    "        \n",
    "        attn = self.softmax(weight_score)\n",
    "        attn = self.dropout(attn)\n",
    "        output = torch.bmm(attn, v)\n",
    "        \n",
    "        return output, attn\n",
    "\n",
    "###########################################################################################\n",
    "\n",
    "class Double_branch_stacked_biLSTM(torch.nn.Module):\n",
    "    def __init__(self, input_dims = (4, 16), hidden_dim = 128, n_classes = 6, n_layers = 4, \n",
    "                 dropout_rate = 0.57, s1_weight = 0.8, bidirectional = True, use_layernorm = True, \n",
    "                 use_batchnorm = False, use_attention = False, use_cepsi=False):\n",
    "        super(Double_branch_stacked_biLSTM, self).__init__()\n",
    "        \n",
    "        # Define object properties\n",
    "        self.n_classes = n_classes\n",
    "        self.s1_weight = s1_weight\n",
    "        self.bidirectional = bidirectional\n",
    "        self.use_layernorm = use_layernorm\n",
    "        self.use_batchnorm = use_batchnorm\n",
    "        self.use_attention = use_attention\n",
    "        self.use_cepsi = use_cepsi\n",
    "        self.model_depth = n_layers * hidden_dim\n",
    "        \n",
    "        # Get the input dimensions for Sentinel-1 and 2 datasets\n",
    "        if isinstance(input_dims, tuple) or isinstance(input_dims, list):\n",
    "            s1_in_dim = input_dims[0]\n",
    "            s2_in_dim = input_dims[1]\n",
    "            \n",
    "        if self.use_cepsi:\n",
    "            s1_expanded_dim = input_dims[0] * 2\n",
    "            s2_expanded_dim = input_dims[1] * 3\n",
    "            self.s1_cepsi = CEPSI(s1_in_dim, s1_expanded_dim)\n",
    "            self.s2_cepsi = CEPSI(s2_in_dim, s2_expanded_dim)\n",
    "        \n",
    "        \n",
    "        # Layer normalization for s1, s2 inputs and current_states of LSTM\n",
    "        if self.use_layernorm:\n",
    "            self.s1_inlayernorm = nn.LayerNorm(s1_expanded_dim if self.use_cepsi else s1_in_dim)\n",
    "            self.s2_inlayernorm = nn.LayerNorm(s2_expanded_dim if self.use_cepsi else s2_in_dim)\n",
    "            self.clayernorm = nn.LayerNorm((hidden_dim + hidden_dim * self.bidirectional) * n_layers)\n",
    "        \n",
    "        # LSTM layers for s1 and s2\n",
    "        self.s1_lstm = nn.LSTM(input_size = s1_expanded_dim if self.use_cepsi else s1_in_dim, hidden_size = hidden_dim, \n",
    "                               num_layers = n_layers, bias = False, batch_first = True, dropout = dropout_rate, \n",
    "                               bidirectional = self.bidirectional)\n",
    "        self.s2_lstm = nn.LSTM(input_size = s2_expanded_dim if self.use_cepsi else s2_in_dim, hidden_size = hidden_dim, \n",
    "                               num_layers = n_layers, bias = False, batch_first = True, dropout = dropout_rate, \n",
    "                               bidirectional = self.bidirectional)\n",
    "        \n",
    "        if self.bidirectional:\n",
    "            hidden_dim = hidden_dim * 2\n",
    "        \n",
    "        if self.use_attention:\n",
    "            self.attention = attention()\n",
    "        \n",
    "        # MLP layer on top of LSTM\n",
    "        linear_input_dim = hidden_dim if self.use_attention else hidden_dim * n_layers\n",
    "        self.linear_class = nn.Linear(linear_input_dim, self.n_classes, bias = True)\n",
    " \n",
    "\n",
    "    def _logits(self, s1, s2):\n",
    "        #set_trace()\n",
    "        if self.use_cepsi:\n",
    "            s1 = self.s1_cepsi(s1.transpose(2,1).contiguous())\n",
    "            s2 = self.s2_cepsi(s2.transpose(2,1).contiguous())\n",
    "        \n",
    "        if self.use_layernorm:\n",
    "            s1 = self.s1_inlayernorm(s1.transpose(2,1).contiguous() if self.use_cepsi else s1)\n",
    "            s2 = self.s2_inlayernorm(s2.transpose(2,1).contiguous() if self.use_cepsi else s2)\n",
    "        \n",
    "        # Get outputs and the last current state and hidden state for each branch.\n",
    "        #s1_outputs & s2_outputs: [B, Seq_length, 2 x hidden_dim]\n",
    "        s1_outputs, s1_last_state_list = self.s1_lstm.forward(s1)\n",
    "        s2_outputs, s2_last_state_list = self.s2_lstm.forward(s2)\n",
    "        \n",
    "        #s1_h & s1_c & s2_h & s2_c: [2 x num_layers, B, hidden_dim] \n",
    "        s1_h, s1_c = s1_last_state_list\n",
    "        s2_h, s2_c = s2_last_state_list\n",
    "        \n",
    "        # Get the query layer to calculate self attention for each branch\n",
    "        if self.use_attention:\n",
    "            if self.bidirectional:\n",
    "                # Get the last state of each branch. size:[B, hidden_dim]\n",
    "                s1_query_forward = s1_c[-1]\n",
    "                s1_query_backward = s1_c[-2]\n",
    "                # size:[B, 2 x hidden_dim]\n",
    "                s1_query = torch.cat([s1_query_forward, s1_query_backward], 1)\n",
    "                \n",
    "                s2_query_forward = s2_c[-1]\n",
    "                s2_query_backward = s2_c[-2]\n",
    "                s2_query = torch.cat([s2_query_forward, s2_query_backward], 1)\n",
    "            else:\n",
    "                s1_query = s1_c[-1]\n",
    "                s2_query = s2_c[-1]\n",
    "            \n",
    "            # Get attention weights and hidden state\n",
    "            s1_h, s1_weights = self.attention(s1_query, s1_outputs, s1_outputs)\n",
    "            s2_h, s2_weights = self.attention(s2_query, s2_outputs, s2_outputs)\n",
    "            s1_h = s1_h.squeeze(1)\n",
    "            s2_h = s2_h.squeeze(1)\n",
    "        else:\n",
    "            s1_nlayers, s1_batchsize, s1_n_hidden = s1_c.shape\n",
    "            s2_nlayers, s2_batchsize, s2_n_hidden = s2_c.shape\n",
    "            s1_h = self.clayernorm(s1_c.transpose(0,1).contiguous().view(s1_batchsize, s1_nlayers * s1_n_hidden))\n",
    "            s2_h = self.clayernorm(s2_c.transpose(0,1).contiguous().view(s2_batchsize, s2_nlayers * s2_n_hidden))\n",
    "        \n",
    "        # Calculate logits for each branch. Shape:[B, num_classes]\n",
    "        s1_logits = self.linear_class.forward(s1_h)\n",
    "        s2_logits = self.linear_class.forward(s2_h)\n",
    "        \n",
    "        if self.use_attention:\n",
    "            s1_pts = s1_weights\n",
    "            s2_pts = s2_weights\n",
    "        else:\n",
    "            s1_pts = None\n",
    "            s2_pts = None\n",
    "        \n",
    "        return s1_logits, s2_logits, s1_pts, s2_pts\n",
    "    \n",
    "    def forward(self, s1, s2):\n",
    "        s1_logits, s2_logits, s1_pts, s2_pts = self._logits(s1, s2)\n",
    "        out_logits = (s1_logits * self.s1_weight) + (s2_logits * (1 - self.s1_weight))\n",
    "        #s1_logprob = F.log_softmax(s1_logits, dim=-1)\n",
    "        #s2_logprob = F.log_softmax(s2_logits, dim=-1)\n",
    "        \n",
    "        return out_logits\n",
    "        #return s1_logprob, s2_logprob\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Inference procedure (In Progress )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from datetime import datetime\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\"\"\"\n",
    "\n",
    "def get_optimizer(optimizer, params, lr, momentum):\n",
    "\n",
    "    optimizer = optimizer.lower()\n",
    "    if optimizer == 'sgd':\n",
    "        return torch.optim.SGD(params, lr, momentum=momentum)\n",
    "    elif optimizer == 'nesterov':\n",
    "        return torch.optim.SGD(params, lr, momentum=momentum, nesterov=True)\n",
    "    elif optimizer == 'adam':\n",
    "        return torch.optim.Adam(params, lr)\n",
    "    elif optimizer == 'amsgrad':\n",
    "        return torch.optim.Adam(params, lr, amsgrad=True)\n",
    "    else:\n",
    "        raise ValueError(\"{} currently not supported, please customize your optimizer in compiler.py\".format(optimizer))\n",
    "\n",
    "###############################################################################################\n",
    "\n",
    "class PolynomialLR(_LRScheduler):\n",
    "    \"\"\"Polynomial learning rate decay until step reach to max_decay_step\n",
    "    \n",
    "    Args:\n",
    "        optimizer (Optimizer): Wrapped optimizer.\n",
    "        max_decay_steps: after this step, we stop decreasing learning rate\n",
    "        min_learning_rate: scheduler stoping learning rate decay, value of learning rate must be this value\n",
    "        power: The power of the polynomial.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, optimizer, max_decay_steps, min_learning_rate=1e-5, power=1.0):\n",
    "        if max_decay_steps <= 1.:\n",
    "            raise ValueError('max_decay_steps should be greater than 1.')\n",
    "        self.max_decay_steps = max_decay_steps\n",
    "        self.min_learning_rate = min_learning_rate\n",
    "        self.power = power\n",
    "        self.last_step = 0\n",
    "        super().__init__(optimizer)\n",
    "        \n",
    "    def get_lr(self):\n",
    "        if self.last_step > self.max_decay_steps:\n",
    "            return [self.min_learning_rate for _ in self.base_lrs]\n",
    "\n",
    "        return [(base_lr - self.min_learning_rate) * \n",
    "                ((1 - self.last_step / self.max_decay_steps) ** (self.power)) + \n",
    "                self.min_learning_rate for base_lr in self.base_lrs]\n",
    "    \n",
    "    def step(self, step=None):\n",
    "        if step is None:\n",
    "            step = self.last_step + 1\n",
    "        self.last_step = step if step != 0 else 1\n",
    "        if self.last_step <= self.max_decay_steps:\n",
    "            decay_lrs = [(base_lr - self.min_learning_rate) * \n",
    "                         ((1 - self.last_step / self.max_decay_steps) ** (self.power)) + \n",
    "                         self.min_learning_rate for base_lr in self.base_lrs]\n",
    "            for param_group, lr in zip(self.optimizer.param_groups, decay_lrs):\n",
    "                param_group['lr'] = lr\n",
    "\n",
    "##########################################################################\n",
    "\n",
    "class ModelCompiler:\n",
    "    '''\n",
    "    Compiler of specified model\n",
    "    Attributes:\n",
    "        model (''nn.Module''): pytorch model for segmentation\n",
    "        classNum (int): output class number of given model\n",
    "        buffer (int): distance to sample edges not considered in optimization\n",
    "        gpuDevices (list): indices of gpu devices to use\n",
    "        params_init (dict): initial model parameters\n",
    "    '''\n",
    "\n",
    "    def __init__(self, model, gpuDevices=[0], params_init=None, freeze_params = None):\n",
    "\n",
    "        self.s3_client = boto3.client(\"s3\")\n",
    "        self.working_dir = config[\"working_dir\"]\n",
    "        self.out_dir = config[\"out_dir\"]\n",
    "        self.gpuDevices = gpuDevices\n",
    "        self.model = model\n",
    "        \n",
    "        self.model_name = self.model.__class__.__name__\n",
    "\n",
    "        if params_init:\n",
    "            self.load_params(params_init, freeze_params)\n",
    "\n",
    "        # gpu\n",
    "        self.gpu = torch.cuda.is_available()\n",
    "        if self.gpu:\n",
    "            print(\"----------GPU available----------\")\n",
    "            # GPU setting\n",
    "            if gpuDevices:\n",
    "                torch.cuda.set_device(gpuDevices[0])\n",
    "                self.model = torch.nn.DataParallel(self.model, device_ids=gpuDevices)\n",
    "            self.model = self.model.cuda()\n",
    "        \n",
    "        num_params = sum([p.numel() for p in self.model.parameters() if p.requires_grad])\n",
    "        print(\"total number of trainable parameters: {:2.1f}M\".format(num_params / 1000000))\n",
    "        \n",
    "        if params_init:\n",
    "            print(\"---------- Pre-trained model compiled successfully ----------\")\n",
    "        else:\n",
    "            print(\"---------- Vanilla Model compiled successfully ----------\")\n",
    "\n",
    "\n",
    "    def load_params(self, dir_params, freeze_params):\n",
    "\n",
    "        params_init = urlparse.urlparse(dir_params)\n",
    "        # load from s3\n",
    "        if params_init.scheme == \"s3\":\n",
    "            \n",
    "            bucket = params_init.netloc\n",
    "            params_key = params_init.path\n",
    "            params_key = params_key[1:] if params_key.startswith('/') else params_key\n",
    "            _, fn_params = os.path.split(params_key)\n",
    "\n",
    "            self.s3_client.download_file(Bucket=bucket,\n",
    "                                         Key=params_key,\n",
    "                                         Filename=fn_params)\n",
    "            inparams = torch.load(fn_params, map_location=\"cuda:{}\".format(self.gpuDevices[0]))\n",
    "\n",
    "            os.remove(fn_params)  # remove after loaded\n",
    "\n",
    "        ## or load from local\n",
    "        else:\n",
    "            inparams = torch.load(dir_params)\n",
    "\n",
    "        ## overwrite model entries with new parameters\n",
    "        model_dict = self.model.state_dict()\n",
    "\n",
    "        if \"module\" in list(inparams.keys())[0]:\n",
    "            inparams_filter = {k[7:]: v.cpu() for k, v in inparams.items() if k[7:] in model_dict}\n",
    "\n",
    "        else:\n",
    "            inparams_filter = {k: v.cpu() for k, v in inparams.items() if k in model_dict}\n",
    "        \n",
    "        model_dict.update(inparams_filter)\n",
    "        self.model.load_state_dict(model_dict)\n",
    "        \n",
    "        if freeze_params != None:\n",
    "            for i, p in enumerate(self.model.parameters()):\n",
    "                if i in freeze_params:\n",
    "                    p.requires_grad = False\n",
    "\n",
    "\n",
    "    def fit(self, trainDataset, valDataset, epochs, optimizer_name, lr_init, LR_policy, criterion, momentum = None):\n",
    "\n",
    "        # Set the folder to save results.\n",
    "        working_dir = self.working_dir\n",
    "        out_dir = self.out_dir\n",
    "        model_name = self.model_name\n",
    "        self.model_dir = \"{}/{}/{}_ep{}\".format(working_dir, self.out_dir, model_name, epochs)\n",
    "        \n",
    "        if not os.path.exists(Path(working_dir) / out_dir / self.model_dir):\n",
    "            os.makedirs(Path(working_dir) / out_dir / self.model_dir)\n",
    "        \n",
    "        os.chdir(Path(working_dir) / out_dir / self.model_dir)\n",
    "        \n",
    "        print(\"--------------- Start training ---------------\")\n",
    "        start = datetime.now()\n",
    "\n",
    "        # Tensorboard writer setting\n",
    "        writer = SummaryWriter('./')\n",
    "\n",
    "        train_loss = []\n",
    "        val_loss = []\n",
    "        lr = lr_init\n",
    "        \n",
    "        optimizer = get_optimizer(optimizer_name, self.model.parameters(), lr, momentum)\n",
    "        \n",
    "        # Initialize the learning rate scheduler\n",
    "        if LR_policy == \"StepLR\":\n",
    "            scheduler = optim.lr_scheduler.StepLR(optimizer, \n",
    "                                                  step_size = 10, \n",
    "                                                  gamma = 0.25,)\n",
    "        \n",
    "        elif LR_policy == \"PolynomialLR\":\n",
    "            scheduler = PolynomialLR(optimizer, \n",
    "                                     max_decay_steps=75, \n",
    "                                     min_learning_rate=1e-5, \n",
    "                                     power=0.85)\n",
    "        else:\n",
    "            scheduler = None  \n",
    "        \n",
    "        \n",
    "        for t in range(epochs):\n",
    "\n",
    "            print(\"[{}/{}]\".format(t + 1, epochs))\n",
    "            # start fitting\n",
    "            start_epoch = datetime.now()\n",
    "            train(trainDataset, self.model, criterion, optimizer, gpu=self.gpu, train_loss=train_loss)\n",
    "            validate(valDataset, self.model, criterion, gpu=self.gpu, val_loss=val_loss)\n",
    "\n",
    "            # Update the scheduler\n",
    "            if LR_policy == \"StepLR\":\n",
    "                scheduler.step()\n",
    "                print(\"LR: {}\".format(scheduler.get_last_lr()))\n",
    "\n",
    "            if LR_policy == \"PolynomialLR\":\n",
    "                scheduler.step(t)\n",
    "                print(\"LR: {}\".format(optimizer.param_groups[0]['lr']))\n",
    "            \n",
    "            # time spent on single iteration\n",
    "            print(\"time:\", (datetime.now() - start_epoch).seconds)\n",
    "\n",
    "            #if t > 1 and t % lr_decay[1] == 0:\n",
    "                #lr *= lr_decay[0]\n",
    "\n",
    "            writer.add_scalars(\"Loss\", {\"train_loss\": train_loss[t], \"validation_loss\": val_loss[t]}, t + 1)\n",
    "            \n",
    "            writer.close()\n",
    "        \n",
    "        print(\"--------------- Training finished in {}s ---------------\".format((datetime.now() - start).seconds))\n",
    "    \n",
    "    def accuracy_evaluation(self, evalDataset, outPrefix, bucket = None):\n",
    "        \n",
    "        if not os.path.exists(Path(self.working_dir) / self.out_dir):\n",
    "            os.makedirs(Path(self.working_dir) / self.out_dir)\n",
    "        \n",
    "        os.chdir(Path(self.working_dir) / self.out_dir)\n",
    "        \n",
    "        print(\"--------------- Start evaluation ---------------\")\n",
    "        start = datetime.now()\n",
    "        \n",
    "        accuracy_evaluation(evalDataset, self.model, self.gpu, outPrefix, bucket)\n",
    "        \n",
    "        print(\"--------------- Evaluation finished in {}s ---------------\".format((datetime.now() - start).seconds))\n",
    "        \n",
    "    def save(self, save_fldr, bucket = None, object = \"params\"):\n",
    "        \n",
    "        outPrefix = Path(self.working_dir) / self.out_dir / save_fldr\n",
    "        \n",
    "        if object == \"params\":\n",
    "            \n",
    "            fn_params = \"{}_params.pth\".format(self.model_name)\n",
    "            \n",
    "            if bucket:\n",
    "                torch.save(self.model.state_dict(), fn_params )\n",
    "\n",
    "                self.s3_client.upload_file(Filename=fn_params, \n",
    "                                           Bucket=bucket, \n",
    "                                           Key=os.path.join(outPrefix, fn_params))\n",
    "                print(\"model parameters uploaded to s3!, at \", outPrefix)\n",
    "                \n",
    "                os.remove(Path(outPrefix) / fn_params)\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                if not os.path.exists(Path(outPrefix)):\n",
    "                    os.makedirs(Path(outPrefix))\n",
    "                \n",
    "                torch.save(self.model.state_dict(), Path(outPrefix) / fn_params)\n",
    "                print(\"model parameters is saved locally, at \", outPrefix)\n",
    "            \n",
    "        elif object == \"model\":\n",
    "            \n",
    "            fn_model = \"{}.pth\".format(self.model_name)\n",
    "            \n",
    "            if bucket:\n",
    "                torch.save(self.model, fn_model)\n",
    "\n",
    "                self.s3_client.upload_file(Filename=fn_model,\n",
    "                                           Bucket=bucket, \n",
    "                                           Key=os.path.join(outPrefix, fn_model))\n",
    "                print(\"model uploaded to s3!, at \", outPrefix)\n",
    "                \n",
    "                os.remove(Path(outPrefix) / fn_params)\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                if not os.path.exists(Path(outPrefix)):\n",
    "                    os.makedirs(Path(outPrefix))\n",
    "                \n",
    "                torch.save(self.model, Path(outPrefix) / fn_params)\n",
    "                print(\"model saved locally, at \", outPrefix)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Object type is not acceptable.\")\n",
    "\n",
    "################################################################################################################\n",
    "################################### Train, Evaluate, Validate and Predict ######################################\n",
    "################################################################################################################\n",
    "\n",
    "def train(trainData, model, criterion, optimizer, gpu=True, train_loss=[]):\n",
    "    \n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    i = 0\n",
    "    \n",
    "    for s1_img, s2_img, label in trainData:\n",
    "        s1_img = Variable(s1_img)\n",
    "        #s1_img[s1_img != s1_img] = -100\n",
    "        s2_img = Variable(s2_img)\n",
    "        #s2_img[s2_img != s2_img] = -100\n",
    "        label = Variable(label)\n",
    "        \n",
    "        if gpu:\n",
    "            s1_img = s1_img.cuda()\n",
    "            s2_img = s2_img.cuda()\n",
    "            label = label.cuda()\n",
    "        \n",
    "        model_out = model(s1_img, s2_img)\n",
    "        loss = criterion()(model_out, label)\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        #s1_model_out,  s2_model_out= model(s1_img, s2_img)\n",
    "        #s1_loss = criterion()(s1_model_out, label)\n",
    "        #s2_loss = criterion()(s2_model_out, label)\n",
    "        #s1_weight = 0.8\n",
    "        #total_loss = s1_loss * s1_weight + s2_loss * (1 - s1_weight)\n",
    "        \n",
    "        \n",
    "        #epoch_loss += total_loss.item()\n",
    "        #print(\"train: \", i, epoch_loss)\n",
    "        i += 1\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        #total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(\"train loss: {}\".format(epoch_loss / i))\n",
    "    if train_loss != None:\n",
    "        train_loss.append(float(epoch_loss / i))\n",
    "\n",
    "##################################################\n",
    "\n",
    "def validate(evalData, model, criterion, gpu=True, val_loss=[]):\n",
    "    \n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    i = 0\n",
    "    #set_trace()\n",
    "    for s1_img, s2_img, label in evalData:\n",
    "        s1_img = Variable(s1_img, requires_grad=False)\n",
    "        s1_img[s1_img != s1_img] = -100\n",
    "        s2_img = Variable(s2_img, requires_grad=False)\n",
    "        s2_img[s2_img != s2_img] = -100\n",
    "        label = Variable(label, requires_grad=False)\n",
    "        \n",
    "        if gpu:\n",
    "            s1_img = s1_img.cuda()\n",
    "            s2_img = s2_img.cuda()\n",
    "            label = label.cuda()\n",
    "        \n",
    "        model_out = model(s1_img, s2_img)\n",
    "        loss = nn.CrossEntropyLoss()(model_out, label)\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        #s1_model_out,  s2_model_out= model(s1_img, s2_img)\n",
    "        #s1_loss = criterion()(s1_model_out, label)\n",
    "        #s2_loss = criterion()(s2_model_out, label)\n",
    "        #s1_weight = 0.75\n",
    "        #total_loss = s1_loss.item() * s1_weight + s2_loss.item() * (1 - s1_weight)\n",
    "        \n",
    "        \n",
    "        #epoch_loss += total_loss\n",
    "        #print(\"val: \", i, epoch_loss)\n",
    "        i += 1\n",
    "    \n",
    "    print(\"validation loss: {}\".format(epoch_loss / i))\n",
    "    if val_loss != None:\n",
    "        val_loss.append(float(epoch_loss / i))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[\"shift brightness\", \"jitter\"]\n",
    "\n",
    "config = {\n",
    "    \n",
    "    \"working_dir\" : \"C:/My_documents/CropTypeData_Rustowicz/working_folder\",\n",
    "    \"out_dir\": \"try_10\",\n",
    "    # Dataset & Loader\n",
    "    \"root_dir\" : \"C:/My_documents/CropTypeData_Rustowicz\",\n",
    "    \"country\" : \"Ghana\",\n",
    "    \"lbl_fldrname\" : \"Labels\",\n",
    "    \"sources\" : [\"Sentinel-1\", \"Sentinel-2\"],\n",
    "    \"percnt_pixels\" : 0.3,\n",
    "    \"sampling_strategy\" : \"fixed size\",\n",
    "    \"transform\" : None,\n",
    "    \"batch_train\" : 128,\n",
    "    \"batch_val\" : 1,\n",
    "    \n",
    "    # Model Compiler\n",
    "    \"init_params\" : None,\n",
    "    \"gpus\" : [0],\n",
    "    \n",
    "    \"LSTM_input_dims\" : (4, 16),\n",
    "    \"LSTM_hidden_dim\" : 128,\n",
    "    \"n_classes\": 4,\n",
    "    \"n_LSTM_layers\" : 4,\n",
    "    \"LSTM_lyr_dropout_rate\" : 0.2,\n",
    "    \"s1_weight\" : 0.6,\n",
    "    \n",
    "    # Model fitting\n",
    "    \"epoch\" : 150,\n",
    "    \"optimizer\" : \"nesterov\",\n",
    "    \"momentum\" : 0.95,\n",
    "    \"criterion\" : BalancedCrossEntropyLoss,\n",
    "    \"lr_init\" : 0.01,\n",
    "    \"LR_policy\" : \"PolynomialLR\",\n",
    "    \n",
    "    \"bucket\" : None,\n",
    "    \"save_fldr\": \"testing_results\",\n",
    "    \"prefix_out\" : \"C:/My_documents/CropTypeData_Rustowicz/working_folder/try_10\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = pixelDataset(root_dir = config[\"root_dir\"], \n",
    "                             country = config[\"country\"], \n",
    "                             lbl_fldrname = config[\"lbl_fldrname\"], \n",
    "                             usage = \"train\", \n",
    "                             sources = config[\"sources\"], \n",
    "                             percnt_pixels = config[\"percnt_pixels\"],\n",
    "                             sampling_strategy = config[\"sampling_strategy\"], \n",
    "                             transform = config[\"transform\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sampler = CropTypeBatchSampler(train_dataset, batch_size = config[\"batch_train\"])\n",
    "#train_loader = DataLoader(train_dataset, batch_size = config[\"batch_train\"], collate_fn=collate_var_length)\n",
    "\n",
    "sampler2 = CropTypeBatchSampler2(train_dataset, \n",
    "                                 batch_size = config[\"batch_train\"])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_sampler = sampler2, \n",
    "                          collate_fn=collate_var_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validation_dataset = pixelDataset(root_dir = config[\"root_dir\"], \n",
    "                                  country = config[\"country\"], \n",
    "                                  lbl_fldrname = config[\"lbl_fldrname\"], \n",
    "                                  usage = \"validation\", \n",
    "                                  sources = config[\"sources\"], \n",
    "                                  percnt_pixels = config[\"percnt_pixels\"],\n",
    "                                  sampling_strategy = config[\"sampling_strategy\"], \n",
    "                                  transform = config[\"transform\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_loader = DataLoader(validation_dataset, \n",
    "                               batch_size = config[\"batch_val\"], \n",
    "                               shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = Double_branch_stacked_biLSTM(input_dims = config[\"LSTM_input_dims\"],\n",
    "                                          hidden_dim = config[\"LSTM_hidden_dim\"], \n",
    "                                          n_classes = config[\"n_classes\"], \n",
    "                                          n_layers = config[\"n_LSTM_layers\"], \n",
    "                                          dropout_rate = config[\"LSTM_lyr_dropout_rate\"], \n",
    "                                          s1_weight = config[\"s1_weight\"], \n",
    "                                          bidirectional = True, \n",
    "                                          use_layernorm = True, \n",
    "                                          use_batchnorm = False, \n",
    "                                          use_attention = False,\n",
    "                                          use_cepsi=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelCompiler(model = lstm_model,\n",
    "                      gpuDevices = config[\"gpus\"], \n",
    "                      params_init = config[\"init_params\"],\n",
    "                      freeze_params = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(train_loader, \n",
    "          validation_loader, \n",
    "          config[\"epoch\"], \n",
    "          config[\"optimizer\"], \n",
    "          config[\"lr_init\"],\n",
    "          config[\"LR_policy\"], \n",
    "          config[\"criterion\"], \n",
    "          config[\"momentum\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.accuracy_evaluation(validation_loader, \n",
    "                          outPrefix=config[\"prefix_out\"], \n",
    "                          bucket=config[\"bucket\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(save_fldr=config[\"save_fldr\"], \n",
    "           bucket=config[\"bucket\"], \n",
    "           object = \"params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1 = torch.randn(64, 256, 10)\n",
    "tensor2 = torch.randn(64, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1 = torch.randn(64, 1, 10)\n",
    "tensor2 = torch.randn(64, 10, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensor2 = tensor2.transpose(2,1).contiguous()\n",
    "#tensor3 = torch.matmul(tensor1, tensor2)\n",
    "tensor3 = torch.bmm(tensor1, tensor2)\n",
    "tensor3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percnt_pixels = 0.1\n",
    "total_neg_pixels = 30\n",
    "total_pos_pixels = 4096 - total_neg_pixels\n",
    "num_negative_samples2 = math.ceil(total_neg_pixels * percnt_pixels * \n",
    "                                 abs((total_pos_pixels - total_neg_pixels) / (total_pos_pixels + total_neg_pixels)))\n",
    "num_negative_samples = math.ceil((total_neg_pixels * percnt_pixels) * (total_pos_pixels / 4096))\n",
    "num_negative_samples3 = math.ceil((total_neg_pixels * percnt_pixels) * (min(total_pos_pixels, total_neg_pixels) / max(total_pos_pixels, total_neg_pixels)))\n",
    "num_negative_samples4 = math.ceil((total_neg_pixels * percnt_pixels) * 0.1)\n",
    "print(total_pos_pixels)\n",
    "print(num_negative_samples)\n",
    "print(num_negative_samples2)\n",
    "print(num_negative_samples3)\n",
    "print(num_negative_samples4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Chip_stats(img_tile, percnt_pixels = 1, sampling_strategy = \"natural frequency\"):\n",
    "    \n",
    "    # fixed sampling strategy for negative samples from each image chip.\n",
    "    negative_indices = np.where(img_tile == [0])\n",
    "    negative_coordinates = list(zip(negative_indices[0], negative_indices[1]))\n",
    "    total_neg_samples = len(negative_coordinates)\n",
    "    num_negative_samples = 3 if total_neg_samples >= 50 else total_neg_samples\n",
    "    neg_samples = random.sample(negative_coordinates, num_negative_samples)\n",
    "    \n",
    "    sampled_coordinates = []\n",
    "    if (0 < percnt_pixels < 1):\n",
    "        unique_vals, unique_counts = np.unique(img_tile, return_counts=True)\n",
    "        smallest_category_count = min(unique_counts)\n",
    "\n",
    "        for val, count in zip(unique_vals, unique_counts):\n",
    "            \n",
    "            if val != 0:\n",
    "                \n",
    "                if sampling_strategy == \"natural frequency\":\n",
    "                    num_samples_per_cat = math.ceil(np.count_nonzero(img_tile == val) * percnt_pixels)\n",
    "                \n",
    "                elif sampling_strategy == \"balanced\":\n",
    "                    if len(unique_vals) > 2:\n",
    "                        num_samples_per_cat = smallest_category_count\n",
    "                    else:\n",
    "                        if count > 100:\n",
    "                            num_samples_per_cat = math.ceil(count * percnt_pixels)\n",
    "                        else:\n",
    "                            num_samples_per_cat = count\n",
    "                \n",
    "                elif sampling_strategy == \"fixed size\":\n",
    "                    num_samples_per_cat = min(count, 10)\n",
    "                \n",
    "                else:\n",
    "                    raise ValueError(\"Sampling strategy is not recognized.\")\n",
    "                \n",
    "                #print(\"number of samples for category {} is {}\".format(val, num_samples_per_cat))\n",
    "                crop_indices = np.where(img_tile == [val])\n",
    "                crop_coordinates = list(zip(crop_indices[0], crop_indices[1]))\n",
    "                crop_samples = random.sample(crop_coordinates, num_samples_per_cat)\n",
    "                print(\"Number of sampled pixels of crop type {} from chip: {}\".format(val, len(crop_coordinates))\n",
    "                sampled_coordinates.extend(crop_samples)\n",
    "        \n",
    "        sampled_coordinates.extend(neg_samples)        \n",
    "        return sampled_coordinates\n",
    "    \n",
    "    elif percnt_pixels == 1:\n",
    "        crop_indices = np.where(img_tile != [0])\n",
    "        crop_coordinates = list(zip(crop_indices[0], crop_indices[1]))\n",
    "        print(\"total number of crop pixels from chip: \", len(crop_coordinates))\n",
    "        crop_coordinates.extend(neg_samples)\n",
    "        \n",
    "        return crop_coordinates\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"'percnt_pixels' argument is out of range of (0, 1].\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-venv",
   "language": "python",
   "name": "local-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "465px",
    "left": "1550px",
    "right": "20px",
    "top": "119px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
