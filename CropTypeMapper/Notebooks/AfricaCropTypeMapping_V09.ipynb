{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "from random import shuffle\n",
    "import gc\n",
    "import math\n",
    "from pathlib import Path\n",
    "import time\n",
    "from datetime import datetime\n",
    "from collections import Counter, defaultdict, OrderedDict\n",
    "import urllib.parse as urlparse\n",
    "import boto3\n",
    "import shutil\n",
    "import tqdm\n",
    "import itertools\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import numpy as np\n",
    "from numpy import inf\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import rasterio\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "import torch.utils.data\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "import torch.nn.utils.rnn as rnn_util\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PyTorch version: {}\".format(torch.__version__))\n",
    "print(\"Cuda version : {}\".format(torch.version.cuda))\n",
    "print('CUDNN version:', torch.backends.cudnn.version())\n",
    "print('Number of available GPU Devices:', torch.cuda.device_count())\n",
    "print(\"current GPU Device: {}\".format(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_reproducible(seed = 42, cudnn = True):\n",
    "    \"\"\"Make all the randomization processes start from a shared seed\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.random.manual_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    if cudnn:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "make_reproducible()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Accuracy Evaluation and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\"\"\"\n",
    "\n",
    "class BinaryMetrics:\n",
    "    \n",
    "    '''Metrics measuring model performance.'''\n",
    "\n",
    "    def __init__(self, refArray, scoreArray, predArray=None):\n",
    "        '''\n",
    "        Params:\n",
    "            refArray (narray): Array of ground truth\n",
    "            scoreArray (narray): Array of pixels scores of positive class\n",
    "        '''\n",
    "\n",
    "        self.observation = refArray.flatten()\n",
    "        self.score = scoreArray.flatten()\n",
    "        \n",
    "        if self.observation.shape != self.score.shape:\n",
    "            raise Exception(\"Inconsistent size between label and prediction arrays.\")\n",
    "        \n",
    "        if predArray is not None:\n",
    "            self.prediction = predArray.flatten()\n",
    "        else:\n",
    "            self.prediction = np.where(self.score > 0.5, 1, 0)\n",
    "\n",
    "        self.confusion_matrix = self.confusion_matrix()\n",
    "\n",
    "        \n",
    "    def __add__(self, other):\n",
    "        \"\"\"\n",
    "        Add two BinaryMetrics instances\n",
    "        Params:\n",
    "            other (''BinaryMetrics''): A BinaryMetrics instance\n",
    "        Return:\n",
    "            ''BinaryMetrics''\n",
    "        \"\"\"\n",
    "\n",
    "        return BinaryMetrics(np.append(self.observation, other.observation),\n",
    "                             np.append(self.score, other.score),\n",
    "                            np.append(self.prediction, other.prediction))\n",
    "\n",
    "\n",
    "    def __radd__(self, other):\n",
    "        \"\"\"\n",
    "        Add a BinaryMetrics instance with reversed operands.\n",
    "        Params:\n",
    "            other\n",
    "        Returns:\n",
    "            ''BinaryMetrics\n",
    "        \"\"\"\n",
    "\n",
    "        if other == 0:\n",
    "            return self\n",
    "        else:\n",
    "            return self.__add__(other)\n",
    "\n",
    "\n",
    "    def confusion_matrix(self):\n",
    "        \"\"\"\n",
    "        Calculate confusion matrix of given ground truth and predicted label\n",
    "        Returns:\n",
    "            ''pandas.dataframe'' of observation on the column and prediction on the row\n",
    "        \"\"\"\n",
    "\n",
    "        #set_trace()\n",
    "        refArray = self.observation\n",
    "        predArray = self.prediction\n",
    "\n",
    "        if refArray.max() > 1 or predArray.max() > 1:\n",
    "            raise Exception(\"Invalid array\")\n",
    "        \n",
    "        predArray = predArray * 2\n",
    "        sub = refArray - predArray\n",
    "\n",
    "        self.tp = np.sum(sub == -1)\n",
    "        self.fp = np.sum(sub == -2)\n",
    "        self.fn = np.sum(sub == 1)\n",
    "        self.tn = np.sum(sub == 0)\n",
    "        \n",
    "        confusionMatrix = pd.DataFrame(data = np.array([[self.tn, self.fp],[self.fn, self.tp]]),\n",
    "                                       index = ['observation = 0', 'observation = 1'],\n",
    "                                       columns = ['prediction = 0', 'prediction = 1'])\n",
    "\n",
    "        return confusionMatrix\n",
    "\n",
    "\n",
    "    def ir(self):\n",
    "        \"\"\"\n",
    "        Imbalance Ratio (IR) is defined as the proportion between positive and negative instances of the label. \n",
    "        This value lies within the [0, ∞] range, having a value IR = 1 in the balanced case.\n",
    "        Returns:\n",
    "             float\n",
    "        \"\"\"\n",
    "        try:\n",
    "            ir = (self.tp + self.fn) / (self.fp + self.tn)\n",
    "        \n",
    "        except ZeroDivisionError:\n",
    "            ir = np.nan_to_num(float(\"NaN\"))\n",
    "\n",
    "        return ir\n",
    "    \n",
    "    \n",
    "    def oa(self):\n",
    "        \"\"\"\n",
    "        Calculate Overal Accuracy.\n",
    "        Returns:\n",
    "            float\n",
    "        \"\"\"\n",
    "\n",
    "        oa = metrics.accuracy_score(self.observation, self.prediction)\n",
    "        \n",
    "        return oa\n",
    "    \n",
    "    \n",
    "    def producers_accuracy(self):\n",
    "        \"\"\"\n",
    "        Calculate Producer's Accuracy (True Positive Rate |Sensitivity |hit rate | recall).\n",
    "        Returns:\n",
    "            float\n",
    "        \"\"\"\n",
    "\n",
    "        return metrics.recall_score(self.observation, self.prediction)\n",
    "\n",
    "    \n",
    "    def users_accuracy(self):\n",
    "        \"\"\"\n",
    "        Calculate User’s Accuracy (Positive Prediction Value (PPV) | Precision).\n",
    "        Returns:\n",
    "            float\n",
    "        \"\"\"\n",
    "\n",
    "        ua = metrics.precision_score(self.observation, self.prediction)\n",
    "        \n",
    "        return ua\n",
    "    \n",
    "    \n",
    "    def npv(self):\n",
    "        \"\"\"\n",
    "        Calculate Negative Predictive Value or true negative accuracy.\n",
    "        Returns:\n",
    "             float\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            npv = self.tn / (self.tn + self.fn)\n",
    "        \n",
    "        except ZeroDivisionError:\n",
    "            npv = np.nan_to_num(float(\"NaN\"))\n",
    "        \n",
    "        return npv\n",
    "\n",
    "\n",
    "    def specificity(self):\n",
    "        \"\"\"\n",
    "        Calculate Specificity aka. True negative rate (TNR), or inverse recall.\n",
    "        Returns:\n",
    "             float\n",
    "        \"\"\"\n",
    "        try:\n",
    "            spc = self.tn / (self.tn + self.fp)\n",
    "        \n",
    "        except ZeroDivisionError:\n",
    "            spc = np.nan_to_num(float(\"NaN\"))\n",
    "\n",
    "        return spc\n",
    "\n",
    "      \n",
    "    def f1_measure(self):\n",
    "        \"\"\"\n",
    "        Calculate F1 score.\n",
    "        Returns:\n",
    "            float\n",
    "        \"\"\"\n",
    "\n",
    "        f1 = metrics.f1_score(self.observation, self.prediction)\n",
    "\n",
    "        return f1\n",
    "    \n",
    "    \n",
    "    def iou(self):\n",
    "        \"\"\"\n",
    "        Calculate interception over union for the positive class.\n",
    "        Returns:\n",
    "            float\n",
    "        \"\"\"\n",
    "\n",
    "        return metrics.jaccard_score(self.observation, self.prediction)\n",
    "    \n",
    "    \n",
    "    def miou(self):\n",
    "        \"\"\"\n",
    "        Calculate mean interception over union considering both positive and negative classes.\n",
    "        Returns:\n",
    "            float\n",
    "        \"\"\"\n",
    "        try:\n",
    "            miou = np.nanmean([self.tn / (self.tn + self.fn + self.fp), self.tp / (self.tp + self.fn + self.fp)])\n",
    "        \n",
    "        except ZeroDivisionError:\n",
    "            miou = np.nan_to_num(float(\"NaN\"))\n",
    "\n",
    "        return miou\n",
    "    \n",
    "    \n",
    "    def tss(self):\n",
    "        \"\"\"\n",
    "        Calculates true scale statistic (TSS). Also called Bookmaker Informedness (BM). \n",
    "        Scale of the metric:[-1,1].\n",
    "        Returns:\n",
    "            float\n",
    "        \"\"\"  \n",
    "        tss = self.tp / (self.tp + self.fn) + self.tn / (self.tn + self.fp) - 1\n",
    "        \n",
    "        return tss\n",
    "\n",
    "##################################################    \n",
    "    \n",
    "def accuracy_evaluation(eval_data, model, gpu, out_prefix, weights, bucket=None):\n",
    "    \"\"\"\n",
    "    Evaluate model\n",
    "    Params:\n",
    "        eval_data (''DataLoader'') -- Batch grouped data\n",
    "        model -- Trained model for validation\n",
    "        buffer: Buffer added to the targeted grid when creating dataset. This allows metrics to calculate only\n",
    "            at non-buffered region\n",
    "        gpu (binary,optional): Decide whether to use GPU, default is True\n",
    "        bucket (str): name of s3 bucket to save metrics\n",
    "        outPrefix (str): s3 prefix to save metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    metrics = []\n",
    "    \n",
    "    for s1_img, s2_img, label in eval_data:\n",
    "        s1_img = Variable(s1_img, requires_grad=False)    #shape=(B,T,C)\n",
    "        s1_img[s1_img != s1_img] = 0\n",
    "        s2_img = Variable(s2_img, requires_grad=False)\n",
    "        s2_img[s2_img != s2_img] = 0\n",
    "        label = Variable(label, requires_grad=False)      #shape=1\n",
    "    \n",
    "        if gpu:\n",
    "            s1_img = s1_img.cuda()\n",
    "            s2_img = s2_img.cuda()\n",
    "            label = label.cuda()\n",
    "        \n",
    "        #model_out = model(s1_img, s2_img) #shape=(B, Class_num)\n",
    "        #model_out_prob = F.softmax(model_out, 1)\n",
    "        #model_out_prob = F.softmax(out_logits, 1)\n",
    "        \n",
    "        s1_model_out,  s2_model_out, fused_model_out = model(s1_img, s2_img)\n",
    "        out_logits = s1_model_out * weights[0] + s2_model_out * weights[1] + fused_model_out * weights[2]\n",
    "        model_out_prob = F.softmax(out_logits, 1)\n",
    "        \n",
    "        batch, nclass = model_out_prob.size()\n",
    "        \n",
    "        for i in range(batch):\n",
    "            label_batch = label[i].cpu().numpy()\n",
    "            batch_pred = model_out_prob.max(dim=1)[1].data[i].cpu().numpy()\n",
    "            \n",
    "            for n in range(1, nclass):\n",
    "                class_out = model_out_prob[:, n].data[i].cpu().numpy()\n",
    "                class_pred = np.where(batch_pred == n, 1, 0)\n",
    "                class_label = np.where(label_batch == n, 1, 0)\n",
    "                pixel_metrics = BinaryMetrics(class_label, class_out, class_pred)\n",
    "                \n",
    "                try:\n",
    "                    metrics[n - 1].append(pixel_metrics)\n",
    "                except:\n",
    "                    metrics.append([pixel_metrics])\n",
    "    #set_trace()\n",
    "    metrics = [sum(m) for m in metrics]\n",
    "    \n",
    "    report = pd.DataFrame({\n",
    "        \"Overal Accuracy\" : [m.oa() for m in metrics],\n",
    "        \"Producer's Accuracy (recall)\" : [m.producers_accuracy() for m in metrics],\n",
    "        \"User's Accuracy (precision)\" : [m.users_accuracy() for m in metrics],\n",
    "        \"Negative Predictive Value\" : [m.npv() for m in metrics],\n",
    "        \"Specificity (TNR)\" : [m.specificity() for m in metrics],\n",
    "        \"F1 score\" : [m.f1_measure() for m in metrics],\n",
    "        \"IoU\" : [m.iou() for m in metrics],\n",
    "        \"mIoU\" : [m.miou() for m in metrics],\n",
    "        \"TSS\" : [m.tss() for m in metrics]\n",
    "    }, index=[\"class_{}\".format(m) for m in range(1, len(metrics) + 1)])\n",
    "    \n",
    "    if bucket:\n",
    "        metrics_path = f\"s3://{bucket}/{out_prefix}/Metrics.csv\"\n",
    "    else:\n",
    "        metrics_path = Path(out_prefix).joinpath(\"Metrics.csv\")\n",
    "        Path(out_prefix).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "    report.to_csv(metrics_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Loading input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "################################### Helper functions for custom Dataset ######################################\n",
    "\n",
    "def load_data(dataPath, isLabel = False):\n",
    "    \"\"\"Load the dataset.\n",
    "    Args:\n",
    "        dataPath (str) -- Path to either the image or label raster.\n",
    "        isLabel (binary) -- decide wether the input dataset is label. Default is False.\n",
    "    \n",
    "    Returns:\n",
    "        loaded data as numpy ndarray. \n",
    "    \"\"\"\n",
    "    \n",
    "    if isLabel:\n",
    "        \n",
    "        with rasterio.open(dataPath, \"r\") as src:\n",
    "            \n",
    "            if src.count != 1:\n",
    "                raise ValueError(\"Label must have only 1 band but {} bands were detected.\".format(src.count))\n",
    "            img = src.read(1)\n",
    "    \n",
    "    else:\n",
    "        img = np.load(dataPath)\n",
    "    \n",
    "    return img\n",
    "\n",
    "############################################################\n",
    "\n",
    "def pickle_dataset(dataset, filePath):\n",
    "    with open(filePath, \"wb\") as fp:\n",
    "        pickle.dump(dataset, fp)\n",
    "#####\n",
    "\n",
    "def load_dataset(filePath):\n",
    "    return pd.read_pickle(filePath)\n",
    "\n",
    "############################################################\n",
    "\n",
    "def get_test_pixel_coord(img_cube):\n",
    "    \n",
    "    x_ls = range(img_cube.shape[1])\n",
    "    y_ls = range(img_cube.shape[2])\n",
    "    index = list(itertools.product(x_ls, y_ls))\n",
    "    \n",
    "    return index\n",
    "\n",
    "############################################################\n",
    "\n",
    "class CropTypeBatchSampler(Sampler):\n",
    "    \"\"\"\n",
    "    This sampler is designed to divide samples into batches for mini-batch training in a way that samples in each batch\n",
    "    are closest in sequence length to each other which is helpful as the samples in a batch require the minimum amount of\n",
    "    zero padding to become equal length.\n",
    "    \n",
    "    Args:\n",
    "            dataset (Pytorch dataset): list of tuples in the form of [(s1_img, s2_img, label),...,(s1_img, s2_img, label)]\n",
    "            batch_size (int): Number of samples in a mini-batch training strategy.\n",
    "            sort_src (str) -- image dataset used for sorting.\n",
    "            drop_last (bool) -- Decide whether keep or drop the last batch if its length is shorter than batch size.\n",
    "    Returns:\n",
    "            list of batches where each batch is a list of sample indices.\n",
    "            \n",
    "    Note 1: Batches are designed so that samples in a batch are closest in sequence length only for the chosen image source.\n",
    "    Note 2: The last batch might be shorter that the other batch size if drop_last is False.\n",
    "    Note 3: Separate padding might be required for both sources using 'collate_fn'.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataset, batch_size, sort_src, drop_last=False):\n",
    "        super(CropTypeBatchSampler, self).__init__(dataset)\n",
    "        \n",
    "        assert sort_src in [\"s1\", \"s2\"]\n",
    "        self.batch_size = batch_size\n",
    "        self.batches = []\n",
    "        batch = []\n",
    "        indices_n_lengths = []\n",
    "        \n",
    "        for i in range(len(dataset)):\n",
    "            if sort_src == \"s1\":\n",
    "                indices_n_lengths.append((i, dataset[i][0].shape[0]))\n",
    "            else:\n",
    "                indices_n_lengths.append((i, dataset[i][1].shape[0]))\n",
    "        \n",
    "        shuffle(indices_n_lengths)\n",
    "        indices_n_lengths.sort(key = lambda x:x[1])\n",
    "        \n",
    "        for i in range(len(indices_n_lengths)):\n",
    "            sample_idx = indices_n_lengths[i][0]\n",
    "            batch.append(sample_idx)\n",
    "            \n",
    "            if len(batch) == self.batch_size:\n",
    "                self.batches.append(batch)\n",
    "                batch = []\n",
    "        \n",
    "        if len(dataset) % self.batch_size != 0:       \n",
    "            if (len(batch) > 0) and (not drop_last):\n",
    "                self.batches.append(batch)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.batches)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for b in self.batches:\n",
    "            yield b\n",
    "\n",
    "############################################################\n",
    "\n",
    "def collate_var_length(batch):\n",
    "    \n",
    "    batch_size = len(batch)\n",
    "    \n",
    "    s1_max_len = 50\n",
    "    s2_max_len = 50\n",
    "    \n",
    "    labels = [batch[i][2] for i in range(batch_size)]\n",
    "    label = torch.stack(labels)\n",
    "    \n",
    "    s1_grids = [batch[i][0] for i in range(batch_size)]\n",
    "    s2_grids = [batch[i][1] for i in range(batch_size)]\n",
    "    \n",
    "    s1_img = rnn_util.pad_sequence(s1_grids, batch_first=True)\n",
    "    s2_img = rnn_util.pad_sequence(s2_grids, batch_first=True)\n",
    "    \n",
    "    return s1_img, s2_img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class pixelDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "            root_dir (str): path to the main folder of the dataset, formatted as indicated in the readme\n",
    "            usage (str): decide whether we are making a \"train\", \"validation\" or \"test\" dataset.\n",
    "            num_samples (int) -- Number of samples for each crop type.\n",
    "            sampling_strategy (str) -- If ranked samples are only taken from crop pixels with lowest number of cloudy days.\n",
    "                                       Otherwise a samples can be chosen randomly from the all the avilable samples for each crop type.\n",
    "            sources (list of str): Sensors of image acquisition. At the moment two sensors \n",
    "                                   are used [\"Sentinel-1\", \"Sentinel-2\"]\n",
    "            inference_index (iterable) : Only gets used at prediction time as a mechanism to go through prediction tiles one at a time.\n",
    "            verbose (bool): Decide to print extra information on-screen.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, root_dir, usage, num_samples=None, sampling_strategy=\"ranked\", sources=(\"Sentinel-1\", \"Sentinel-2\"), \n",
    "                 inference_index=None, verbose=False):\n",
    "        \n",
    "        self.usage = usage\n",
    "        self.sources = sources\n",
    "        self.num_samples = num_samples\n",
    "        self.sampling_strategy = sampling_strategy\n",
    "        \n",
    "        assert self.usage in [\"train\", \"validation\", \"test\"], \"Usage can only be one of 'train', 'validation' and 'test'.\"\n",
    "        assert self.sampling_strategy in [\"ranked\", \"random\"], \"Sampling strategy is invalid.\"\n",
    "        \n",
    "        if self.usage in [\"train\", \"validation\"]:\n",
    "            \n",
    "            assert num_samples is not None\n",
    "            \n",
    "            s1_dir = Path(root_dir).joinpath(\"Ghana\", self.sources[0], self.usage, \"categories\")\n",
    "            s2_dir = Path(root_dir).joinpath(\"Ghana\", self.sources[1], self.usage, \"categories\")\n",
    "            categories = [name for name in os.listdir(s1_dir) if os.path.isdir(os.path.join(s1_dir, name))]\n",
    "            \n",
    "            s1_samples_ls = []\n",
    "            s2_samples_ls = []\n",
    "            \n",
    "            for cat in categories:\n",
    "                s1_src_path = Path(s1_dir).joinpath(cat)\n",
    "                s1_fnames = [Path(dirpath) / f for (dirpath, dirnames, filenames) in os.walk(s1_src_path) for \\\n",
    "                             f in filenames if f.endswith(\".npy\")]\n",
    "                s1_fnames.sort()\n",
    "                \n",
    "                s2_src_path = Path(s2_dir).joinpath(cat)\n",
    "                s2_fnames = [Path(dirpath) / f for (dirpath, dirnames, filenames) in os.walk(s2_src_path) for \\\n",
    "                             f in filenames if f.endswith(\".npy\")]\n",
    "                s2_fnames.sort()\n",
    "                assert len(s1_fnames) == len(s2_fnames)\n",
    "                \n",
    "                if len(s1_fnames) < self.num_samples:\n",
    "                    s1_samples_ls.extend(s1_fnames)\n",
    "                    s2_samples_ls.extend(s2_fnames)\n",
    "                    print(f\"===> Only {len(s1_fnames)} samples are available for {cat} class. All taken.\")\n",
    "                \n",
    "                else:\n",
    "                    if sampling_strategy == \"ranked\":\n",
    "                    \n",
    "                        grid_numbers = [str(f).split(\"_\")[-5] for f in s1_fnames]\n",
    "                        num_unique_tiles = len(sorted(set(grid_numbers)))\n",
    "                        min_num_samp_from_each_id = self.num_samples // num_unique_tiles\n",
    "                        \n",
    "                        if verbose:\n",
    "                            print(f\"Category: {cat}, Total number of tiles: {num_unique_tiles} Num samples per ite: {min_num_samp_from_each_id}\")\n",
    "                            print(\"#####\")\n",
    "                        i = 1\n",
    "                        counter = 0\n",
    "                        while counter < self.num_samples:\n",
    "                            for grid in sorted(set(grid_numbers)):\n",
    "                                s1_samples_in_grid = [str(f) for f in s1_fnames if \"_\" + grid + \"_\" in str(f)]\n",
    "                                s2_samples_in_grid = [str(f) for f in s2_fnames if \"_\" + grid + \"_\" in str(f)]\n",
    "                                assert len(s1_samples_in_grid) == len(s2_samples_in_grid)\n",
    "                                if len(s1_samples_in_grid) > (i+min_num_samp_from_each_id):\n",
    "                                    diff = abs(self.num_samples - counter)\n",
    "                                    if diff >= min_num_samp_from_each_id:\n",
    "                                        s1_samples = [fn for fn in s1_samples_in_grid if int(str(fn).split(\"_\")[-3]) in range(i, i+min_num_samp_from_each_id)]\n",
    "                                        s2_samples = [fn for fn in s2_samples_in_grid if int(str(fn).split(\"_\")[-3]) in range(i, i+min_num_samp_from_each_id)]\n",
    "                                    else:\n",
    "                                        s1_samples = [fn for fn in s1_samples_in_grid if int(str(fn).split(\"_\")[-3]) in range(i, i+diff)]\n",
    "                                        s2_samples = [fn for fn in s2_samples_in_grid if int(str(fn).split(\"_\")[-3]) in range(i, i+diff)]\n",
    "                                else:\n",
    "                                    else_diff = len(s1_samples_in_grid) - i\n",
    "                                    s1_samples = [fn for fn in s1_samples_in_grid if int(str(fn).split(\"_\")[-3]) in range(i, i+else_diff)]\n",
    "                                    s2_samples = [fn for fn in s2_samples_in_grid if int(str(fn).split(\"_\")[-3]) in range(i, i+else_diff)]\n",
    "                                    \n",
    "                                if verbose:\n",
    "                                    print(f\"grid: {grid}, counter: {counter}, i: {i}\")\n",
    "                                    print(f\"S1 samples: {s1_samples}\")\n",
    "                                    print(\"\")\n",
    "                                    print(f\"S2 samples: {s2_samples}\")\n",
    "                                    print(\"-----\")\n",
    "                                s1_samples_ls.extend(s1_samples)\n",
    "                                s2_samples_ls.extend(s2_samples)\n",
    "                                counter+=len(s1_samples)\n",
    "                                if counter >= self.num_samples:\n",
    "                                    break\n",
    "                        i+=min_num_samp_from_each_id\n",
    "  \n",
    "                    else:\n",
    "                        random_indices = random.sample(range(len(s1_fnames)), self.num_samples)\n",
    "                        for idx in random_indices:\n",
    "                            s1_samples_ls.append(s1_fnames[idx])\n",
    "                            s2_samples_ls.append(s2_fnames[idx])          \n",
    "            \n",
    "            self.lbl = []\n",
    "            self.s1 = []\n",
    "            self.s2 = []\n",
    "            \n",
    "            assert len(s1_samples_ls) == len(s2_samples_ls)\n",
    "            \n",
    "            for s1_fn, s2_fn in tqdm.tqdm(zip(s1_samples_ls, s2_samples_ls), total = len(s1_samples_ls)):\n",
    "                \n",
    "                s1_lbl = str(s1_fn).split(\"_\")[-1].replace(\".npy\", \"\")\n",
    "                s2_lbl = str(s2_fn).split(\"_\")[-1].replace(\".npy\", \"\")\n",
    "                assert s1_lbl == s2_lbl\n",
    "                \n",
    "                lbl_val = int(s1_lbl)\n",
    "                self.lbl.append(lbl_val)\n",
    "                \n",
    "                s1_array = np.load(s1_fn)\n",
    "                self.s1.append(s1_array)\n",
    "                \n",
    "                s2_array = np.load(s2_fn)\n",
    "                self.s2.append(s2_array)\n",
    "            \n",
    "            print(\"------{} tuple samples of form (s1, s2, lbl) are loaded from the {} dataset------\".format(len(self.s1), self.usage))\n",
    "        \n",
    "        if self.usage == \"test\":\n",
    "            \n",
    "            self.s1 = []\n",
    "            self.s2 = []\n",
    "            self.img_coor = []\n",
    "\n",
    "            s1_dir = Path(root_dir).joinpath(\"prediction_tiles\", self.sources[0])\n",
    "            s1_fnames = [Path(dirpath) / f for (dirpath, dirnames, filenames) in os.walk(s1_dir) for f in filenames if f.endswith(\".npy\")]\n",
    "            s1_meta_fnames = [Path(dirpath) / f for (dirpath, dirnames, filenames) in os.walk(s1_dir) for f in filenames if f.endswith(\".pickle\")]\n",
    "            s1_fnames.sort()\n",
    "            s1_meta_fnames.sort()\n",
    "\n",
    "            s2_dir = Path(root_dir).joinpath(\"prediction_tiles\", self.sources[1])\n",
    "            s2_fnames = [Path(dirpath) / f for (dirpath, dirnames, filenames) in os.walk(s2_dir) for f in filenames if f.endswith(\".npy\") if \"source\" in f]\n",
    "            s2_meta_fnames = [Path(dirpath) / f for (dirpath, dirnames, filenames) in os.walk(s2_dir) for f in filenames if f.endswith(\".pickle\")]\n",
    "            s2_fnames.sort()\n",
    "            s2_meta_fnames.sort()\n",
    "\n",
    "            s1_grid_id = str(s1_fnames[inference_index]).split(\"_\")[-1].replace(\".npy\", \"\")\n",
    "            s2_grid_id = str(s2_fnames[inference_index]).split(\"_\")[-1].replace(\".npy\", \"\")\n",
    "            s1_grid_meta_id = str(s1_meta_fnames[inference_index]).split(\"_\")[-2]\n",
    "            s2_grid_meta_id = str(s2_meta_fnames[inference_index]).split(\"_\")[-2]\n",
    "            assert s1_grid_id == s2_grid_id == s1_grid_meta_id == s2_grid_meta_id\n",
    "            \n",
    "            self.tile_id = s1_grid_id\n",
    "            self.meta = pd.read_pickle(s1_meta_fnames[0])\n",
    "            \n",
    "            s1_array = np.load(s1_fnames[inference_index])\n",
    "            s1_array = s1_array * 1e-7\n",
    "            \n",
    "            s2_array = np.load(s2_fnames[inference_index])\n",
    "            s2_array = s2_array * 1e-7\n",
    "            \n",
    "            assert s1_array.shape[1] == s2_array.shape[1]\n",
    "            assert s1_array.shape[2] == s2_array.shape[2]\n",
    "            \n",
    "            pixel_indices = get_test_pixel_coord(s1_array)\n",
    "            \n",
    "            for coord in pixel_indices:\n",
    "                s1_val = s1_array[:,coord[0], coord[1],:]\n",
    "                self.s1.append(s1_val.copy())\n",
    "                \n",
    "                s2_val = s2_array[:,coord[0], coord[1],:]\n",
    "                self.s2.append(s2_val.copy())\n",
    "                \n",
    "                self.img_coor.append(coord)\n",
    "            \n",
    "            del s1_array, s2_array\n",
    "            gc.collect()\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        if self.usage in [\"train\", \"validation\"]:\n",
    "            s1_img = self.s1[index]\n",
    "            s2_img = self.s2[index]\n",
    "            label = self.lbl[index]\n",
    "            \n",
    "            # numpy to torch\n",
    "            # tensor shape: (N x C x T)\n",
    "            s1_img = torch.from_numpy(s1_img.transpose((1, 0))).float()\n",
    "            s2_img = torch.from_numpy(s2_img.transpose((1, 0))).float()\n",
    "            label = torch.from_numpy(np.asarray(label)).long()\n",
    "                \n",
    "            return s1_img, s2_img, label\n",
    "        \n",
    "        if self.usage == \"test\":\n",
    "            s1_img = self.s1[index]\n",
    "            s2_img = self.s2[index]\n",
    "            coord = self.img_coor[index]\n",
    "            \n",
    "            s1_img = torch.from_numpy(s1_img.transpose((1, 0))).float()\n",
    "            s2_img = torch.from_numpy(s2_img.transpose((1, 0))).float()\n",
    "            \n",
    "            return s1_img, s2_img, coord\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Custom Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import torch\n",
    "from torch import nn\n",
    "\"\"\"\n",
    "\n",
    "class BalancedCrossEntropyLoss(nn.Module):\n",
    "    '''\n",
    "    Balanced cross entropy loss by weighting of inverse class ratio\n",
    "    Params:\n",
    "        ignore_index (int): Class index to ignore\n",
    "        reduction (str): Reduction method to apply, return mean over batch if 'mean',\n",
    "            return sum if 'sum', return a tensor of shape [N,] if 'none'\n",
    "    Returns:\n",
    "        Loss tensor according to arg reduction\n",
    "    '''\n",
    "\n",
    "    def __init__(self, ignore_index=-100, reduction='mean'):\n",
    "        super(BalancedCrossEntropyLoss, self).__init__()\n",
    "        self.ignore_index = ignore_index\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, predict, target):\n",
    "        #set_trace()\n",
    "        # get class weights\n",
    "        unique, unique_counts = torch.unique(target, return_counts=True)\n",
    "        # calculate weight for only valid indices\n",
    "        unique_counts = unique_counts[unique != self.ignore_index]\n",
    "        unique = unique[unique != self.ignore_index]\n",
    "        ratio = unique_counts.float() / torch.numel(target)\n",
    "        weight = (1. / ratio) / torch.sum(1. / ratio)\n",
    "\n",
    "        lossWeight = torch.ones(predict.shape[1]).cuda() * 0.00001\n",
    "        for i in range(len(unique)):\n",
    "            lossWeight[unique[i]] = weight[i]\n",
    "        loss = nn.CrossEntropyLoss(weight=lossWeight, ignore_index=self.ignore_index, reduction=self.reduction)\n",
    "\n",
    "        return loss(predict, target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "\"\"\"\n",
    "\n",
    "# Dot-product attention between Bi-LSTM last states and its output.\n",
    "class attention(nn.Module):\n",
    "    def __init__(self, attn_dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dropout = nn.Dropout(attn_dropout)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, q, k, v):\n",
    "        #set_trace()\n",
    "        query = q.unsqueeze(1)\n",
    "        \n",
    "        key = k.transpose(2,1).contiguous()\n",
    "        weight_score = torch.bmm(query, key)\n",
    "        \n",
    "        attn = self.softmax(weight_score)\n",
    "        attn = self.dropout(attn)\n",
    "        output = torch.bmm(attn, v)\n",
    "        \n",
    "        return output, attn\n",
    "\n",
    "###################################################################################################\n",
    "\n",
    "def get_inp_branch(x):\n",
    "    if isinstance(x, tuple) or isinstance(x, list):\n",
    "        br1 = x[0]\n",
    "        br2 = x[1]\n",
    "    elif isinstance(x, int) or isinstance(x, float):\n",
    "        br1 = x\n",
    "        br2 = x\n",
    "           \n",
    "    return br1, br2\n",
    "    \n",
    "\n",
    "###########################################################################################\n",
    "\n",
    "class Double_branch_stacked_biLSTM(torch.nn.Module):\n",
    "    def __init__(self, input_dims = (4, 11), hidden_dims = (64, 64), n_classes = 4, n_layers = (2, 2), \n",
    "                 dropout_rate = (0.35, 0.45), s1_weight = 0.6, bidirectional = True, use_layernorm = True, \n",
    "                 use_batchnorm = False, use_attention = False):\n",
    "        super(Double_branch_stacked_biLSTM, self).__init__()\n",
    "        \n",
    "        # Define object properties\n",
    "        self.n_classes = n_classes\n",
    "        self.s1_weight = s1_weight\n",
    "        self.bidirectional = bidirectional\n",
    "        self.use_layernorm = use_layernorm\n",
    "        self.use_batchnorm = use_batchnorm\n",
    "        self.use_attention = use_attention\n",
    "\n",
    "        \n",
    "        s1_in_dim, s2_in_dim = get_inp_branch(input_dims)\n",
    "        s1_hidden_dim, s2_hidden_dim = get_inp_branch(hidden_dims)\n",
    "        s1_n_layers, s2_n_layers = get_inp_branch(n_layers)\n",
    "        s1_dropout_rate, s2_dropout_rate = get_inp_branch(dropout_rate)\n",
    "        \n",
    "        # Layer normalization for s1, s2 inputs and current_states of LSTM\n",
    "        if self.use_layernorm:\n",
    "            self.s1_inlayernorm = nn.LayerNorm(s1_in_dim)\n",
    "            self.s1_clayernorm = nn.LayerNorm((s1_hidden_dim + s1_hidden_dim * self.bidirectional) * s1_n_layers)\n",
    "            \n",
    "            self.s2_inlayernorm = nn.LayerNorm(s2_in_dim)\n",
    "            self.s2_clayernorm = nn.LayerNorm((s2_hidden_dim + s2_hidden_dim * self.bidirectional) * s2_n_layers)\n",
    "        \n",
    "        # LSTM layers for s1 and s2\n",
    "        self.s1_lstm = nn.LSTM(input_size = s1_in_dim, hidden_size = s1_hidden_dim, \n",
    "                               num_layers = s1_n_layers, bias = False, batch_first = True, dropout = s1_dropout_rate, \n",
    "                               bidirectional = self.bidirectional)\n",
    "        \n",
    "        self.s2_lstm = nn.LSTM(input_size = s2_in_dim, hidden_size = s2_hidden_dim, \n",
    "                               num_layers = s2_n_layers, bias = False, batch_first = True, dropout = s2_dropout_rate, \n",
    "                               bidirectional = self.bidirectional)\n",
    "        \n",
    "        if self.bidirectional:\n",
    "            s1_hidden_dim = s1_hidden_dim * 2\n",
    "            s2_hidden_dim = s2_hidden_dim * 2\n",
    "        \n",
    "        if self.use_attention:\n",
    "            self.attention = attention()\n",
    "        \n",
    "        # MLP layer on top of LSTM\n",
    "        s1_linear_input_dim = s1_hidden_dim if self.use_attention else s1_hidden_dim * s1_n_layers\n",
    "        self.s1_linear_class = nn.Linear(s1_linear_input_dim, self.n_classes, bias = True)\n",
    "        \n",
    "        s2_linear_input_dim = s2_hidden_dim if self.use_attention else s2_hidden_dim * s2_n_layers\n",
    "        self.s2_linear_class = nn.Linear(s2_linear_input_dim, self.n_classes, bias = True)\n",
    " \n",
    "\n",
    "    def _logits(self, s1, s2):\n",
    "        #set_trace()\n",
    "        if self.use_layernorm:\n",
    "            s1 = self.s1_inlayernorm(s1)\n",
    "            s2 = self.s2_inlayernorm(s2)\n",
    "        \n",
    "        # Get outputs and the last current state and hidden state for each branch.\n",
    "        #s1_outputs & s2_outputs: [B, Seq_length, 2 x hidden_dim]\n",
    "        s1_outputs, s1_last_state_list = self.s1_lstm.forward(s1)\n",
    "        s2_outputs, s2_last_state_list = self.s2_lstm.forward(s2)\n",
    "        \n",
    "        #s1_h & s1_c & s2_h & s2_c: [2 x num_layers, B, hidden_dim] \n",
    "        s1_h, s1_c = s1_last_state_list\n",
    "        s2_h, s2_c = s2_last_state_list\n",
    "        \n",
    "        # Get the query layer to calculate self attention for each branch\n",
    "        if self.use_attention:\n",
    "            if self.bidirectional:\n",
    "                # Get the last state of each branch. size:[B, hidden_dim]\n",
    "                s1_query_forward = s1_c[-1]\n",
    "                s1_query_backward = s1_c[-2]\n",
    "                # size:[B, 2 x hidden_dim]\n",
    "                s1_query = torch.cat([s1_query_forward, s1_query_backward], 1)\n",
    "                \n",
    "                s2_query_forward = s2_c[-1]\n",
    "                s2_query_backward = s2_c[-2]\n",
    "                s2_query = torch.cat([s2_query_forward, s2_query_backward], 1)\n",
    "            else:\n",
    "                s1_query = s1_c[-1]\n",
    "                s2_query = s2_c[-1]\n",
    "            \n",
    "            # Get attention weights and hidden state\n",
    "            s1_h, s1_weights = self.attention(s1_query, s1_outputs, s1_outputs)\n",
    "            s2_h, s2_weights = self.attention(s2_query, s2_outputs, s2_outputs)\n",
    "            s1_h = s1_h.squeeze(1)\n",
    "            s2_h = s2_h.squeeze(1)\n",
    "        else:\n",
    "            s1_nlayers, s1_batchsize, s1_n_hidden = s1_c.shape\n",
    "            s2_nlayers, s2_batchsize, s2_n_hidden = s2_c.shape\n",
    "            s1_h = self.s1_clayernorm(s1_c.transpose(0,1).contiguous().view(s1_batchsize, s1_nlayers * s1_n_hidden))\n",
    "            s2_h = self.s2_clayernorm(s2_c.transpose(0,1).contiguous().view(s2_batchsize, s2_nlayers * s2_n_hidden))\n",
    "        \n",
    "        # Calculate logits for each branch. Shape:[B, num_classes]\n",
    "        s1_logits = self.s1_linear_class.forward(s1_h)\n",
    "        s2_logits = self.s2_linear_class.forward(s2_h)\n",
    "        \n",
    "        if self.use_attention:\n",
    "            s1_pts = s1_weights\n",
    "            s2_pts = s2_weights\n",
    "        else:\n",
    "            s1_pts = None\n",
    "            s2_pts = None\n",
    "        \n",
    "        return s1_logits, s2_logits, s1_pts, s2_pts\n",
    "    \n",
    "    def forward(self, s1, s2):\n",
    "        \n",
    "        s1_logits, s2_logits, s1_pts, s2_pts = self._logits(s1, s2)\n",
    "        fused_logits = (s1_logits * self.s1_weight) + (s2_logits * (1 - self.s1_weight))\n",
    "        \n",
    "        return s1_logits, s2_logits, fused_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Training and Inference procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from datetime import datetime\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\"\"\"\n",
    "\n",
    "def get_optimizer(optimizer, params, lr, momentum):\n",
    "\n",
    "    optimizer = optimizer.lower()\n",
    "    if optimizer == 'sgd':\n",
    "        return torch.optim.SGD(params, lr, momentum=momentum)\n",
    "    elif optimizer == 'nesterov':\n",
    "        return torch.optim.SGD(params, lr, momentum=momentum, nesterov=True)\n",
    "    elif optimizer == 'adam':\n",
    "        return torch.optim.Adam(params, lr)\n",
    "    elif optimizer == 'amsgrad':\n",
    "        return torch.optim.Adam(params, lr, amsgrad=True)\n",
    "    else:\n",
    "        raise ValueError(\"{} currently not supported, please customize your optimizer in compiler.py\".format(optimizer))\n",
    "\n",
    "###############################################################################################\n",
    "\n",
    "class PolynomialLR(_LRScheduler):\n",
    "    \"\"\"Polynomial learning rate decay until step reach to max_decay_step\n",
    "    \n",
    "    Args:\n",
    "        optimizer (Optimizer): Wrapped optimizer.\n",
    "        max_decay_steps: after this step, we stop decreasing learning rate\n",
    "        min_learning_rate: scheduler stoping learning rate decay, value of learning rate must be this value\n",
    "        power: The power of the polynomial.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, optimizer, max_decay_steps, min_learning_rate=1e-5, power=1.0):\n",
    "        if max_decay_steps <= 1.:\n",
    "            raise ValueError('max_decay_steps should be greater than 1.')\n",
    "        self.max_decay_steps = max_decay_steps\n",
    "        self.min_learning_rate = min_learning_rate\n",
    "        self.power = power\n",
    "        self.last_step = 0\n",
    "        super().__init__(optimizer)\n",
    "        \n",
    "    def get_lr(self):\n",
    "        if self.last_step > self.max_decay_steps:\n",
    "            return [self.min_learning_rate for _ in self.base_lrs]\n",
    "\n",
    "        return [(base_lr - self.min_learning_rate) * \n",
    "                ((1 - self.last_step / self.max_decay_steps) ** (self.power)) + \n",
    "                self.min_learning_rate for base_lr in self.base_lrs]\n",
    "    \n",
    "    def step(self, step=None):\n",
    "        if step is None:\n",
    "            step = self.last_step + 1\n",
    "        self.last_step = step if step != 0 else 1\n",
    "        if self.last_step <= self.max_decay_steps:\n",
    "            decay_lrs = [(base_lr - self.min_learning_rate) * \n",
    "                         ((1 - self.last_step / self.max_decay_steps) ** (self.power)) + \n",
    "                         self.min_learning_rate for base_lr in self.base_lrs]\n",
    "            for param_group, lr in zip(self.optimizer.param_groups, decay_lrs):\n",
    "                param_group['lr'] = lr\n",
    "\n",
    "##########################################################################\n",
    "\n",
    "class ModelCompiler:\n",
    "    '''\n",
    "    Compiler of specified model\n",
    "    Args:\n",
    "        model (''nn.Module'') -- pytorch model for segmentation.\n",
    "        working_dir (sys.path or str) -- path to the working directory.\n",
    "        out_dir (sys.path or str) -- Path to the directory to store output prediction and associated files.\n",
    "        gpuDevices (tuple) -- indices of gpu devices to use.\n",
    "        br_weights (tuple) -- weights to decide the influence of each triple branchs in the LSTM model (e.g. s1, s2, fused). \n",
    "        params_init (sys.path or str) -- Path to the saved model parameters to load.\n",
    "        freeze_params (list of int) -- list of indices of the trainable layers in the network to freeze the gradients.\n",
    "                                       Useful in finetunning the model.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, model, working_dir, out_dir, gpuDevices=(0), \n",
    "                 br_weights=(0.3, 0.3, 0.4), params_init=None, freeze_params=None):\n",
    "\n",
    "        self.s3_client = boto3.client(\"s3\")\n",
    "        self.working_dir = working_dir\n",
    "        self.out_dir = out_dir\n",
    "        self.gpuDevices = gpuDevices\n",
    "        self.br_weights = br_weights\n",
    "        self.model = model\n",
    "        \n",
    "        self.model_name = self.model.__class__.__name__\n",
    "\n",
    "        if params_init:\n",
    "            self.load_params(params_init, freeze_params)\n",
    "\n",
    "        # gpu\n",
    "        self.gpu = torch.cuda.is_available()\n",
    "        if self.gpu:\n",
    "            print(\"----------GPU available----------\")\n",
    "            # GPU setting\n",
    "            if gpuDevices:\n",
    "                torch.cuda.set_device(gpuDevices[0])\n",
    "                self.model = torch.nn.DataParallel(self.model, device_ids=gpuDevices)\n",
    "            self.model = self.model.cuda()\n",
    "        \n",
    "        num_params = sum([p.numel() for p in self.model.parameters() if p.requires_grad])\n",
    "        print(\"total number of trainable parameters: {:2.1f}M\".format(num_params / 1000000))\n",
    "        \n",
    "        if params_init:\n",
    "            print(\"---------- Pre-trained model compiled successfully ----------\")\n",
    "        else:\n",
    "            print(\"---------- Vanilla Model compiled successfully ----------\")\n",
    "\n",
    "\n",
    "    def load_params(self, dir_params, freeze_params):\n",
    "\n",
    "        params_init = urlparse.urlparse(dir_params)\n",
    "        # load from s3\n",
    "        if params_init.scheme == \"s3\":\n",
    "            \n",
    "            bucket = params_init.netloc\n",
    "            params_key = params_init.path\n",
    "            params_key = params_key[1:] if params_key.startswith('/') else params_key\n",
    "            _, fn_params = os.path.split(params_key)\n",
    "\n",
    "            self.s3_client.download_file(Bucket=bucket,\n",
    "                                         Key=params_key,\n",
    "                                         Filename=fn_params)\n",
    "            inparams = torch.load(fn_params, map_location=\"cuda:{}\".format(self.gpuDevices[0]))\n",
    "\n",
    "            os.remove(fn_params)  # remove after loaded\n",
    "\n",
    "        ## or load from local\n",
    "        else:\n",
    "            inparams = torch.load(dir_params)\n",
    "\n",
    "        ## overwrite model entries with new parameters\n",
    "        model_dict = self.model.state_dict()\n",
    "\n",
    "        if \"module\" in list(inparams.keys())[0]:\n",
    "            inparams_filter = {k[7:]: v.cpu() for k, v in inparams.items() if k[7:] in model_dict}\n",
    "\n",
    "        else:\n",
    "            inparams_filter = {k: v.cpu() for k, v in inparams.items() if k in model_dict}\n",
    "        \n",
    "        model_dict.update(inparams_filter)\n",
    "        self.model.load_state_dict(model_dict)\n",
    "        \n",
    "        if freeze_params != None:\n",
    "            for i, p in enumerate(self.model.parameters()):\n",
    "                if i in freeze_params:\n",
    "                    p.requires_grad = False\n",
    "\n",
    "\n",
    "    def fit(self, trainDataset, valDataset, epochs, optimizer_name, lr_init, LR_policy, criterion, momentum=None):\n",
    "        \n",
    "\n",
    "        # Set the folder to save results.\n",
    "        working_dir = self.working_dir\n",
    "        out_dir = self.out_dir\n",
    "        model_name = self.model_name\n",
    "        self.model_dir = \"{}/{}/{}_ep{}\".format(working_dir, self.out_dir, model_name, epochs)\n",
    "        \n",
    "        if not os.path.exists(Path(working_dir) / out_dir / self.model_dir):\n",
    "            os.makedirs(Path(working_dir) / out_dir / self.model_dir)\n",
    "        \n",
    "        os.chdir(Path(working_dir) / out_dir / self.model_dir)\n",
    "        \n",
    "        print(\"--------------- Start training ---------------\")\n",
    "        start = datetime.now()\n",
    "\n",
    "        # Tensorboard writer setting\n",
    "        writer = SummaryWriter('./')\n",
    "\n",
    "        train_loss = []\n",
    "        val_loss = []\n",
    "        lr = lr_init\n",
    "        \n",
    "        optimizer = get_optimizer(optimizer_name, self.model.parameters(), lr, momentum)\n",
    "        \n",
    "        # Initialize the learning rate scheduler\n",
    "        if LR_policy == \"StepLR\":\n",
    "            scheduler = optim.lr_scheduler.StepLR(optimizer, \n",
    "                                                  step_size = 10, \n",
    "                                                  gamma = 0.85,)\n",
    "        elif LR_policy == \"Exponential\":\n",
    "            scheduler = optim.lr_scheduler.ExponentialLR(optimizer,\n",
    "                                                         gamma = 0.85,)\n",
    "        \n",
    "        elif LR_policy == \"PolynomialLR\":\n",
    "            scheduler = PolynomialLR(optimizer, \n",
    "                                     max_decay_steps=100, \n",
    "                                     min_learning_rate=1e-5, \n",
    "                                     power=0.9)\n",
    "        else:\n",
    "            scheduler = None  \n",
    "        \n",
    "        if isinstance(criterion, tuple) or isinstance(criterion, list):\n",
    "            train_criterion = criterion[0]\n",
    "            val_criterion = criterion[1]\n",
    "        else:\n",
    "            train_criterion = criterion\n",
    "            val_criterion = criterion\n",
    "        \n",
    "        for t in range(epochs):\n",
    "\n",
    "            print(\"[{}/{}]\".format(t + 1, epochs))\n",
    "            # start fitting\n",
    "            start_epoch = datetime.now()\n",
    "            train(trainDataset, self.model, train_criterion, optimizer, self.br_weights, gpu=self.gpu, train_loss=train_loss)\n",
    "            validate(valDataset, self.model, val_criterion, self.br_weights, gpu=self.gpu, val_loss=val_loss)\n",
    "\n",
    "            # Update the scheduler\n",
    "            if LR_policy in [\"StepLR\", \"Exponential\"]:\n",
    "                scheduler.step()\n",
    "                print(\"LR: {}\".format(scheduler.get_last_lr()))\n",
    "\n",
    "            if LR_policy == \"PolynomialLR\":\n",
    "                scheduler.step(t)\n",
    "                print(\"LR: {}\".format(optimizer.param_groups[0]['lr']))\n",
    "            \n",
    "            # time spent on single iteration\n",
    "            print(\"time:\", (datetime.now() - start_epoch).seconds)\n",
    "\n",
    "            #if t > 1 and t % lr_decay[1] == 0:\n",
    "                #lr *= lr_decay[0]\n",
    "\n",
    "            writer.add_scalars(\"Loss\", {\"train_loss\": train_loss[t], \"validation_loss\": val_loss[t]}, t + 1)\n",
    "            \n",
    "            writer.close()\n",
    "        \n",
    "        print(\"--------------- Training finished in {}s ---------------\".format((datetime.now() - start).seconds))\n",
    "    \n",
    "    def accuracy_evaluation(self, evalDataset, outPrefix, bucket=None):\n",
    "        \n",
    "        if not os.path.exists(Path(self.working_dir) / self.out_dir):\n",
    "            os.makedirs(Path(self.working_dir) / self.out_dir)\n",
    "        \n",
    "        os.chdir(Path(self.working_dir) / self.out_dir)\n",
    "        \n",
    "        print(\"--------------- Start evaluation ---------------\")\n",
    "        start = datetime.now()\n",
    "        \n",
    "        accuracy_evaluation(evalDataset, self.model, self.gpu, outPrefix, self.br_weights, bucket)\n",
    "        \n",
    "        print(\"--------------- Evaluation finished in {}s ---------------\".format((datetime.now() - start).seconds))\n",
    "        \n",
    "    def inference(self, predDataset, out_prefix=None):\n",
    "        \n",
    "        print(\"-------------------------- Start Inference(Test) --------------------------\")\n",
    "        \n",
    "        start = datetime.now()\n",
    "        if out_prefix is None:\n",
    "            out_prefix = Path(self.working_dir) / self.out_dir / \"Inference_output\"\n",
    "        \n",
    "        prefix_hard = Path(out_prefix) / \"HardScore\"\n",
    "        prefix_soft = Path(out_prefix) / \"SoftProb\"\n",
    "        \n",
    "        if not os.path.exists(prefix_hard):\n",
    "            os.makedirs(prefix_hard)\n",
    "        if not os.path.exists(prefix_soft):\n",
    "            os.makedirs(prefix_soft)\n",
    "        \n",
    "        os.chdir(Path(out_prefix))\n",
    "        \n",
    "        inference(predDataset, self.model, prefix_soft, prefix_hard, gpu=self.gpu, weights=self.br_weights)\n",
    "        \n",
    "        duration_in_sec = (datetime.now() - start).seconds\n",
    "        duration_format = str(timedelta(seconds = duration_in_sec))\n",
    "        print(\"-------------------------- Inference finished in {}s --------------------------\".format(duration_format))\n",
    "    \n",
    "    def save(self, save_fldr, bucket=None, save_object=\"params\"):\n",
    "        \n",
    "        outPrefix = Path(self.working_dir) / self.out_dir / save_fldr\n",
    "        \n",
    "        if save_object == \"params\":\n",
    "            \n",
    "            fn_params = \"{}_params.pth\".format(self.model_name)\n",
    "            \n",
    "            if bucket:\n",
    "                torch.save(self.model.state_dict(), fn_params )\n",
    "\n",
    "                self.s3_client.upload_file(Filename=fn_params, \n",
    "                                           Bucket=bucket, \n",
    "                                           Key=os.path.join(outPrefix, fn_params))\n",
    "                print(\"model parameters uploaded to s3!, at \", outPrefix)\n",
    "                \n",
    "                os.remove(Path(outPrefix) / fn_params)\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                if not os.path.exists(Path(outPrefix)):\n",
    "                    os.makedirs(Path(outPrefix))\n",
    "                \n",
    "                torch.save(self.model.state_dict(), Path(outPrefix) / fn_params)\n",
    "                print(\"model parameters is saved locally, at \", outPrefix)\n",
    "            \n",
    "        elif save_object == \"model\":\n",
    "            \n",
    "            fn_model = \"{}.pth\".format(self.model_name)\n",
    "            \n",
    "            if bucket:\n",
    "                torch.save(self.model, fn_model)\n",
    "\n",
    "                self.s3_client.upload_file(Filename=fn_model,\n",
    "                                           Bucket=bucket, \n",
    "                                           Key=os.path.join(outPrefix, fn_model))\n",
    "                print(\"model uploaded to s3!, at \", outPrefix)\n",
    "                \n",
    "                os.remove(Path(outPrefix) / fn_model)\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                if not os.path.exists(Path(outPrefix)):\n",
    "                    os.makedirs(Path(outPrefix))\n",
    "                \n",
    "                torch.save(self.model, Path(outPrefix) / fn_model)\n",
    "                print(\"model saved locally, at \", outPrefix)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Object type is not acceptable.\")\n",
    "\n",
    "################################################################################################################\n",
    "################################### Train, Evaluate, Validate and Predict ######################################\n",
    "################################################################################################################\n",
    "\n",
    "def train(trainData, model, criterion, optimizer, weights, gpu=True, train_loss=[]):\n",
    "    \n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    i = 0\n",
    "    \n",
    "    for s1_img, s2_img, label in trainData:\n",
    "        s1_img = Variable(s1_img)\n",
    "        s2_img = Variable(s2_img)\n",
    "        label = Variable(label)\n",
    "        \n",
    "        if gpu:\n",
    "            s1_img = s1_img.cuda()\n",
    "            s2_img = s2_img.cuda()\n",
    "            label = label.cuda()\n",
    "        \n",
    "        #model_out = model(s1_img, s2_img)\n",
    "        #loss = criterion()(model_out, label)\n",
    "        #epoch_loss += loss.item()\n",
    "        \n",
    "        #s1_model_out,  s2_model_out= model(s1_img, s2_img)\n",
    "        #s1_loss = criterion()(s1_model_out, label)\n",
    "        #s2_loss = criterion()(s2_model_out, label)\n",
    "        #s1_weight = 0.5\n",
    "        #total_loss = s1_loss * s1_weight + s2_loss * (1 - s1_weight)\n",
    "        #epoch_loss += total_loss.item()\n",
    "        \n",
    "        s1_model_out,  s2_model_out, fused_model_out = model(s1_img, s2_img)\n",
    "        s1_loss = criterion()(s1_model_out, label)\n",
    "        s2_loss = criterion()(s2_model_out, label)\n",
    "        fused_loss = criterion()(fused_model_out, label)\n",
    "        total_loss = (s1_loss * weights[0] + s2_loss * weights[1] + fused_loss * weights[2])\n",
    "        epoch_loss += total_loss.item()\n",
    "        \n",
    "        #print(\"train: \", i, epoch_loss)\n",
    "        i += 1\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        #loss.backward()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(\"train loss: {}\".format(epoch_loss / i))\n",
    "    if train_loss != None:\n",
    "        train_loss.append(float(epoch_loss / i))\n",
    "\n",
    "##################################################\n",
    "\n",
    "def validate(evalData, model, criterion, weights, gpu=True, val_loss=[]):\n",
    "    \n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    i = 0\n",
    "    #set_trace()\n",
    "    for s1_img, s2_img, label in evalData:\n",
    "        s1_img = Variable(s1_img, requires_grad=False)\n",
    "        #s1_img[s1_img != s1_img] = -100\n",
    "        s2_img = Variable(s2_img, requires_grad=False)\n",
    "        #s2_img[s2_img != s2_img] = -100\n",
    "        label = Variable(label, requires_grad=False)\n",
    "        \n",
    "        if gpu:\n",
    "            s1_img = s1_img.cuda()\n",
    "            s2_img = s2_img.cuda()\n",
    "            label = label.cuda()\n",
    "        \n",
    "        #model_out = model(s1_img, s2_img)\n",
    "        #loss = nn.CrossEntropyLoss()(model_out, label)\n",
    "        #epoch_loss += loss.item()\n",
    "        \n",
    "        #s1_model_out,  s2_model_out= model(s1_img, s2_img)\n",
    "        #s1_loss = criterion()(s1_model_out, label)\n",
    "        #s2_loss = criterion()(s2_model_out, label)\n",
    "        #s1_weight = 0.5\n",
    "        #total_loss = s1_loss.item() * s1_weight + s2_loss.item() * (1 - s1_weight)\n",
    "        #epoch_loss += total_loss\n",
    "        \n",
    "        s1_model_out,  s2_model_out, fused_model_out = model(s1_img, s2_img)\n",
    "        s1_loss = criterion(ignore_index = 0)(s1_model_out, label)\n",
    "        s2_loss = criterion(ignore_index = 0)(s2_model_out, label)\n",
    "        fused_loss = criterion(ignore_index = 0)(fused_model_out, label)\n",
    "        total_loss = (s1_loss * weights[0] + s2_loss * weights[1] + fused_loss * weights[2])\n",
    "        epoch_loss += total_loss.item()\n",
    "        \n",
    "        #print(\"val: \", i, epoch_loss)\n",
    "        i += 1\n",
    "    \n",
    "    print(\"validation loss: {}\".format(epoch_loss / i))\n",
    "    if val_loss != None:\n",
    "        val_loss.append(float(epoch_loss / i))\n",
    "\n",
    "##################################################\n",
    "\n",
    "def inference(testData, model, score_path, pred_path, gpu, weights):\n",
    "\n",
    "    testData, meta, tile_id = testData\n",
    "    \n",
    "    meta_hard = meta.copy()\n",
    "    \n",
    "    meta_hard.update({'dtype': 'uint8',\n",
    "                      'nodata': None,\n",
    "                      'count': 1,\n",
    "                     })\n",
    "    \n",
    "    meta_soft = meta_hard.copy()\n",
    "    meta_soft.update({\n",
    "        \"dtype\": \"float32\"\n",
    "    })\n",
    "    \n",
    "    name_prob = \"prob_{}.tif\".format(tile_id)\n",
    "    name_crisp = \"crisp_{}.tif\".format(tile_id)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    h_canvas = np.zeros((1, meta_hard['height'], meta_hard['width']), dtype = meta_hard[\"dtype\"])\n",
    "    canvas_softScore_ls = []\n",
    "    metrics = []\n",
    "    \n",
    "    for s1_img, s2_img, coor in testData:\n",
    "        s1_img = Variable(s1_img, requires_grad=False)\n",
    "        s2_img = Variable(s2_img, requires_grad=False)\n",
    "        \n",
    "        if gpu:\n",
    "            s1_img = s1_img.cuda()\n",
    "            s2_img = s2_img.cuda()\n",
    "        \n",
    "        s1_model_out, s2_model_out, fused_model_out = model(s1_img, s2_img)\n",
    "        pred_logits = s1_model_out * weights[0] + s2_model_out * weights[1] + fused_model_out * weights[2] \n",
    "        pred_prob = F.softmax(pred_logits, 1)\n",
    "        \n",
    "        batch, nclass = pred_prob.size()\n",
    "        \n",
    "        for i in range(batch):\n",
    "            index = (int(coor[0][i]), int(coor[1][i]))\n",
    "            out_predict = pred_prob.max(dim=1)[1].cpu().numpy()\n",
    "            out_predict = np.expand_dims(out_predict, axis=0).astype(np.int8)\n",
    "            h_canvas[:, index[0], index[1]] = out_predict\n",
    "            \n",
    "            for n in range(nclass - 1):\n",
    "                out_softScore = pred_prob[:, n+1].data[i].cpu().numpy() * 100\n",
    "                out_softScore = np.expand_dims(out_softScore, axis=0).astype(np.float32)\n",
    "                try:\n",
    "                    canvas_softScore_ls[n][:, index[0], index[1]] = out_softScore\n",
    "                except:\n",
    "                    canvas_softScore_single = np.zeros((1, meta_soft['height'], meta_soft['width']), dtype= meta_soft[\"dtype\"])\n",
    "                    canvas_softScore_single[:, index[0], index[1]] = out_softScore\n",
    "                    canvas_softScore_ls.append(canvas_softScore_single)\n",
    "    \n",
    "    with rasterio.open(Path(pred_path) / name_crisp, \"w\", **meta_hard) as dst:\n",
    "        dst.write(h_canvas)\n",
    "    \n",
    "    for n in range(1, len(canvas_softScore_ls)):\n",
    "        with rasterio.open(Path(score_path) / name_prob, \"w\", **meta_soft) as dst:\n",
    "            dst.write(canvas_softScore_ls[n])\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \n",
    "    \"working_dir\" : \"C:/My_documents/CropTypeData_Rustowicz/working_folder\",\n",
    "    \"out_dir\": \"new_try_01\",\n",
    "    # Dataset & Loader\n",
    "    \"root_dir\" : \"C:/My_documents/CropTypeData_Rustowicz/CropType\",\n",
    "    \"sampling_strategy\" : \"ranked\",\n",
    "    \"lbl_fldrname\" : \"Labels\",\n",
    "    \"sources\" : [\"Sentinel-1\", \"Sentinel-2\"],\n",
    "    \"num_train_pixels\" : 15000,\n",
    "    \"num_validation_pixels\" : 10000,\n",
    "    \"test_label\" : False,\n",
    "    \"batch_train\" : 128,\n",
    "    \"batch_val\" : 1,\n",
    "    \n",
    "    # Model Compiler\n",
    "    \"init_params\" : None,\n",
    "    \"gpus\" : [0],\n",
    "    \"input_dims\" : (4, 11),\n",
    "    \"LSTM_hidden_dim\" : (48, 64),\n",
    "    \"CNN_hidden_dim\" : (48, 64),\n",
    "    \"CNN_kernel_size\" : (5, 5),\n",
    "    \"CNN_sequence_length\" : (57, 67),\n",
    "    \"n_classes\": 4,\n",
    "    \"n_LSTM_layers\" : (2, 4),\n",
    "    \"LSTM_lyr_dropout_rate\" : (0.4, 0.5),\n",
    "    \"CNN_lyr_dropout_rate\" : (0.25, 0.45),\n",
    "    \"s1_weight\" : 0.5,\n",
    "    \n",
    "    # Model fitting\n",
    "    \"epoch\" : 75,\n",
    "    \"optimizer\" : \"amsgrad\",\n",
    "    \"momentum\" : 0.95,\n",
    "    \"criterion\" : nn.CrossEntropyLoss,\n",
    "    \"branch_weights\" : (0.3, 0,3, 0.4),\n",
    "    \"lr_init\" : 0.01,\n",
    "    \"LR_policy\" : \"\",\n",
    "    \n",
    "    \"bucket\" : None,\n",
    "    \"save_fldr\": \"model_path\",\n",
    "    \"prefix_out\" : None\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Making training dataset from .npy files\n",
    "train_dataset = pixelDataset(root_dir=config[\"root_dir\"],\n",
    "                             usage=\"train\",\n",
    "                             num_samples=config[\"num_train_pixels\"],\n",
    "                             sampling_strategy=config[\"sampling_strategy\"],  \n",
    "                             sources=config[\"sources\"],\n",
    "                             verbose=False\n",
    "                             )\n",
    "\n",
    "#Make a Pickle from the training dataset\n",
    "#filePath = Path(config[\"working_dir\"]) / config[\"out_dir\"] / \"train_dataset.pickle\"\n",
    "#pickle_dataset(train_dataset, filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training dataset from pickle file\n",
    "filePath = Path(config[\"working_dir\"]) / config[\"out_dir\"] / \"train_dataset.pickle\"\n",
    "train_dataset = load_dataset(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batching and loading the training dataset on GPU\n",
    "sampler = CropTypeBatchSampler(train_dataset, batch_size=config[\"batch_train\"], sort_src=\"s1\", drop_last=False)\n",
    "train_loader = DataLoader(train_dataset, batch_sampler=sampler, collate_fn=collate_var_length)\n",
    "\n",
    "# Loading without dedicated sampler\n",
    "#train_loader = DataLoader(train_dataset, batch_size = config[\"batch_train\"], shuffle=True, collate_fn=collate_var_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check to check how the data looks like.\n",
    "\"\"\"\n",
    "for s1, s2, lbl in DataLoader(train_dataset, batch_sampler=sampler, collate_fn=collate_var_length):\n",
    "    print(s1.shape)\n",
    "    print(s1[1,:,:])\n",
    "    print(\"---\")\n",
    "    print(s2.shape)\n",
    "    print(s2[1,:,:])\n",
    "    print(\"---\")\n",
    "    print(lbl)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make validation dataset from .npy file\n",
    "validation_dataset = pixelDataset(root_dir = config[\"root_dir\"],\n",
    "                                  usage = \"validation\",\n",
    "                                  num_samples = config[\"num_validation_pixels\"],\n",
    "                                  sampling_strategy=config[\"sampling_strategy\"], \n",
    "                                  sources = config[\"sources\"],\n",
    "                                  verbose=False\n",
    "                                  )\n",
    "\n",
    "# Make a Pickle from the validation dataset\n",
    "#filePath = Path(config[\"working_dir\"]) / config[\"out_dir\"] / \"validation_dataset.pickle\"\n",
    "#pickle_dataset(train_dataset, filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the validation dataset from pickle file\n",
    "filePath = Path(config[\"working_dir\"]) / config[\"out_dir\"] / \"validation_dataset.pickle\"\n",
    "validation_dataset = load_dataset(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batching and loading the validation dataset on GPU\n",
    "validation_loader = DataLoader(validation_dataset, \n",
    "                               batch_size = config[\"batch_val\"], \n",
    "                               shuffle = True,\n",
    "                              collate_fn= collate_var_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "lstm_model = Double_branch_stacked_biLSTM(input_dims = config[\"input_dims\"],\n",
    "                                          hidden_dims = config[\"LSTM_hidden_dim\"], \n",
    "                                          n_classes = config[\"n_classes\"], \n",
    "                                          n_layers = config[\"n_LSTM_layers\"], \n",
    "                                          dropout_rate = config[\"LSTM_lyr_dropout_rate\"], \n",
    "                                          s1_weight = config[\"s1_weight\"], \n",
    "                                          bidirectional = True, \n",
    "                                          use_layernorm = True, \n",
    "                                          use_batchnorm = False, \n",
    "                                          use_attention = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model = ModelCompiler(model=lstm_model,\n",
    "                      working_dir=config[\"working_dir\"], \n",
    "                      out_dir=config[\"out_dir\"],\n",
    "                      gpuDevices=config[\"gpus\"],\n",
    "                      br_weights = config[\"branch_weights\"],\n",
    "                      params_init=config[\"init_params\"],\n",
    "                      freeze_params=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(train_loader, \n",
    "          validation_loader, \n",
    "          config[\"epoch\"], \n",
    "          config[\"optimizer\"], \n",
    "          config[\"lr_init\"],\n",
    "          config[\"LR_policy\"], \n",
    "          config[\"criterion\"],\n",
    "          config[\"momentum\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.accuracy_evaluation(validation_loader, \n",
    "                          outPrefix=config[\"prefix_out\"],\n",
    "                          weights = config[\"branch_weights\"],\n",
    "                          bucket=config[\"bucket\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(save_fldr=config[\"save_fldr\"], \n",
    "           bucket=config[\"bucket\"], \n",
    "           save_object = \"params\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "lstm_model = Double_branch_stacked_biLSTM(input_dims = config[\"input_dims\"],\n",
    "                                          hidden_dims = config[\"LSTM_hidden_dim\"], \n",
    "                                          n_classes = config[\"n_classes\"], \n",
    "                                          n_layers = config[\"n_LSTM_layers\"], \n",
    "                                          dropout_rate = config[\"LSTM_lyr_dropout_rate\"], \n",
    "                                          s1_weight = config[\"s1_weight\"], \n",
    "                                          bidirectional = True, \n",
    "                                          use_layernorm = True, \n",
    "                                          use_batchnorm = False, \n",
    "                                          use_attention = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"init_params\"] = \"C:/My_documents/CropTypeData_Rustowicz/working_folder/new_try_01/model_path/Double_branch_stacked_biLSTM_params.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model = ModelCompiler(model=lstm_model,\n",
    "                      working_dir=config[\"working_dir\"], \n",
    "                      out_dir=config[\"out_dir\"],\n",
    "                      gpuDevices=config[\"gpus\"],\n",
    "                      br_weights = config[\"branch_weights\"],\n",
    "                      params_init=config[\"init_params\"],\n",
    "                      freeze_params=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_pred(usage, item):\n",
    "    dataset = pixelDataset(root_dir = config[\"root_dir\"],\n",
    "                           usage = \"test\",\n",
    "                           sources = config[\"sources\"],\n",
    "                           inference_index = item)\n",
    "    tile = dataset.tile_id\n",
    "    meta = dataset.meta\n",
    "    data_loader = DataLoader(dataset, \n",
    "                          batch_size=config[\"batch_val\"], \n",
    "                          shuffle = False)\n",
    "    \n",
    "    return data_loader, meta, tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediction_dir = Path(config[root_dir]).joinpath(\"prediction_tiles\", config[\"sources\"][0])\n",
    "s1_fnames = [Path(dirpath) / f for (dirpath, dirnames, filenames) in os.walk(prediction_dir) for f in filenames if f.endswith(\".npy\")]\n",
    "tile_count = len(s1_fnames)\n",
    "\n",
    "for i in range(tile_count):\n",
    "    pred_data = load_data_pred(\"test\", i)\n",
    "    model.inference(pred_data, config[\"prefix_out\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-venv",
   "language": "python",
   "name": "local-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "465px",
    "left": "1550px",
    "right": "20px",
    "top": "118px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
